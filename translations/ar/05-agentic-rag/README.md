[![Agentic RAG](../../../translated_images/ar/lesson-5-thumbnail.20ba9d0c0ae64fae.webp)](https://youtu.be/WcjAARvdL7I?si=BCgwjwFb2yCkEhR9)

> _(انقر على الصورة أعلاه لمشاهدة فيديو هذا الدرس)_

# Agentic RAG

يوفر هذا الدرس نظرة شاملة على توليد الاسترجاع المعزز الوكِلي (Agentic RAG)، وهو نمط ناشئ في الذكاء الاصطناعي حيث تقوم نماذج اللغة الكبيرة (LLMs) بالتخطيط بشكل مستقل لخطواتها التالية مع جلب المعلومات من مصادر خارجية. بخلاف أنماط الاسترجاع الثابتة التي تتبع نموذج القراءة بعد الاسترجاع، يتضمن Agentic RAG مكالمات تكرارية للنموذج اللغوي الكبير، متداخلة مع استدعاءات لأدوات أو وظائف ومخرجات منظمة. يقوم النظام بتقييم النتائج، وتحسين الاستعلامات، واستدعاء أدوات إضافية إذا لزم الأمر، ويستمر في هذه الدورة حتى يتم تحقيق حل مرضٍ.

## مقدمة

سيغطي هذا الدرس

- **فهم Agentic RAG:** تعلّم عن نمط الذكاء الاصطناعي الناشئ حيث تقوم نماذج اللغة الكبيرة (LLMs) بالتخطيط المستقل لخطواتها التالية أثناء سحب المعلومات من مصادر بيانات خارجية.
- **فهم نمط الصانع-المراجع التكراري:** استيعاب حلقة المكالمات التكرارية للنموذج اللغوي الكبير، المتداخلة مع استدعاءات الأدوات أو الوظائف والمخرجات المنظمة، والمصممة لتحسين الدقة ومعالجة الاستعلامات المشوهة.
- **استكشاف التطبيقات العملية:** تحديد السيناريوهات التي يبرع بها Agentic RAG، مثل بيئات التركيز على الدقة، والتفاعلات المعقدة مع قواعد البيانات، وسير العمل الممتد.

## أهداف التعلم

بعد إتمام هذا الدرس، ستعرف/تفهم كيف:

- **فهم Agentic RAG:** تعلّم عن نمط الذكاء الاصطناعي الناشئ حيث تقوم نماذج اللغة الكبيرة (LLMs) بالتخطيط المستقل لخطواتها التالية أثناء سحب المعلومات من مصادر بيانات خارجية.
- **نمط الصانع-المراجع التكراري:** استيعاب مفهوم حلقة المكالمات التكرارية للنموذج اللغوي الكبير، المتداخلة مع استدعاءات الأدوات أو الوظائف والمخرجات المنظمة، والمصممة لتحسين الدقة ومعالجة الاستعلامات المشوهة.
- **امتلاك عملية التفكير:** فهم قدرة النظام على امتلاك عملية التفكيره، واتخاذ قرارات حول كيفية التعامل مع المشاكل دون الاعتماد على مسارات معرفّة مسبقًا.
- **سير العمل:** فهم كيف يقرر النموذج الوكِلي بشكل مستقل استرجاع تقارير اتجاهات السوق، وتحديد بيانات المنافسين، وربط مقاييس المبيعات الداخلية، وتجميع النتائج، وتقييم الاستراتيجية.
- **الحلقات التكرارية، دمج الأدوات، والذاكرة:** التعرف على اعتماد النظام على نمط تفاعل حلقي، مع الاحتفاظ بالحالة والذاكرة عبر الخطوات لتجنب الحلقات المتكررة واتخاذ قرارات مستنيرة.
- **معالجة أوضاع الفشل والتصحيح الذاتي:** استكشاف آليات التصحيح الذاتي القوية للنظام، بما في ذلك التكرار وإعادة الاستعلام، واستخدام أدوات التشخيص، والرجوع للمراقبة البشرية.
- **حدود الوكالة:** فهم قيود Agentic RAG التي تركز على الاستقلاليّة ضمن نطاق متخصص واعتماده على البنية التحتية واحترام قواعد الضبط.
- **حالات الاستخدام العملية والقيمة:** تحديد السيناريوهات التي يبرع بها Agentic RAG، مثل بيئات التركيز على الدقة، والتفاعلات المعقدة مع قواعد البيانات، وسير العمل الممتد.
- **الحوكمة، الشفافية، والثقة:** تعلم أهمية الحوكمة والشفافية، بما في ذلك التفكير القابل للتفسير، التحكم في التحيز، والإشراف البشري.

## ما هو Agentic RAG؟

توليد الاسترجاع المعزز الوكِلي (Agentic RAG) هو نمط ناشئ في الذكاء الاصطناعي حيث تقوم نماذج اللغة الكبيرة (LLMs) بالتخطيط المستقل لخطواتها التالية أثناء سحب المعلومات من مصادر خارجية. بخلاف أنماط الاسترجاع الثابتة التي تتبع نموذج القراءة بعد الاسترجاع، يتضمن Agentic RAG مكالمات تكرارية للنموذج اللغوي الكبير، متداخلة مع استدعاءات لأدوات أو وظائف ومخرجات منظمة. يقوم النظام بتقييم النتائج، وتحسين الاستعلامات، واستدعاء أدوات إضافية إذا لزم الأمر، ويستمر في هذه الدورة حتى يتم تحقيق حل مرضٍ. هذا النمط التكراري "صانع-مراجع" يُحسّن الدقة، يتعامل مع استعلامات مشوهة، ويضمن نتائج عالية الجودة.

يمتلك النظام عملية تفكيره بنشاط، يعيد كتابة الاستعلامات الفاشلة، يختار طرق استرجاع مختلفة، ويُدمج أدوات متعددة—مثل البحث الناقط في Azure AI Search، قواعد بيانات SQL، أو واجهات برمجة التطبيقات المخصصة—قبل إنهاء إجابته. السمة المميزة للنظام الوكِلي هي قدرته على امتلاك عملية تفكيره. تعتمد تطبيقات RAG التقليدية على مسارات معرفّة مسبقًا، لكن النظام الوكِلي يحدد بشكل مستقل تسلسل الخطوات بناءً على جودة المعلومات التي يعثر عليها.

## تعريف توليد الاسترجاع المعزز الوكِلي (Agentic RAG)

توليد الاسترجاع المعزز الوكِلي (Agentic RAG) هو نمط ناشئ في تطوير الذكاء الاصطناعي حيث لا تقوم نماذج اللغة الكبيرة فقط بجلب المعلومات من مصادر بيانات خارجية، بل تخطط أيضًا بشكل مستقل للخطوات التالية. بخلاف أنماط الاسترجاع الثابتة التي تتبع نموذج القراءة بعد الاسترجاع أو تسلسلات الإرشادات المفصلة بعناية، يتضمن Agentic RAG حلقة من المكالمات التكرارية للنموذج اللغوي الكبير، متداخلة مع استدعاءات لأدوات أو وظائف ومخرجات منظمة. في كل خطوة، يقوم النظام بتقييم النتائج التي حصل عليها، ويقرر ما إذا كان يجب تحسين استعلاماته، ويستدعي أدوات إضافية إذا لزم الأمر، ويستمر في هذه الدورة حتى يحقق حلاً مرضيًا.

هذا النمط التكراري "صانع-مراجع" مُصمم لتحسين الدقة، والتعامل مع استعلامات مشوهة لقواعد البيانات المنظمة (مثل NL2SQL)، وضمان نتائج متوازنة وعالية الجودة. بدلاً من الاعتماد فقط على سلاسل الإرشادات المصممة بعناية، يمتلك النظام عملية تفكيره بنشاط. يستطيع إعادة كتابة الاستعلامات الفاشلة، اختيار طرق استرجاع مختلفة، ودمج أدوات متعددة—مثل البحث الناقط في Azure AI Search، قواعد بيانات SQL، أو واجهات برمجة التطبيقات المخصصة—قبل إنهاء إجابته. هذا يلغي الحاجة إلى أطر تنسيق معقدة جدًا. بدلاً من ذلك، يمكن لحلقة بسيطة من "مكالمة LLM → استخدام أداة → مكالمة LLM → ..." أن تنتج مخرجات متقدمة ومبنية جيدًا.

![Agentic RAG Core Loop](../../../translated_images/ar/agentic-rag-core-loop.c8f4b85c26920f71.webp)

## امتلاك عملية التفكير

السمة المميزة التي تجعل النظام "وكِليًا" هي قدرته على امتلاك عملية تفكيره. غالبًا ما تعتمد تطبيقات RAG التقليدية على قيام البشر بتحديد مسار للنموذج: سلسلة من الأفكار تحدد ما يجب استرجاعه ومتى.
لكن عندما يكون النظام حقًا وكِليًا، يقرر داخليًا كيفية التعامل مع المشكلة. إنه لا ينفذ نصًا فقط؛ بل يحدد بشكل مستقل تسلسل الخطوات بناءً على جودة المعلومات التي يجدها.
على سبيل المثال، إذا طُلب منه إنشاء استراتيجية إطلاق منتج، لا يعتمد فقط على نص يعرض كامل عملية البحث واتخاذ القرار. بدلًا من ذلك، يقرر النموذج الوكِلي بشكل مستقل أن:

1. استرجاع تقارير اتجاهات السوق الحالية باستخدام Bing Web Grounding
2. تحديد بيانات المنافسين ذات الصلة باستخدام Azure AI Search.
3. ربط مقاييس المبيعات الداخلية التاريخية باستخدام Azure SQL Database.
4. تجميع النتائج في استراتيجية مترابطة تتم تنسيقها عبر Azure OpenAI Service.
5. تقييم الاستراتيجية للكشف عن أي ثغرات أو تناقضات، مما يحفز جولة أخرى من الاسترجاع إذا لزم الأمر.
كل هذه الخطوات—تحسين الاستعلامات، اختيار المصادر، التكرار حتى الوصول إلى "رضا" عن الإجابة—يقررها النموذج، وليس مبرمجًا مسبقًا بواسطة الإنسان.

## الحلقات التكرارية، دمج الأدوات، والذاكرة

![Tool Integration Architecture](../../../translated_images/ar/tool-integration.0f569710b5c17c10.webp)

يعتمد النظام الوكِلي على نمط تفاعل حلقي:

- **المكالمة الأولية:** يتم تقديم هدف المستخدم (المعروف بالطلب) إلى النموذج اللغوي الكبير.
- **استدعاء الأداة:** إذا حدد النموذج وجود معلومات مفقودة أو تعليمات غامضة، يختار أداة أو طريقة استرجاع—مثل استعلام قاعدة بيانات نقطية (مثال: البحث الهجين في Azure AI Search على بيانات خاصة) أو مكالمة SQL منظمة—لجمع مزيد من السياق.
- **التقييم والتحسين:** بعد مراجعة البيانات المعادة، يقرر النموذج ما إذا كانت المعلومات كافية. إذا لم تكن كذلك، يحسّن الاستعلام، يجرب أداة أخرى، أو يضبط نهجه.
- **التكرار حتى الرضا:** تستمر هذه الدورة حتى يحدد النموذج أنه يتمتع بوضوح وأدلة كافية لتقديم رد نهائي ومدروس.
- **الذاكرة والحالة:** نظرًا لأن النظام يحتفظ بحالته وذاكرته عبر الخطوات، يمكنه تذكر المحاولات السابقة ونتائجها، وتجنب الحلقات المتكررة واتخاذ قرارات أكثر وعيًا أثناء التقدم.

مع مرور الوقت، يخلق هذا شعورًا بفهم متطور، مما يمكن النموذج من التنقل في المهام المعقدة متعددة الخطوات دون الحاجة لتدخل بشري مستمر أو إعادة تشكيل الطلب.

## معالجة أوضاع الفشل والتصحيح الذاتي

تشمل استقلالية Agentic RAG أيضًا آليات تصحيح ذاتي قوية. عندما يصطدم النظام بنهايات مسدودة—مثل استرجاع مستندات غير ذات صلة أو مواجهة استعلامات مشوهة—يمكنه:

- **التكرار وإعادة الاستعلام:** بدلاً من إرجاع ردود ذات قيمة منخفضة، يحاول النموذج استراتيجيات بحث جديدة، يعيد كتابة استعلامات قواعد البيانات، أو ينظر في مجموعات بيانات بديلة.
- **استخدام أدوات التشخيص:** قد يستدعي النظام وظائف إضافية مصممة لمساعدته في تصحيح خطوات تفكيره أو تأكيد صحة البيانات التي استرجعها. ستكون أدوات مثل Azure AI Tracing مهمة لتمكين المراقبة والملاحظة القوية.
- **الرجوع للمراقبة البشرية:** في السيناريوهات ذات المخاطر العالية أو الفشل المتكرر، قد يشير النموذج إلى عدم اليقين ويطلب توجيهًا بشريًا. بمجرد أن يقدم الإنسان ملاحظات تصحيحية، يمكن للنموذج تضمين هذا الدرس في المستقبل.

يسمح هذا النهج التكراري والديناميكي للنموذج بالتحسن المستمر، مما يضمن أنه ليس مجرد نظام لمرة واحدة بل نظام يتعلم من أخطائه خلال الجلسة المعينة.

![Self Correction Mechanism](../../../translated_images/ar/self-correction.da87f3783b7f174b.webp)

## حدود الوكالة

على الرغم من استقلاليته ضمن مهمة معينة، لا يشابه Agentic RAG الذكاء الاصطناعي العام الاصطناعي. قدرات "الوكالة" الخاصة به محصورة بالأدوات ومصادر البيانات والسياسات التي يوفرها المطورون البشر. لا يمكنه اختراع أدواته الخاصة أو الخروج عن حدود المجال المحددة له. بدلاً من ذلك، يتفوق في تنظيم الموارد المتاحة بشكل ديناميكي.
تشمل الاختلافات الرئيسية عن أشكال الذكاء الاصطناعي الأكثر تقدمًا:

1. **الاستقلالية الخاصة بالنطاق:** تركز أنظمة Agentic RAG على تحقيق الأهداف التي يحددها المستخدم داخل نطاق معروف، مستخدمة استراتيجيات مثل إعادة كتابة الاستعلام أو اختيار الأداة لتحسين النتائج.
2. **الاعتماد على البنية التحتية:** تعتمد قدرات النظام على الأدوات والبيانات التي يدمجها المطورون. لا يمكنه تجاوز هذه الحدود دون تدخل بشري.
3. **احترام قواعد الضبط:** تبقى الإرشادات الأخلاقية وقواعد الامتثال وسياسات الأعمال مهمة جدًا. حرية الوكيل مقيدة دائمًا بإجراءات السلامة وآليات الإشراف (نأمل ذلك؟).

## حالات الاستخدام العملية والقيمة

يبرع Agentic RAG في السيناريوهات التي تتطلب تحسينًا تكراريًا ودقة:

1. **بيئات التركيز على الدقة:** في فحوصات الامتثال، التحليل التنظيمي، أو البحوث القانونية، يمكن للنموذج الوكِلي التحقق مرارًا من الحقائق، استشارة مصادر متعددة، وإعادة كتابة الاستعلامات حتى ينتج إجابة مدققة بالكامل.
2. **التفاعلات المعقدة مع قواعد البيانات:** عند التعامل مع بيانات منظمة حيث قد تفشل الاستعلامات غالبًا أو تحتاج إلى تعديل، يمكن للنظام تحسين استعلاماته بشكل مستقل باستخدام Azure SQL أو Microsoft Fabric OneLake، لضمان أن الاسترجاع النهائي يتوافق مع نية المستخدم.
3. **سير العمل الممتد:** قد تتطور الجلسات الأطول مع ظهور معلومات جديدة. يستطيع Agentic RAG دمج البيانات الجديدة باستمرار، وتغيير الاستراتيجيات مع تعلم المزيد عن مساحة المشكلة.

## الحوكمة، الشفافية، والثقة

مع ازدياد استقلالية هذه الأنظمة في التفكير، تصبح الحوكمة والشفافية أمرًا بالغ الأهمية:

- **التفكير القابل للتفسير:** يمكن للنموذج تقديم سجل تدقيقي للاستعلامات التي أجراها، والمصادر التي استشارها، وخطوات التفكير التي اتخذها للوصول إلى استنتاجه. تساعد أدوات مثل Azure AI Content Safety وAzure AI Tracing / GenAIOps في الحفاظ على الشفافية والتخفيف من المخاطر.
- **التحكم في التحيز والاسترجاع المتوازن:** يمكن للمطورين ضبط استراتيجيات الاسترجاع لضمان النظر في مصادر بيانات متوازنة وتمثيلية، والتدقيق المنتظم في المخرجات لاكتشاف التحيز أو الأنماط المشوهة باستخدام نماذج مخصصة لمنظمات علم البيانات المتقدمة باستخدام Azure Machine Learning.
- **الإشراف البشري والامتثال:** للمهام الحساسة، يظل المراجعة البشرية ضرورية. لا يحل Agentic RAG محل الحكم البشري في القرارات الحرجة—بل يعزيزه من خلال تقديم خيارات مدققة بشكل أفضل.

وجود أدوات تقدم سجلًا واضحًا للإجراءات ضروري. بدونها، يصبح تصحيح الأخطاء في عملية متعددة الخطوات صعبًا للغاية. انظر المثال التالي من Literal AI (الشركة وراء Chainlit) لتشغيل وكيل:

![AgentRunExample](../../../translated_images/ar/AgentRunExample.471a94bc40cbdc0c.webp)

## الخلاصة

يمثل Agentic RAG تطورًا طبيعيًا في كيفية تعامل أنظمة الذكاء الاصطناعي مع المهام المعقدة والمكثفة بالبيانات. من خلال اعتماد نمط تفاعل حلقي، واختيار الأدوات بشكل مستقل، وتحسين الاستعلامات حتى تحقيق نتائج عالية الجودة، ينتقل النظام إلى ما وراء اتباع النصوص الثابتة إلى صانع قرار أكثر تكيفًا ووعيًا بالسياق. وعلى الرغم من أنه لا يزال مقيدًا بالبُنى التحتية المقدمة من البشر والإرشادات الأخلاقية، فإن قدرات الوكالة هذه تُمكّن من تفاعلات ذكاء اصطناعي أغنى وأكثر ديناميكية وأكثر فائدة في نهاية المطاف لكل من المؤسسات والمستخدمين النهائيين.

### هل لديك المزيد من الأسئلة حول Agentic RAG؟

انضم إلى [خادم Microsoft Foundry على Discord](https://aka.ms/ai-agents/discord) لتلتقي بمتعلمين آخرين، وتحضر ساعات العمل، وتحصل على إجابات لأسئلتك حول وكلاء الذكاء الاصطناعي.

## موارد إضافية
- <a href="https://learn.microsoft.com/training/modules/use-own-data-azure-openai" target="_blank">تنفيذ التوليد المدعوم بالاسترجاع (RAG) باستخدام خدمة Azure OpenAI: تعلّم كيفية استخدام بياناتك الخاصة مع خدمة Azure OpenAI. توفر وحدة Microsoft Learn هذه دليلًا شاملاً حول تنفيذ RAG</a>
- <a href="https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-approach-gen-ai" target="_blank">تقييم تطبيقات الذكاء الاصطناعي التوليدية مع Microsoft Foundry: يغطي هذا المقال تقييم ومقارنة النماذج على مجموعات البيانات المتاحة للجمهور، بما في ذلك تطبيقات Agentic AI وهياكل RAG</a>
- <a href="https://weaviate.io/blog/what-is-agentic-rag" target="_blank">ما هو Agentic RAG | Weaviate</a>
- <a href="https://ragaboutit.com/agentic-rag-a-complete-guide-to-agent-based-retrieval-augmented-generation/" target="_blank">Agentic RAG: دليل كامل لتوليد الاسترجاع المعزز القائم على الوكلاء – أخبار من generation RAG</a>
- <a href="https://huggingface.co/learn/cookbook/agent_rag" target="_blank">Agentic RAG: عزز أداء RAG الخاص بك بإعادة صياغة الاستعلام والاستعلام الذاتي! كتاب وصفات الذكاء الاصطناعي مفتوح المصدر من Hugging Face</a>
- <a href="https://youtu.be/aQ4yQXeB1Ss?si=2HUqBzHoeB5tR04U" target="_blank">إضافة طبقات Agentic إلى RAG</a>
- <a href="https://www.youtube.com/watch?v=zeAyuLc_f3Q&t=244s" target="_blank">مستقبل مساعدي المعرفة: جيري ليو</a>
- <a href="https://www.youtube.com/watch?v=AOSjiXP1jmQ" target="_blank">كيفية بناء أنظمة Agentic RAG</a>
- <a href="https://ignite.microsoft.com/sessions/BRK102?source=sessions" target="_blank">استخدام خدمة وكلاء Microsoft Foundry لتوسيع نطاق وكلاء الذكاء الاصطناعي الخاص بك</a>

### أوراق أكاديمية

- <a href="https://arxiv.org/abs/2303.17651" target="_blank">2303.17651 Self-Refine: تحسين تدريجي مع تغذية راجعة ذاتية</a>
- <a href="https://arxiv.org/abs/2303.11366" target="_blank">2303.11366 Reflexion: وكلاء لغويون مع التعلم المعزز اللفظي</a>
- <a href="https://arxiv.org/abs/2305.11738" target="_blank">2305.11738 CRITIC: نماذج اللغة الكبيرة يمكنها التصحيح الذاتي من خلال النقد التفاعلي باستخدام الأدوات</a>
- <a href="https://arxiv.org/abs/2501.09136" target="_blank">2501.09136 التوليد المدعوم بالاسترجاع القائم على الوكلاء: دراسة استقصائية عن Agentic RAG</a>

## الدرس السابق

[نمط تصميم استخدام الأدوات](../04-tool-use/README.md)

## الدرس التالي

[بناء وكلاء ذكاء اصطناعي جديرين بالثقة](../06-building-trustworthy-agents/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**إخلاء المسؤولية**:
تمت ترجمة هذا المستند باستخدام خدمة الترجمة الآلية [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق به. للمعلومات الحساسة، يُنصح بالاعتماد على ترجمة احترافية بشرية. نحن غير مسؤولين عن أي سوء فهم أو تفسير ناتج عن استخدام هذه الترجمة.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->