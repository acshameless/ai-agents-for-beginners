# AI-agenter i produktion: Observabilitet og evaluering

[![AI-agenter i produktion](../../../translated_images/da/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

Efterh√•nden som AI-agenter g√•r fra eksperimentelle prototyper til virkelige anvendelser, bliver evnen til at forst√• deres adf√¶rd, overv√•ge deres ydeevne og systematisk evaluere deres output vigtig.

## L√¶ringsm√•l

Efter at have gennemf√∏rt denne lektion vil du vide, hvordan/forst√•:
- Kernekoncepter inden for agent-observabilitet og evaluering
- Teknikker til at forbedre agenters ydeevne, omkostninger og effektivitet
- Hvad og hvordan du systematisk evaluerer dine AI-agenter
- Hvordan du kontrollerer omkostninger ved udrulning af AI-agenter i produktion
- Hvordan du instrumenterer agenter bygget med AutoGen

M√•let er at udstyre dig med viden til at omdanne dine "black box"-agenter til gennemsigtige, h√•ndterbare og p√•lidelige systemer.

_**Bem√¶rk:** Det er vigtigt at udrulle AI-agenter, der er sikre og trov√¶rdige. Se ogs√• lektionen [Opbygning af p√•lidelige AI-agenter](./06-building-trustworthy-agents/README.md)._

## Spor og spans

Observabilitetsv√¶rkt√∏jer s√•som [Langfuse](https://langfuse.com/) eller [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) repr√¶senterer normalt agentk√∏rsler som traces og spans.

- **Trace** repr√¶senterer en komplet agentopgave fra start til slut (som h√•ndtering af en brugerforesp√∏rgsel).
- **Spans** er individuelle trin inden for trace'et (som at kalde en sprogmodel eller hente data).

![Sportr√¶ i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Uden observabilitet kan en AI-agent f√∏les som en "black box" - dens interne tilstand og r√¶sonnement er uigennemsigtige, hvilket g√∏r det sv√¶rt at diagnosticere problemer eller optimere ydeevnen. Med observabilitet bliver agenter til "glasbokse", der tilbyder gennemsigtighed, hvilket er afg√∏rende for at opbygge tillid og sikre, at de fungerer som tilt√¶nkt. 

## Hvorfor observabilitet betyder noget i produktionsmilj√∏er

Overgangen af AI-agenter til produktionsmilj√∏er introducerer et nyt s√¶t udfordringer og krav. Observabilitet er ikke l√¶ngere et "nice-to-have", men en kritisk evne:

*   **Debugging og rod√•rsagsanalyser**: N√•r en agent fejler eller producerer et uventet output, giver observabilitetsv√¶rkt√∏jer de spor, der er n√∏dvendige for at pege p√• fejlkilden. Dette er s√¶rligt vigtigt i komplekse agenter, der kan involvere flere LLM-opkald, v√¶rkt√∏jsinteraktioner og betinget logik.
*   **Latens- og omkostningsstyring**: AI-agenter er ofte afh√¶ngige af LLM'er og andre eksterne API'er, der faktureres per token eller per opkald. Observabilitet muligg√∏r pr√¶cis sporing af disse opkald, hvilket hj√¶lper med at identificere operationer, der er un√∏digt langsomme eller dyre. Dette g√∏r det muligt for teams at optimere prompts, v√¶lge mere effektive modeller eller redesigne arbejdsgange for at styre driftsomkostninger og sikre en god brugeroplevelse.
*   **Trov√¶rdighed, sikkerhed og overholdelse**: I mange anvendelser er det vigtigt at sikre, at agenter opf√∏rer sig sikkert og etisk. Observabilitet giver en revisionssti af agentens handlinger og beslutninger. Dette kan bruges til at opdage og afb√∏de problemer som prompt-injektion, generering af skadeligt indhold eller forkert h√•ndtering af personligt identificerbare oplysninger (PII). For eksempel kan du gennemg√• spor for at forst√•, hvorfor en agent gav et bestemt svar eller brugte et specifikt v√¶rkt√∏j.
*   **Kontinuerlige forbedringssl√∏jfer**: Observabilitetsdata er fundamentet for en iterativ udviklingsproces. Ved at overv√•ge, hvordan agenter pr√¶sterer i den virkelige verden, kan teams identificere forbedringsomr√•der, indsamle data til finjustering af modeller og validere effekten af √¶ndringer. Dette skaber en feedbacksl√∏jfe, hvor produktionsindsigter fra online-evaluering informerer offline-eksperimenter og forfinelse, hvilket f√∏rer til gradvist bedre agentydelse.

## N√∏glemetrikker at spore

For at overv√•ge og forst√• agentadf√¶rd b√∏r en r√¶kke metrikker og signaler spores. Selvom de specifikke metrikker kan variere afh√¶ngigt af agentens form√•l, er nogle universelt vigtige.

Her er nogle af de mest almindelige metrikker, som observabilitetsv√¶rkt√∏jer overv√•ger:

**Forsinkelse (latens):** Hvor hurtigt svarer agenten? Lange ventetider p√•virker brugeroplevelsen negativt. Du b√∏r m√•le latens for opgaver og individuelle trin ved at trace agentk√∏rsler. For eksempel kan en agent, der bruger 20 sekunder p√• alle modelopkald, accelereres ved at bruge en hurtigere model eller ved at k√∏re modelopkald parallelt.

**Omkostninger:** Hvad koster en agentk√∏rsel? AI-agenter er afh√¶ngige af LLM-opkald, der faktureres per token, eller eksterne API'er. Hyppig brug af v√¶rkt√∏jer eller flere prompts kan hurtigt √∏ge omkostningerne. For eksempel, hvis en agent kalder en LLM fem gange for marginal kvalitetforbedring, skal du vurdere, om omkostningen er berettiget, eller om du kan reducere antallet af opkald eller bruge en billigere model. Realtidsoverv√•gning kan ogs√• hj√¶lpe med at identificere uventede spidser (fx bugs, der for√•rsager overdrevne API-loops).

**Anmodningsfejl:** Hvor mange foresp√∏rgsler fejlede agenten p√•? Dette kan omfatte API-fejl eller mislykkede v√¶rkt√∏jsopkald. For at g√∏re din agent mere robust i produktion kan du oprette fallback-mekanismer eller retries. Fx hvis LLM-udbyder A er nede, kan du skifte til LLM-udbyder B som backup.

**Brugerfeedback:** Implementering af direkte brugerevalueringer giver v√¶rdifuld indsigt. Dette kan inkludere eksplicitte vurderinger (üëçthumbs-up/üëédown, ‚≠ê1-5 stjerner) eller tekstuelle kommentarer. Konsistent negativ feedback b√∏r give anledning til alarm, da dette er et tegn p√•, at agenten ikke fungerer som forventet. 

**Implicit brugerfeedback:** Brugeradf√¶rd giver indirekte feedback, selv uden eksplicitte vurderinger. Dette kan inkludere √∏jeblikkelig omformulering af sp√∏rgsm√•l, gentagne foresp√∏rgsler eller klik p√• en retry-knap. Fx hvis du ser, at brugere gentagne gange stiller det samme sp√∏rgsm√•l, er det et tegn p√•, at agenten ikke fungerer som forventet.

**N√∏jagtighed:** Hvor ofte producerer agenten korrekte eller √∏nskv√¶rdige outputs? Definitionerne af n√∏jagtighed varierer (fx korrekt l√∏sning af problemer, informationshentningsn√∏jagtighed, brugertilfredshed). Det f√∏rste skridt er at definere, hvordan succes ser ud for din agent. Du kan spore n√∏jagtighed via automatiserede checks, evalueringsscorer eller opm√¶rkede opgavestatusser. For eksempel at m√¶rke traces som "succeeded" eller "failed". 

**Automatiske evalueringsmetrikker:** Du kan ogs√• s√¶tte automatiserede evaluer op. For eksempel kan du bruge en LLM til at score agentens output, fx om det er hj√¶lpsomt, korrekt eller ej. Der findes ogs√• flere open source-biblioteker, der hj√¶lper dig med at score forskellige aspekter af agenten. Fx [RAGAS](https://docs.ragas.io/) for RAG-agenter eller [LLM Guard](https://llm-guard.com/) til at opdage skadeligt sprog eller prompt-injektion. 

I praksis giver en kombination af disse metrikker den bedste d√¶kning af en AI-agents helbred. I dette kapitels [eksempel-notebook](./code_samples/10_autogen_evaluation.ipynb) vil vi vise, hvordan disse metrikker ser ud i virkelige eksempler, men f√∏rst l√¶rer vi, hvordan en typisk evalueringsarbejdsgang ser ud.

## Instrumenter din agent

For at indsamle tracing-data skal du instrumentere din kode. M√•let er at instrumentere agentkoden til at udsende traces og metrikker, som kan fanges, behandles og visualiseres af en observabilitetsplatform.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) er blevet en industristandard for LLM-observabilitet. Det tilbyder et s√¶t API'er, SDK'er og v√¶rkt√∏jer til at generere, indsamle og eksportere telemetridata. 

Der findes mange instrumenteringsbiblioteker, der pakker eksisterende agent-rammev√¶rk ind og g√∏r det nemt at eksportere OpenTelemetry-spans til et observabilitetsv√¶rkt√∏j. Nedenfor er et eksempel p√• at instrumentere en AutoGen-agent med [OpenLit instrumenteringsbibliotek](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

The [eksempel-notebook](./code_samples/10_autogen_evaluation.ipynb) in this chapter will demonstrate how to instrument your AutoGen agent.

**Manuel oprettelse af spans:** Mens instrumenteringsbiblioteker giver et godt udgangspunkt, er der ofte tilf√¶lde, hvor mere detaljeret eller tilpasset information er n√∏dvendig. Du kan manuelt oprette spans for at tilf√∏je brugerdefineret applikationslogik. Mere vigtigt er, at du kan berige automatisk eller manuelt oprettede spans med brugerdefinerede attributter (ogs√• kendt som tags eller metadata). Disse attributter kan inkludere forretningsspecifikke data, mellemliggende beregninger eller enhver kontekst, der kan v√¶re nyttig til debugging eller analyse, s√•som `user_id`, `session_id`, eller `model_version`.

Eksempel p√• at oprette traces og spans manuelt med [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3): 

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Agent-evaluering

Observabilitet giver os metrikker, men evaluering er processen med at analysere disse data (og udf√∏re tests) for at afg√∏re, hvor godt en AI-agent pr√¶sterer, og hvordan den kan forbedres. Med andre ord, n√•r du har disse traces og metrikker, hvordan bruger du dem s√• til at bed√∏mme agenten og tr√¶ffe beslutninger? 

Regelm√¶ssig evaluering er vigtig, fordi AI-agenter ofte er nondeterministiske og kan udvikle sig (gennem opdateringer eller drift i modellens adf√¶rd) ‚Äì uden evaluering ville du ikke vide, om din "smarte agent" faktisk udf√∏rer sit arbejde godt eller om den er regresset.

Der er to kategorier af evalueringer for AI-agenter: **online-evaluering** og **offline-evaluering**. Begge er v√¶rdifulde og supplerer hinanden. Vi begynder som regel med offline-evaluering, da dette er det minimum, der er n√∏dvendigt, f√∏r man udruller en agent.

### Offline-evaluering

![Datas√¶t-elementer i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Dette involverer at evaluere agenten i et kontrolleret milj√∏, typisk ved hj√¶lp af testdatas√¶t, ikke live-brugerforesp√∏rgsler. Du bruger kuraterede datas√¶t, hvor du ved, hvad det forventede output eller korrekt adf√¶rd er, og k√∏rer derefter din agent p√• disse. 

For eksempel, hvis du byggede en agent til matematik-tekstopgaver, kunne du have et [testdatas√¶t](https://huggingface.co/datasets/gsm8k) p√• 100 problemer med kendte svar. Offline-evaluering udf√∏res ofte under udvikling (og kan v√¶re en del af CI/CD-pipelines) for at tjekke forbedringer eller beskytte mod regressioner. Fordelen er, at det er **gentageligt, og du kan f√• klare n√∏jagtighedsmetrikker, da du har ground truth**. Du kan ogs√• simulere brugerforesp√∏rgsler og m√•le agentens svar mod ideelle svar eller bruge automatiserede metrikker som beskrevet ovenfor. 

Den centrale udfordring med offline-eval er at sikre, at dit testdatas√¶t er d√¶kkende og forbliver relevant ‚Äì agenten kan klare sig godt p√• et fast tests√¶t, men m√∏de meget forskellige foresp√∏rgsler i produktion. Derfor b√∏r du holde tests√¶t opdaterede med nye kanttilf√¶lde og eksempler, der afspejler virkelige scenarier‚Äã. En blanding af sm√• "smoke test"-sager og st√∏rre evalueringss√¶t er nyttig: sm√• s√¶t til hurtige checks og st√∏rre til bredere ydelsesmetrikker‚Äã.

### Online-evaluering 

![Oversigt over observabilitetsmetrikker](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Dette refererer til at evaluere agenten i et live, virkeligt milj√∏, dvs. under faktisk brug i produktion. Online-evaluering involverer at overv√•ge agentens ydeevne p√• rigtige brugerinteraktioner og l√∏bende analysere resultaterne. 

For eksempel kan du spore succesrater, brugertilfredshedsscorer eller andre metrikker p√• live-trafik. Fordelen ved online-evaluering er, at det **fanger ting, du m√•ske ikke forudser i et laboratoriemilj√∏** ‚Äì du kan observere model-drift over tid (hvis agentens effektivitet forringes, efterh√•nden som inputm√∏nstre √¶ndrer sig) og fange uventede foresp√∏rgsler eller situationer, der ikke var i dine testdata‚Äã. Det giver et sandt billede af, hvordan agenten opf√∏rer sig i felten. 

Online-evaluering involverer ofte indsamling af implicit og eksplicit brugerfeedback, som diskuteret, og muligvis k√∏re shadow-tests eller A/B-tests (hvor en ny version af agenten k√∏rer parallelt for at sammenligne med den gamle). Udfordringen er, at det kan v√¶re vanskeligt at f√• p√•lidelige labels eller scores for live-interaktioner ‚Äì du kan v√¶re afh√¶ngig af brugerfeedback eller downstream-metrikker (fx om brugeren klikkede p√• resultatet). 

### Kombinationen af de to

Online- og offline-evalueringer udelukker ikke hinanden; de supplerer hinanden i h√∏j grad. Indsigter fra online-overv√•gning (fx nye typer brugerforesp√∏rgsler, hvor agenten pr√¶sterer d√•rligt) kan bruges til at udvide og forbedre offline-testdatas√¶t. Omvendt kan agenter, der klarer sig godt i offline-tests, derefter mere trygt udrulles og overv√•ges online. 

Faktisk adopterer mange teams en l√∏kke: 

_evaluer offline -> udrul -> overv√•g online -> indsamle nye fejlsager -> tilf√∏j til offline-datas√¶t -> forbedr agenten -> gentag_.

## Almindelige problemer

Som du udruller AI-agenter i produktion, kan du st√∏de p√• forskellige udfordringer. Her er nogle almindelige problemer og deres potentielle l√∏sninger:

| **Problem**    | **Potentiel l√∏sning**   |
| ------------- | ------------------ |
| AI-agenten udf√∏rer ikke opgaver konsekvent | - Forfin prompten, der gives til AI-agenten; v√¶r klar i m√•ls√¶tningerne.<br>- Identificer, hvor opdeling af opgaver i delopgaver og h√•ndtering af dem af flere agenter kan hj√¶lpe. |
| AI-agenten k√∏rer i kontinuerlige l√∏kker  | - S√∏rg for klare termineringsvilk√•r, s√• agenten ved, hvorn√•r processen skal stoppes.<br>- For komplekse opgaver, der kr√¶ver r√¶sonnement og planl√¶gning, brug en st√∏rre model, der er specialiseret til r√¶sonnement. |
| AI-agentens v√¶rkt√∏jsopkald fungerer ikke godt   | - Test og valider v√¶rkt√∏jets output uden for agentsystemet.<br>- Forfin de definerede parametre, prompts og navngivning af v√¶rkt√∏jer.  |
| Multi-agent-systemet fungerer ikke konsekvent | - Forfin prompts givet til hver agent for at sikre, at de er specifikke og forskellige fra hinanden.<br>- Byg et hierarkisk system ved hj√¶lp af en "routing"- eller controller-agent for at bestemme, hvilken agent der er den rigtige. |

Mange af disse problemer kan identificeres mere effektivt med observabilitet p√• plads. De spor og metrikker, vi diskuterede tidligere, hj√¶lper med pr√¶cist at pege p√•, hvor i agentarbejdsgangen problemer opst√•r, hvilket g√∏r debugging og optimering meget mere effektivt.

## H√•ndtering af omkostninger
Her er nogle strategier til at h√•ndtere omkostningerne ved at udrulle AI-agenter i produktion:

**Brug af mindre modeller:** Small Language Models (SLMs) kan klare sig godt i visse agentiske anvendelsestilf√¶lde og vil reducere omkostningerne betydeligt. Som n√¶vnt tidligere er det bedste m√•de at forst√•, hvor godt en SLM vil pr√¶stere i din brugssag p√•, at bygge et evalueringssystem til at bestemme og sammenligne pr√¶stationen i forhold til st√∏rre modeller. Overvej at bruge SLMs til enklere opgaver som intentionsklassificering eller parameterudtr√¶kning, mens du reserverer st√∏rre modeller til komplekst r√¶sonnement.

**Brug af en routermodel:** En tilsvarende strategi er at bruge en blanding af modeller og st√∏rrelser. Du kan bruge en LLM/SLM eller en serverl√∏s funktion til at rute foresp√∏rgsler baseret p√• kompleksitet til de bedst egnede modeller. Dette vil ogs√• hj√¶lpe med at reducere omkostningerne samtidig med, at ydeevnen sikres p√• de rigtige opgaver. For eksempel kan du rute simple foresp√∏rgsler til mindre, hurtigere modeller og kun bruge dyre, store modeller til komplekse r√¶sonnementopgaver.

**Cachelagring af svar:** At identificere almindelige foresp√∏rgsler og opgaver og levere svarene, f√∏r de g√•r gennem dit agentiske system, er en god m√•de at reducere m√¶ngden af lignende foresp√∏rgsler p√•. Du kan endda implementere en proces til at identificere, hvor ens en foresp√∏rgsel er i forhold til dine cachelagrede foresp√∏rgsler ved hj√¶lp af mere grundl√¶ggende AI-modeller. Denne strategi kan betydeligt reducere omkostningerne for ofte stillede sp√∏rgsm√•l eller almindelige arbejdsgange.

## Lad os se, hvordan dette fungerer i praksis

I [eksempelnotebook i denne sektion](./code_samples/10_autogen_evaluation.ipynb) vil vi se eksempler p√•, hvordan vi kan bruge observabilitetsv√¶rkt√∏jer til at overv√•ge og evaluere vores agent.

### Har du flere sp√∏rgsm√•l om AI Agents i produktion?

Deltag i [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) for at m√∏des med andre l√¶rende, deltage i kontortimer og f√• svar p√• dine sp√∏rgsm√•l om AI-agenter.

## Forrige lektion

[Metacognition Design Pattern](../09-metacognition/README.md)

## N√¶ste lektion

[Agentic Protocols](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Ansvarsfraskrivelse:
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten Co-op Translator (https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiske overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det oprindelige dokument i dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritiske oplysninger anbefales en professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->