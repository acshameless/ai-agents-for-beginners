# KI-Agenten in Produktion: Beobachtbarkeit & Evaluation

[![KI-Agenten in Produktion](../../../translated_images/de/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

Da KI-Agenten von experimentellen Prototypen zu realen Anwendungen √ºbergehen, wird die F√§higkeit, ihr Verhalten zu verstehen, ihre Leistung zu √ºberwachen und ihre Ausgaben systematisch zu bewerten, immer wichtiger.

## Lernziele

Nach Abschluss dieser Lektion werden Sie wissen/verstanden haben:
- Kernkonzepte der Beobachtbarkeit und Evaluation von Agenten
- Techniken zur Verbesserung der Leistung, der Kosten und der Effektivit√§t von Agenten
- Was und wie Sie Ihre KI-Agenten systematisch evaluieren
- Wie Sie die Kosten bei der Bereitstellung von KI-Agenten in der Produktion kontrollieren
- Wie Sie Agenten, die mit AutoGen gebaut wurden, instrumentieren

Das Ziel ist es, Sie mit dem Wissen auszustatten, Ihre ‚ÄûBlackbox‚Äú-Agenten in transparente, handhabbare und verl√§ssliche Systeme zu verwandeln.

_**Hinweis:** Es ist wichtig, KI-Agenten einzusetzen, die sicher und vertrauensw√ºrdig sind. Sehen Sie sich auch die Lektion [Building Trustworthy AI Agents](./06-building-trustworthy-agents/README.md) an._

## Traces und Spans

Beobachtbarkeitstools wie [Langfuse](https://langfuse.com/) oder [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) stellen Agentenl√§ufe √ºblicherweise als Traces und Spans dar.

- **Trace** repr√§sentiert eine vollst√§ndige Agentenaufgabe von Anfang bis Ende (z. B. die Bearbeitung einer Benutzeranfrage).
- **Spans** sind einzelne Schritte innerhalb des Traces (z. B. ein Aufruf eines Sprachmodells oder das Abrufen von Daten).

![Trace-Baum in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Ohne Beobachtbarkeit kann sich ein KI-Agent wie eine ‚ÄûBlackbox‚Äú anf√ºhlen ‚Äì sein interner Zustand und seine Schlussfolgerungen sind undurchsichtig, was es schwierig macht, Probleme zu diagnostizieren oder die Leistung zu optimieren. Mit Beobachtbarkeit werden Agenten zu ‚ÄûGlasboxen‚Äú, die Transparenz bieten, die entscheidend ist, um Vertrauen aufzubauen und sicherzustellen, dass sie wie beabsichtigt funktionieren.

## Warum Beobachtbarkeit in Produktionsumgebungen wichtig ist

Die √úberf√ºhrung von KI-Agenten in Produktionsumgebungen bringt eine neue Reihe von Herausforderungen und Anforderungen mit sich. Beobachtbarkeit ist nicht l√§nger ein ‚ÄûNice-to-have‚Äú, sondern eine kritische F√§higkeit:

*   **Debugging und Root-Cause-Analyse**: Wenn ein Agent fehlschl√§gt oder unerwartete Ausgaben liefert, liefern Beobachtbarkeitstools die Traces, die ben√∂tigt werden, um die Fehlerquelle zu lokalisieren. Das ist besonders wichtig bei komplexen Agenten, die mehrere LLM-Aufrufe, Tool-Interaktionen und bedingte Logik enthalten k√∂nnen.
*   **Latenz- und Kostenmanagement**: KI-Agenten verlassen sich oft auf LLMs und andere externe APIs, die pro Token oder pro Aufruf abgerechnet werden. Beobachtbarkeit erm√∂glicht eine pr√§zise Verfolgung dieser Aufrufe und hilft dabei, Operationen zu identifizieren, die √ºberm√§√üig langsam oder teuer sind. Dadurch k√∂nnen Teams Prompts optimieren, effizientere Modelle w√§hlen oder Workflows neu gestalten, um Betriebskosten zu senken und eine gute Benutzererfahrung sicherzustellen.
*   **Vertrauen, Sicherheit und Compliance**: In vielen Anwendungen ist es wichtig sicherzustellen, dass Agenten sich sicher und ethisch verhalten. Beobachtbarkeit liefert eine Pr√ºfspur der Aktionen und Entscheidungen des Agenten. Diese kann verwendet werden, um Probleme wie Prompt-Injection, die Erzeugung sch√§dlicher Inhalte oder den unsachgem√§√üen Umgang mit personenbezogenen Daten (PII) zu erkennen und zu mindern. Beispielsweise kann man Traces √ºberpr√ºfen, um zu verstehen, warum ein Agent eine bestimmte Antwort gegeben oder ein bestimmtes Tool verwendet hat.
*   **Kontinuierliche Verbesserungszyklen**: Beobachtbarkeitsdaten bilden die Grundlage eines iterativen Entwicklungsprozesses. Durch die √úberwachung der Agentenleistung in der realen Welt k√∂nnen Teams Bereiche f√ºr Verbesserungen identifizieren, Daten f√ºr das Fine-Tuning sammeln und die Auswirkungen von √Ñnderungen validieren. Dies schafft einen Feedback-Loop, bei dem Erkenntnisse aus der Online-Evaluation die Offline-Experimente und Verfeinerungen informieren, was zu einer schrittweisen Verbesserung der Agentenleistung f√ºhrt.

## Wichtige Metriken zur √úberwachung

Um das Verhalten von Agenten zu √ºberwachen und zu verstehen, sollten eine Reihe von Metriken und Signalen verfolgt werden. Die spezifischen Metriken k√∂nnen je nach Zweck des Agenten variieren, einige sind jedoch universell wichtig.

Hier sind einige der am h√§ufigsten von Beobachtbarkeitstools √ºberwachten Metriken:

**Latenz:** Wie schnell reagiert der Agent? Lange Wartezeiten beeintr√§chtigen die Benutzererfahrung. Sie sollten die Latenz f√ºr Aufgaben und einzelne Schritte messen, indem Sie Agentenl√§ufe nachverfolgen. Beispielsweise k√∂nnte ein Agent, der f√ºr alle Modellaufrufe 20 Sekunden ben√∂tigt, durch die Verwendung eines schnelleren Modells oder durch paralleles Ausf√ºhren von Modellaufrufen beschleunigt werden.

**Kosten:** Welche Kosten fallen pro Agentenlauf an? KI-Agenten verlassen sich auf LLM-Aufrufe, die pro Token oder externe APIs abgerechnet werden. H√§ufige Tool-Nutzung oder mehrere Prompts k√∂nnen die Kosten schnell in die H√∂he treiben. Wenn ein Agent beispielsweise ein LLM f√ºnfmal aufruft, um eine marginale Qualit√§tsverbesserung zu erzielen, m√ºssen Sie beurteilen, ob die Kosten gerechtfertigt sind oder ob Sie die Anzahl der Aufrufe reduzieren oder ein g√ºnstigeres Modell verwenden k√∂nnen. Echtzeit√ºberwachung kann auch helfen, unerwartete Spitzen zu identifizieren (z. B. Bugs, die zu √ºberm√§√üigen API-Schleifen f√ºhren).

**Request-Fehler:** Wie viele Anfragen sind fehlgeschlagen? Das kann API-Fehler oder fehlgeschlagene Tool-Aufrufe umfassen. Um Ihren Agenten in der Produktion robuster gegen solche Fehler zu machen, k√∂nnen Sie Fallbacks oder Retries einrichten. Z. B. wenn LLM-Anbieter A ausf√§llt, wechseln Sie als Backup zu LLM-Anbieter B.

**Benutzerfeedback:** Die Implementierung direkter Benutzerevaluationen liefert wertvolle Einblicke. Dies kann explizite Bewertungen (üëçDaumen hoch/üëéDaumen runter, ‚≠ê1-5 Sterne) oder textuelle Kommentare umfassen. Konsistent negatives Feedback sollte Sie alarmieren, da dies ein Zeichen daf√ºr ist, dass der Agent nicht wie erwartet funktioniert.

**Implizites Benutzerfeedback:** Benutzerverhalten liefert auch ohne explizite Bewertungen indirektes Feedback. Dazu geh√∂ren sofortige Umformulierungen von Fragen, wiederholte Anfragen oder das Klicken auf eine Wiederholen-Schaltfl√§che. Z. B. wenn Sie feststellen, dass Benutzer dieselbe Frage wiederholt stellen, ist das ein Zeichen daf√ºr, dass der Agent nicht wie erwartet funktioniert.

**Genauigkeit:** Wie h√§ufig liefert der Agent korrekte oder gew√ºnschte Ausgaben? Die Definition von Genauigkeit variiert (z. B. Korrektheit bei Probleml√∂sungen, Genauigkeit der Informationsbeschaffung, Benutzerzufriedenheit). Der erste Schritt ist zu definieren, wie Erfolg f√ºr Ihren Agenten aussieht. Sie k√∂nnen die Genauigkeit √ºber automatisierte Pr√ºfungen, Evaluationsscores oder Task-Abschluss-Auszeichnungen verfolgen. Beispielsweise durch Markieren von Traces als ‚Äûsucceeded‚Äú oder ‚Äûfailed‚Äú.

**Automatisierte Evaluationsmetriken:** Sie k√∂nnen auch automatisierte Evals einrichten. Beispielsweise k√∂nnen Sie ein LLM verwenden, um die Ausgabe des Agenten zu bewerten, z. B. ob sie hilfreich, korrekt oder nicht ist. Es gibt auch mehrere Open-Source-Bibliotheken, die Ihnen helfen, verschiedene Aspekte des Agenten zu bewerten. Z. B. [RAGAS](https://docs.ragas.io/) f√ºr RAG-Agenten oder [LLM Guard](https://llm-guard.com/), um sch√§dliche Sprache oder Prompt-Injection zu erkennen.

In der Praxis bietet eine Kombination dieser Metriken die beste Abdeckung f√ºr den Zustand eines KI-Agenten. In diesem Kapitel zeigen wir Ihnen im [Beispiel-Notebook](./code_samples/10_autogen_evaluation.ipynb), wie diese Metriken in realen Beispielen aussehen, aber zuerst lernen wir, wie ein typischer Evaluationsworkflow aussieht.

## Instrumentieren Sie Ihren Agenten

Um Tracing-Daten zu sammeln, m√ºssen Sie Ihren Code instrumentieren. Ziel ist es, den Agenten-Code so zu instrumentieren, dass Traces und Metriken erzeugt werden, die von einer Beobachtbarkeitsplattform erfasst, verarbeitet und visualisiert werden k√∂nnen.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) hat sich als Industriestandard f√ºr LLM-Beobachtbarkeit etabliert. Es bietet ein Set von APIs, SDKs und Tools zur Erzeugung, Sammlung und zum Export von Telemetriedaten.

Es gibt viele Instrumentierungsbibliotheken, die vorhandene Agenten-Frameworks umh√ºllen und das einfache Exportieren von OpenTelemetry-Spans an ein Beobachtbarkeits-Tool erm√∂glichen. Nachfolgend ein Beispiel zur Instrumentierung eines AutoGen-Agenten mit der [OpenLit-Instrumentierungsbibliothek](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

Das [Beispiel-Notebook](./code_samples/10_autogen_evaluation.ipynb) in diesem Kapitel demonstriert, wie Sie Ihren AutoGen-Agenten instrumentieren.

**Manuelle Span-Erstellung:** W√§hrend Instrumentierungsbibliotheken eine gute Basis liefern, gibt es oft F√§lle, in denen detailliertere oder benutzerdefinierte Informationen ben√∂tigt werden. Sie k√∂nnen Spans manuell erstellen, um benutzerdefinierte Anwendungslogik hinzuzuf√ºgen. Wichtiger noch: Sie k√∂nnen automatisch oder manuell erstellte Spans mit benutzerdefinierten Attributen (auch als Tags oder Metadaten bekannt) anreichern. Diese Attribute k√∂nnen gesch√§ftsspezifische Daten, Zwischenberechnungen oder jeden Kontext enthalten, der f√ºr Debugging oder Analyse n√ºtzlich sein k√∂nnte, wie z. B. `user_id`, `session_id` oder `model_version`.

Beispiel zur manuellen Erstellung von Traces und Spans mit dem [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Agenten-Evaluation

Beobachtbarkeit liefert uns Metriken, aber Evaluation ist der Prozess der Analyse dieser Daten (und der Durchf√ºhrung von Tests), um zu bestimmen, wie gut ein KI-Agent arbeitet und wie er verbessert werden kann. Anders gesagt: Sobald Sie diese Traces und Metriken haben, wie nutzen Sie sie, um den Agenten zu bewerten und Entscheidungen zu treffen?

Regelm√§√üige Evaluation ist wichtig, da KI-Agenten oft nicht-deterministisch sind und sich entwickeln k√∂nnen (durch Updates oder driftendes Modellverhalten) ‚Äì ohne Evaluation w√ºrden Sie nicht wissen, ob Ihr ‚Äûsmarter Agent‚Äú tats√§chlich seine Aufgabe gut erf√ºllt oder ob er sich verschlechtert hat.

Es gibt zwei Kategorien von Evaluationen f√ºr KI-Agenten: **Online-Evaluation** und **Offline-Evaluation**. Beide sind wertvoll und erg√§nzen sich gegenseitig. √úblicherweise beginnen wir mit der Offline-Evaluation, da dies der Mindestschritt ist, bevor ein Agent bereitgestellt wird.

### Offline-Evaluation

![Datensatzeintr√§ge in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Dies beinhaltet die Evaluierung des Agenten in einer kontrollierten Umgebung, typischerweise unter Verwendung von Testdatens√§tzen und nicht mit Live-Benutzeranfragen. Sie verwenden kuratierte Datens√§tze, bei denen Sie wissen, welche Ausgabe oder welches Verhalten erwartet wird, und f√ºhren dann Ihren Agenten darauf aus.

Wenn Sie z. B. einen Agenten f√ºr Mathematiktextaufgaben gebaut haben, k√∂nnten Sie einen [Testdatensatz](https://huggingface.co/datasets/gsm8k) mit 100 Aufgaben und bekannten L√∂sungen haben. Offline-Evaluation wird oft w√§hrend der Entwicklung durchgef√ºhrt (und kann Teil von CI/CD-Pipelines sein), um Verbesserungen zu √ºberpr√ºfen oder Regressionen vorzubeugen. Der Vorteil ist, dass sie **wiederholbar ist und Sie klare Genauigkeitsmetriken erhalten, da Sie die Ground-Truth haben**. Sie k√∂nnten auch Benutzeranfragen simulieren und die Antworten des Agenten mit idealen Antworten abgleichen oder automatisierte Metriken wie oben beschrieben verwenden.

Die zentrale Herausforderung bei der Offline-Eval besteht darin, sicherzustellen, dass Ihr Testdatensatz umfassend bleibt und relevant ist ‚Äì der Agent k√∂nnte auf einem festen Testset gut abschneiden, aber in der Produktion sehr unterschiedliche Anfragen erhalten. Daher sollten Sie Testsets mit neuen Randf√§llen und Beispielen aktualisiert halten, die reale Szenarien widerspiegeln. Eine Mischung aus kleinen ‚ÄûSmoke-Test‚Äú-F√§llen und gr√∂√üeren Evaluationssets ist n√ºtzlich: Kleine Sets f√ºr schnelle Checks und gr√∂√üere f√ºr breitere Leistungsmetriken.

### Online-Evaluation

![√úbersicht Beobachtbarkeitsmetriken](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Dies bezieht sich auf die Evaluierung des Agenten in einer Live-, realen Umgebung, d. h. w√§hrend der tats√§chlichen Nutzung in der Produktion. Online-Evaluation umfasst die √úberwachung der Agentenleistung bei echten Benutzerinteraktionen und die kontinuierliche Analyse der Ergebnisse.

Beispielsweise k√∂nnten Sie Erfolgsraten, Benutzerzufriedenheitswerte oder andere Metriken im Live-Traffic verfolgen. Der Vorteil der Online-Evaluation ist, dass sie **Dinge erfasst, die Sie in einer Laborumgebung m√∂glicherweise nicht vorhersehen** ‚Äì Sie k√∂nnen Modell-Drift im Laufe der Zeit beobachten (wenn die Wirksamkeit des Agenten nachl√§sst, weil sich Eingabeprofile √§ndern) und unerwartete Anfragen oder Situationen auffangen, die nicht in Ihren Testdaten enthalten waren. Sie liefert ein echtes Bild davon, wie sich der Agent in freier Wildbahn verh√§lt.

Online-Evaluation umfasst oft das Sammeln impliziten und expliziten Benutzerfeedbacks, wie bereits besprochen, und eventuell das Durchf√ºhren von Shadow-Tests oder A/B-Tests (bei denen eine neue Version des Agenten parallel l√§uft, um sie mit der alten zu vergleichen). Die Herausforderung besteht darin, dass es schwierig sein kann, zuverl√§ssige Labels oder Scores f√ºr Live-Interaktionen zu erhalten ‚Äì Sie m√ºssen sich m√∂glicherweise auf Benutzerfeedback oder Downstream-Metriken st√ºtzen (z. B. hat der Benutzer das Ergebnis angeklickt?).

### Kombination der beiden

Online- und Offline-Evaluationen schlie√üen einander nicht aus; sie erg√§nzen sich stark. Erkenntnisse aus dem Online-Monitoring (z. B. neue Arten von Benutzeranfragen, bei denen der Agent schlecht abschneidet) k√∂nnen zur Erweiterung und Verbesserung der Offline-Testdatens√§tze verwendet werden. Umgekehrt k√∂nnen Agenten, die in Offline-Tests gut abschneiden, mit h√∂herer Zuversicht in Produktion bereitgestellt und online √ºberwacht werden.

Tats√§chlich √ºbernehmen viele Teams eine Schleife:

_evaluieren offline -> bereitstellen -> online √ºberwachen -> neue Fehlf√§lle sammeln -> zum Offline-Datensatz hinzuf√ºgen -> Agent verfeinern -> wiederholen_.

## H√§ufige Probleme

Beim Einsatz von KI-Agenten in der Produktion k√∂nnen verschiedene Herausforderungen auftreten. Hier sind einige h√§ufige Probleme und m√∂gliche L√∂sungen:

| **Problem**    | **M√∂gliche L√∂sung**   |
| ------------- | ------------------ |
| KI-Agent erf√ºllt Aufgaben nicht konsistent | - Verfeinern Sie den Prompt f√ºr den KI-Agenten; seien Sie klar in den Zielen.<br>- Identifizieren Sie, wo das Aufteilen der Aufgaben in Unteraufgaben und deren Bearbeitung durch mehrere Agenten helfen kann. |
| KI-Agent ger√§t in Endlosschleifen  | - Stellen Sie sicher, dass Sie klare Abbruchbedingungen haben, damit der Agent wei√ü, wann der Prozess zu stoppen ist.<br>- F√ºr komplexe Aufgaben, die Schlussfolgern und Planung erfordern, verwenden Sie ein gr√∂√üeres Modell, das auf reasoning-Aufgaben spezialisiert ist. |
| Tool-Aufrufe des KI-Agenten performen nicht gut   | - Testen und validieren Sie die Ausgabe des Tools au√üerhalb des Agentensystems.<br>- Verfeinern Sie die definierten Parameter, Prompts und die Benennung der Tools.  |
| Multi-Agenten-System verh√§lt sich inkonsistent | - Verfeinern Sie die Prompts f√ºr jeden Agenten, damit sie spezifisch und unterscheidbar sind.<br>- Bauen Sie ein hierarchisches System mit einem ‚ÄûRouting‚Äú- oder Controller-Agenten auf, der bestimmt, welcher Agent der richtige ist. |

Viele dieser Probleme lassen sich mit Beobachtbarkeit effektiver identifizieren. Die zuvor besprochenen Traces und Metriken helfen dabei, genau den Punkt im Agenten-Workflow zu lokalisieren, an dem Probleme auftreten, was Debugging und Optimierung deutlich effizienter macht.

## Kostenmanagement
Hier sind einige Strategien, um die Kosten f√ºr die Bereitstellung von KI-Agenten in der Produktion zu verwalten:

**Verwendung kleinerer Modelle:** Small Language Models (SLMs) k√∂nnen in bestimmten agentischen Anwendungsf√§llen gute Leistungen erbringen und die Kosten deutlich senken. Wie bereits erw√§hnt, ist der Aufbau eines Evaluierungssystems zur Bestimmung und zum Vergleich der Leistung im Vergleich zu gr√∂√üeren Modellen der beste Weg, um zu verstehen, wie gut ein SLM in Ihrem Anwendungsfall abschneiden wird. Ziehen Sie in Betracht, SLMs f√ºr einfachere Aufgaben wie Intent-Klassifikation oder Parameterextraktion zu verwenden und gr√∂√üere Modelle f√ºr komplexes Schlussfolgern vorzubehalten.

**Verwendung eines Router-Modells:** Eine √§hnliche Strategie besteht darin, eine Vielfalt von Modellen und Gr√∂√üen zu verwenden. Sie k√∂nnen ein LLM/SLM oder eine serverlose Funktion nutzen, um Anfragen je nach Komplexit√§t an die am besten geeigneten Modelle zu leiten. Dies hilft ebenfalls, die Kosten zu senken und gleichzeitig die Leistung bei den passenden Aufgaben sicherzustellen. Beispielsweise leiten Sie einfache Abfragen an kleinere, schnellere Modelle weiter und verwenden teure gro√üe Modelle nur f√ºr komplexe Schlussfolgerungsaufgaben.

**Zwischenspeichern von Antworten:** Das Identifizieren h√§ufiger Anfragen und Aufgaben und das Bereitstellen der Antworten, bevor sie durch Ihr agentisches System laufen, ist ein guter Weg, um das Volumen √§hnlicher Anfragen zu reduzieren. Sie k√∂nnen sogar einen Ablauf implementieren, um zu erkennen, wie √§hnlich eine Anfrage Ihren zwischengespeicherten Anfragen mithilfe einfacherer KI-Modelle ist. Diese Strategie kann die Kosten f√ºr h√§ufig gestellte Fragen oder g√§ngige Workflows erheblich reduzieren.

## Schauen wir uns an, wie das in der Praxis funktioniert

In the [example notebook of this section](./code_samples/10_autogen_evaluation.ipynb), wir werden Beispiele daf√ºr sehen, wie wir Observability-Tools nutzen k√∂nnen, um unseren Agenten zu √ºberwachen und zu bewerten.

### Haben Sie weitere Fragen zu KI-Agenten in der Produktion?

Join the [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) to meet with other learners, attend office hours and get your AI Agents questions answered.

## Vorherige Lektion

[Metakognition-Designmuster](../09-metacognition/README.md)

## N√§chste Lektion

[Agentische Protokolle](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Haftungsausschluss:
Dieses Dokument wurde mit dem KI‚Äë√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Die urspr√ºngliche Fassung des Dokuments in der Ausgangssprache ist als ma√ügebliche Quelle zu betrachten. Bei kritischen Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Verwendung dieser √úbersetzung ergeben.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->