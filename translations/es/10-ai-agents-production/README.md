# Agentes de IA en Producci√≥n: Observabilidad y Evaluaci√≥n

[![Agentes de IA en Producci√≥n](../../../translated_images/es/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

A medida que los agentes de IA pasan de prototipos experimentales a aplicaciones del mundo real, la capacidad de comprender su comportamiento, supervisar su rendimiento y evaluar sistem√°ticamente sus salidas se vuelve importante.

## Objetivos de aprendizaje

Despu√©s de completar esta lecci√≥n, sabr√°s c√≥mo/entender√°s:
- Conceptos clave de observabilidad y evaluaci√≥n de agentes
- T√©cnicas para mejorar el rendimiento, los costos y la efectividad de los agentes
- Qu√© y c√≥mo evaluar sistem√°ticamente tus agentes de IA
- C√≥mo controlar los costos al desplegar agentes de IA en producci√≥n
- C√≥mo instrumentar agentes creados con AutoGen

El objetivo es equiparte con el conocimiento para transformar tus agentes "caja negra" en sistemas transparentes, manejables y fiables.

_**Nota:** Es importante desplegar Agentes de IA que sean seguros y confiables. Consulta tambi√©n la lecci√≥n [Building Trustworthy AI Agents](./06-building-trustworthy-agents/README.md)._

## Trazas y spans

Las herramientas de observabilidad como [Langfuse](https://langfuse.com/) o [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) suelen representar las ejecuciones de agentes como trazas y spans.

- **Trace** representa una tarea completa del agente desde el inicio hasta el final (como manejar una consulta de usuario).
- **Spans** son pasos individuales dentro de la traza (como llamar a un modelo de lenguaje o recuperar datos).

![√Årbol de trazas en Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Sin observabilidad, un agente de IA puede sentirse como una "caja negra": su estado interno y su razonamiento son opacos, lo que dificulta diagnosticar problemas u optimizar el rendimiento. Con observabilidad, los agentes se convierten en "cajas de cristal", ofreciendo transparencia que es vital para generar confianza y asegurar que operen seg√∫n lo previsto. 

## Por qu√© la observabilidad importa en entornos de producci√≥n

La transici√≥n de agentes de IA a entornos de producci√≥n introduce un nuevo conjunto de desaf√≠os y requisitos. La observabilidad deja de ser algo "agradable de tener" y se convierte en una capacidad cr√≠tica:

*   **Depuraci√≥n y an√°lisis de causa ra√≠z**: Cuando un agente falla o produce una salida inesperada, las herramientas de observabilidad proporcionan las trazas necesarias para localizar la fuente del error. Esto es especialmente importante en agentes complejos que pueden implicar m√∫ltiples llamadas a LLM, interacciones con herramientas y l√≥gica condicional.
*   **Gesti√≥n de latencia y costos**: Los agentes de IA a menudo dependen de LLMs y otras API externas que se facturan por token o por llamada. La observabilidad permite un seguimiento preciso de estas llamadas, ayudando a identificar operaciones que son excesivamente lentas o caras. Esto permite a los equipos optimizar prompts, seleccionar modelos m√°s eficientes o redise√±ar flujos de trabajo para gestionar los costos operativos y asegurar una buena experiencia de usuario.
*   **Confianza, seguridad y cumplimiento**: En muchas aplicaciones, es importante asegurar que los agentes se comporten de manera segura y √©tica. La observabilidad proporciona una pista de auditor√≠a de las acciones y decisiones del agente. Esto puede usarse para detectar y mitigar problemas como la inyecci√≥n de prompts, la generaci√≥n de contenido da√±ino o el manejo inadecuado de informaci√≥n de identificaci√≥n personal (PII). Por ejemplo, puedes revisar trazas para entender por qu√© un agente proporcion√≥ cierta respuesta o us√≥ una herramienta espec√≠fica.
*   **Bucles de mejora continua**: Los datos de observabilidad son la base de un proceso de desarrollo iterativo. Al monitorizar c√≥mo se desempe√±an los agentes en el mundo real, los equipos pueden identificar √°reas de mejora, recopilar datos para el ajuste fino de modelos y validar el impacto de los cambios. Esto crea un bucle de retroalimentaci√≥n donde las ideas de producci√≥n obtenidas a partir de la evaluaci√≥n en l√≠nea informan la experimentaci√≥n y el refinamiento fuera de l√≠nea, llevando a un rendimiento progresivamente mejor del agente.

## M√©tricas clave para supervisar

Para monitorizar y comprender el comportamiento del agente, debe rastrearse una variedad de m√©tricas y se√±ales. Aunque las m√©tricas espec√≠ficas pueden variar seg√∫n el prop√≥sito del agente, algunas son universalmente importantes.

Aqu√≠ est√°n algunas de las m√©tricas m√°s comunes que las herramientas de observabilidad monitorizan:

**Latencia:** ¬øQu√© tan r√°pido responde el agente? Los tiempos de espera largos impactan negativamente la experiencia del usuario. Debes medir la latencia de las tareas y de pasos individuales trazando las ejecuciones del agente. Por ejemplo, un agente que tarda 20 segundos en todas las llamadas al modelo podr√≠a acelerarse usando un modelo m√°s r√°pido o ejecutando las llamadas al modelo en paralelo.

**Costos:** ¬øCu√°l es el gasto por ejecuci√≥n del agente? Los agentes de IA dependen de llamadas a LLM facturadas por token o de APIs externas. El uso frecuente de herramientas o m√∫ltiples prompts puede aumentar r√°pidamente los costos. Por ejemplo, si un agente llama a un LLM cinco veces por una mejora marginal de calidad, debes evaluar si el costo se justifica o si podr√≠as reducir el n√∫mero de llamadas o usar un modelo m√°s barato. La monitorizaci√≥n en tiempo real tambi√©n puede ayudar a identificar picos inesperados (por ejemplo, bugs que causan bucles excesivos de API).

**Errores de solicitudes:** ¬øCu√°ntas solicitudes fall√≥ el agente? Esto puede incluir errores de API o llamadas a herramientas fallidas. Para hacer tu agente m√°s robusto ante estos fallos en producci√≥n, puedes configurar alternativas o reintentos. Por ejemplo, si el proveedor de LLM A falla, cambias al proveedor de LLM B como respaldo.

**Retroalimentaci√≥n del usuario:** Implementar evaluaciones directas de los usuarios proporciona informaci√≥n valiosa. Esto puede incluir valoraciones expl√≠citas (üëçpulgar arriba/üëépulgar abajo, ‚≠ê1-5 estrellas) o comentarios textuales. La retroalimentaci√≥n negativa consistente debe alertarte ya que es una se√±al de que el agente no est√° funcionando como se espera. 

**Retroalimentaci√≥n impl√≠cita del usuario:** El comportamiento del usuario ofrece retroalimentaci√≥n indirecta incluso sin valoraciones expl√≠citas. Esto puede incluir reformulaci√≥n inmediata de preguntas, consultas repetidas o hacer clic en un bot√≥n de reintento. Por ejemplo, si ves que los usuarios preguntan repetidamente lo mismo, es una se√±al de que el agente no est√° funcionando como se espera.

**Precisi√≥n:** ¬øCon qu√© frecuencia produce el agente salidas correctas o deseables? Las definiciones de precisi√≥n var√≠an (por ejemplo, correcci√≥n en la resoluci√≥n de problemas, precisi√≥n en la recuperaci√≥n de informaci√≥n, satisfacci√≥n del usuario). El primer paso es definir c√≥mo se ve el √©xito para tu agente. Puedes rastrear la precisi√≥n mediante comprobaciones automatizadas, puntuaciones de evaluaci√≥n o etiquetas de finalizaci√≥n de tareas. Por ejemplo, marcar trazas como "succeeded" o "failed". 

**M√©tricas de evaluaci√≥n automatizada:** Tambi√©n puedes configurar evaluaciones autom√°ticas. Por ejemplo, puedes usar un LLM para puntuar la salida del agente, p. ej. si es √∫til, precisa o no. Tambi√©n existen varias bibliotecas de c√≥digo abierto que te ayudan a puntuar diferentes aspectos del agente. Por ejemplo, [RAGAS](https://docs.ragas.io/) para agentes RAG o [LLM Guard](https://llm-guard.com/) para detectar lenguaje da√±ino o inyecci√≥n de prompts. 

En la pr√°ctica, una combinaci√≥n de estas m√©tricas ofrece la mejor cobertura de la salud de un agente de IA. En el [notebook de ejemplo](./code_samples/10_autogen_evaluation.ipynb) de este cap√≠tulo, te mostraremos c√≥mo se ven estas m√©tricas en ejemplos reales, pero primero aprenderemos c√≥mo es un flujo de evaluaci√≥n t√≠pico.

## Instrumenta tu agente

Para recopilar datos de trazado, necesitar√°s instrumentar tu c√≥digo. El objetivo es instrumentar el c√≥digo del agente para emitir trazas y m√©tricas que puedan ser capturadas, procesadas y visualizadas por una plataforma de observabilidad.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) se ha consolidado como un est√°ndar de la industria para la observabilidad de LLM. Proporciona un conjunto de APIs, SDKs y herramientas para generar, recopilar y exportar datos de telemetr√≠a. 

Hay muchas bibliotecas de instrumentaci√≥n que envuelven frameworks de agentes existentes y facilitan la exportaci√≥n de spans de OpenTelemetry a una herramienta de observabilidad. A continuaci√≥n hay un ejemplo de instrumentaci√≥n de un agente AutoGen con la biblioteca de instrumentaci√≥n [OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

El [notebook de ejemplo](./code_samples/10_autogen_evaluation.ipynb) en este cap√≠tulo demostrar√° c√≥mo instrumentar tu agente AutoGen.

**Creaci√≥n manual de spans:** Mientras que las bibliotecas de instrumentaci√≥n proporcionan una buena base, a menudo hay casos donde se necesita informaci√≥n m√°s detallada o personalizada. Puedes crear spans manualmente para a√±adir l√≥gica de aplicaci√≥n personalizada. M√°s importante a√∫n, pueden enriquecer spans creados autom√°ticamente o manualmente con atributos personalizados (tambi√©n conocidos como tags o metadata). Estos atributos pueden incluir datos espec√≠ficos del negocio, c√°lculos intermedios o cualquier contexto que pueda ser √∫til para depuraci√≥n o an√°lisis, como `user_id`, `session_id` o `model_version`.

Ejemplo de creaci√≥n manual de trazas y spans con el [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3): 

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Evaluaci√≥n del agente

La observabilidad nos proporciona m√©tricas, pero la evaluaci√≥n es el proceso de analizar esos datos (y realizar pruebas) para determinar qu√© tan bien se desempe√±a un agente de IA y c√≥mo se puede mejorar. En otras palabras, una vez que tienes esas trazas y m√©tricas, ¬øc√≥mo las usas para juzgar al agente y tomar decisiones? 

La evaluaci√≥n regular es importante porque los agentes de IA suelen ser no deterministas y pueden evolucionar (mediante actualizaciones o deriva del comportamiento del modelo): sin evaluaci√≥n, no sabr√≠as si tu "agente inteligente" realmente est√° haciendo bien su trabajo o si ha empeorado.

Hay dos categor√≠as de evaluaciones para agentes de IA: **evaluaci√≥n en l√≠nea** y **evaluaci√≥n offline**. Ambas son valiosas y se complementan entre s√≠. Normalmente comenzamos con la evaluaci√≥n offline, ya que es el paso m√≠nimo necesario antes de desplegar cualquier agente.

### Evaluaci√≥n offline

![Elementos del conjunto de datos en Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Esto implica evaluar al agente en un entorno controlado, t√≠picamente usando conjuntos de prueba, no consultas de usuarios en vivo. Utilizas conjuntos de datos curados donde sabes cu√°l es la salida esperada o el comportamiento correcto, y luego ejecutas tu agente sobre ellos. 

Por ejemplo, si construiste un agente para resolver problemas matem√°ticos de enunciado, podr√≠as tener un [conjunto de prueba](https://huggingface.co/datasets/gsm8k) de 100 problemas con respuestas conocidas. La evaluaci√≥n offline se realiza a menudo durante el desarrollo (y puede ser parte de pipelines de CI/CD) para comprobar mejoras o proteger contra regresiones. El beneficio es que es **repetible y puedes obtener m√©tricas claras de precisi√≥n ya que tienes la verdad de referencia**. Tambi√©n podr√≠as simular consultas de usuarios y medir las respuestas del agente frente a respuestas ideales o usar m√©tricas automatizadas como se describi√≥ arriba. 

El desaf√≠o clave de la evaluaci√≥n offline es asegurar que tu conjunto de pruebas sea exhaustivo y permanezca relevante: el agente puede funcionar bien en un conjunto de pruebas fijo pero encontrarse con consultas muy diferentes en producci√≥n. Por lo tanto, debes mantener los conjuntos de prueba actualizados con nuevos casos l√≠mite y ejemplos que reflejen escenarios del mundo real. Una mezcla de peque√±os casos de "smoke test" y conjuntos de evaluaci√≥n m√°s grandes es √∫til: conjuntos peque√±os para comprobaciones r√°pidas y m√°s grandes para m√©tricas de rendimiento m√°s amplias.

### Evaluaci√≥n en l√≠nea

![Resumen de m√©tricas de observabilidad](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Esto se refiere a evaluar al agente en un entorno en vivo y del mundo real, es decir, durante el uso real en producci√≥n. La evaluaci√≥n en l√≠nea implica monitorizar el rendimiento del agente en interacciones reales de usuarios y analizar los resultados de forma continua. 

Por ejemplo, podr√≠as rastrear tasas de √©xito, puntuaciones de satisfacci√≥n del usuario u otras m√©tricas en tr√°fico en vivo. La ventaja de la evaluaci√≥n en l√≠nea es que **captura cosas que podr√≠as no anticipar en un entorno de laboratorio**: puedes observar la deriva del modelo a lo largo del tiempo (si la efectividad del agente se degrada a medida que cambian los patrones de entrada) y detectar consultas o situaciones inesperadas que no estaban en tus datos de prueba. Proporciona una imagen real de c√≥mo se comporta el agente en el entorno real. 

La evaluaci√≥n en l√≠nea a menudo implica recopilar retroalimentaci√≥n impl√≠cita y expl√≠cita de los usuarios, como se discuti√≥, y posiblemente ejecutar pruebas en sombras o pruebas A/B (donde una nueva versi√≥n del agente se ejecuta en paralelo para comparar con la antigua). El desaf√≠o es que puede ser complicado obtener etiquetas o puntuaciones fiables para interacciones en vivo: podr√≠as depender de la retroalimentaci√≥n del usuario o de m√©tricas downstream (como si el usuario hizo clic en el resultado). 

### Combinando ambas

Las evaluaciones en l√≠nea y offline no son mutuamente excluyentes; se complementan mucho entre s√≠. Las ideas de la monitorizaci√≥n en l√≠nea (por ejemplo, nuevos tipos de consultas de usuarios donde el agente rinde mal) pueden usarse para aumentar y mejorar los conjuntos de prueba offline. A la inversa, los agentes que funcionan bien en pruebas offline pueden desplegarse con m√°s confianza y monitorizarse en l√≠nea. 

De hecho, muchos equipos adoptan un bucle:

_evaluar offline -> desplegar -> monitorizar online -> recopilar nuevos casos de fallo -> a√±adir al conjunto de datos offline -> refinar el agente -> repetir_.

## Problemas comunes

Al desplegar agentes de IA en producci√≥n, puedes encontrar varios desaf√≠os. Aqu√≠ hay algunos problemas comunes y sus posibles soluciones:

| **Issue**    | **Potential Solution**   |
| ------------- | ------------------ |
| AI Agent not performing tasks consistently | - Refina el prompt dado al Agente de IA; s√© claro en los objetivos.<br>- Identifica d√≥nde dividir las tareas en subtareas y manejarlo por m√∫ltiples agentes puede ayudar. |
| AI Agent running into continuous loops  | - Aseg√∫rate de tener t√©rminos y condiciones de terminaci√≥n claros para que el Agente sepa cu√°ndo detener el proceso.<br>- Para tareas complejas que requieren razonamiento y planificaci√≥n, usa un modelo m√°s grande que est√© especializado en tareas de razonamiento. |
| AI Agent tool calls are not performing well   | - Prueba y valida la salida de la herramienta fuera del sistema del agente.<br>- Refina los par√°metros definidos, los prompts y la nomenclatura de las herramientas.  |
| Multi-Agent system not performing consistently | - Refina los prompts dados a cada agente para asegurarte de que sean espec√≠ficos y distintos entre s√≠.<br>- Construye un sistema jer√°rquico usando un agente "enrutador" o controlador para determinar cu√°l agente es el correcto. |

Muchos de estos problemas pueden identificarse de forma m√°s efectiva con la observabilidad en su lugar. Las trazas y m√©tricas que discutimos anteriormente ayudan a localizar exactamente d√≥nde en el flujo de trabajo del agente ocurren los problemas, haciendo que la depuraci√≥n y la optimizaci√≥n sean mucho m√°s eficientes.

## Gesti√≥n de costos
Aqu√≠ hay algunas estrategias para gestionar los costos de desplegar agentes de IA en producci√≥n:

**Usar modelos m√°s peque√±os:** Los Modelos de Lenguaje Peque√±os (SLMs) pueden desempe√±arse bien en ciertos casos de uso relacionados con agentes y reducir√°n significativamente los costos. Como se mencion√≥ anteriormente, construir un sistema de evaluaci√≥n para determinar y comparar el rendimiento frente a modelos m√°s grandes es la mejor manera de entender qu√© tan bien se desempe√±ar√° un SLM en tu caso de uso. Considera usar SLMs para tareas m√°s simples como clasificaci√≥n de intenciones o extracci√≥n de par√°metros, mientras reservas modelos m√°s grandes para razonamientos complejos.

**Usar un modelo enrutador:** Una estrategia similar es usar una diversidad de modelos y tama√±os. Puedes usar un LLM/SLM o una funci√≥n sin servidor para enrutar las solicitudes seg√∫n su complejidad hacia los modelos m√°s adecuados. Esto tambi√©n ayudar√° a reducir costos y a garantizar el rendimiento en las tareas correctas. Por ejemplo, enruta consultas simples a modelos m√°s peque√±os y r√°pidos, y utiliza modelos grandes y costosos solo para tareas de razonamiento complejo.

**Almacenamiento en cach√© de respuestas:** Identificar solicitudes y tareas comunes y proporcionar las respuestas antes de que pasen por tu sistema de agentes es una buena manera de reducir el volumen de solicitudes similares. Incluso puedes implementar un flujo para identificar cu√°n similar es una solicitud a tus solicitudes en cach√© usando modelos de IA m√°s b√°sicos. Esta estrategia puede reducir significativamente los costos para preguntas frecuentes o flujos de trabajo comunes.

## Veamos c√≥mo funciona esto en la pr√°ctica

En el [cuaderno de ejemplo de esta secci√≥n](./code_samples/10_autogen_evaluation.ipynb), veremos ejemplos de c√≥mo podemos usar herramientas de observabilidad para monitorizar y evaluar nuestro agente.


### ¬øTienes m√°s preguntas sobre agentes de IA en producci√≥n?

√önete al [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) para reunirte con otros estudiantes, asistir a horas de oficina y obtener respuestas a tus preguntas sobre agentes de IA.

## Lecci√≥n anterior

[Patr√≥n de dise√±o de metacognici√≥n](../09-metacognition/README.md)

## Siguiente lecci√≥n

[Protocolos para agentes](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Descargo de responsabilidad:
Este documento ha sido traducido utilizando el servicio de traducci√≥n por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por la exactitud, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por un humano. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->