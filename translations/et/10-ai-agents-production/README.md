# AI-agentide tootmine: j√§lgitavus ja hindamine

[![AI-agentide tootmine](../../../translated_images/et/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

Kui AI-agentid liiguvad eksperimenteerimisprotot√º√ºpide staadiumist reaalse maailma rakendusteni, muutub oluliseks nende k√§itumise m√µistmine, j√µudluse j√§lgimine ja v√§ljundite s√ºsteemne hindamine.

## √ïpieesm√§rgid

P√§rast selle tunni l√§bimist oskad/saad aru:
- Agendi j√§lgitavuse ja hindamise p√µhim√µistetest
- Tehnikatest, kuidas parandada agentide j√µudlust, kulusid ja t√µhusust
- Mida ja kuidas oma AI-agente s√ºsteemselt hinnata
- Kuidas kulusid kontrollida AI-agentide tootmisse juurutamisel
- Kuidas instrumeneerida AutoGeniga ehitatud agente

Eesm√§rk on anda sulle teadmised, kuidas muuta sinu "must kast" agentidest l√§bipaistvad, hallatavad ja usaldusv√§√§rsed s√ºsteemid.

_**M√§rkus:** On oluline juurutada AI-agente, kes on turvalised ja usaldusv√§√§rsed. Vaata ka √µppetundi [Usaldusv√§√§rsete AI-agentide loomine](./06-building-trustworthy-agents/README.md)._

## J√§ljed ja kestad

J√§lgitavust√∂√∂riistad nagu [Langfuse](https://langfuse.com/) v√µi [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) kujutavad tavaliselt agendi k√§ivitusi j√§lgedena ja kestadena.

- **J√§lg (trace)** t√§histab t√§ielikku agendi √ºlesannet algusest l√µpuni (n√§iteks kasutaja p√§ringu t√∂√∂tlemine).
- **Kestad (spans)** on √ºksikud sammud j√§ljes (n√§iteks keelemudeli kutsumine v√µi andmete p√§rimine).

![J√§lgede puu Langfuses](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Ilma j√§lgitavuseta v√µib AI-agent tunduda kui "must kast" ‚Äì selle sisemine olek ja m√µtlemine on h√§marad, mis teeb probleemide diagnoosimise ja j√µudluse optimeerimise raskeks. J√§lgitavusega muutuvad agentide "klaaskastideks", pakkudes l√§bipaistvust, mis on usalduse loomisel ja selle kindlustamisel, et nad t√∂√∂tavad kavandatult, h√§davajalik.

## Miks j√§lgitavus tootmiskeskkondades oluline on

AI-agentide √ºletoomine tootmiskeskkondadesse seab esile uued v√§ljakutsed ja n√µuded. J√§lgitavus ei ole enam lihtsalt hea lisav√µimalus, vaid kriitiline v√µimekus:

*   **T√µrkeotsing ja algp√µhjuse anal√º√ºs:** Kui agent eba√µnnestub v√µi toodab ootamatut v√§ljundit, annavad j√§lgitavust√∂√∂riistad vajalikud j√§ljed vea algp√µhjuse t√§psustamiseks. See on eriti oluline keerulistes agentides, mis v√µivad sisaldada mitmeid LLM-p√§ringuid, t√∂√∂riistade interaktsioone ja tingimusloogikat.
*   **Latentsus ja kulude haldamine:** AI-agentid toetuvad sageli LLM-idele ja teistele v√§listele API-dele, mille eest arveldatakse tokenite v√µi p√§ringute alusel. J√§lgitavus v√µimaldab t√§pselt j√§lgida neid p√§ringuid, aidates tuvastada liiga aeglasi v√µi kulukaid operatsioone. See v√µimaldab meeskondadel optimeerida p√§ringuid, valida efektiivsemaid mudeleid v√µi √ºmber kujundada t√∂√∂vooge kulude kontrollimiseks ja hea kasutajakogemuse tagamiseks.
*   **Usaldus, turvalisus ja n√µuetele vastavus:** Paljudes rakendustes on oluline tagada, et agent k√§ituks turvaliselt ja eetiliselt. J√§lgitavus annab auditeerimistee agendi tegevustest ja otsustest. Seda saab kasutada selliste probleemide avastamiseks ja leevendamiseks nagu sisendi s√ºstimine (prompt injection), kahjuliku sisu genereerimine v√µi isikuandmete v√§√§rkohtlemine. N√§iteks saad j√§lgi √ºle vaadata, et m√µista, miks agent andis teatud vastuse v√µi kasutas spetsiifilist t√∂√∂riista.
*   **J√§tkuvad parendusts√ºklid:** J√§lgatavuse andmed on iteratiivse arendusprotsessi alus. J√§lgides, kuidas agent maailmas toimib, saab meeskond tuvastada parenduskohti, koguda andmeid mudelite t√§psustamiseks ja valideerida muudatuste m√µju. See loob tagasisideloo, kus tootmiskeskkonna teadmised veebihindamisest suunavad offline katsetusi ja t√§iendamist, mis viib j√§rjest parema agentide j√µudluseni.

## Olulised m√µ√µdikud j√§lgimiseks

Agentide k√§itumise j√§lgimiseks ja m√µistmiseks tuleks j√§lgida mitmesuguseid m√µ√µdikuid ja signaale. Kuigi spetsiifilised m√µ√µdikud v√µivad erineda s√µltuvalt agendi eesm√§rgist, on m√µned universaalselt olulised.

Siin on m√µned k√µige levinumad m√µ√µdikud, mida j√§lgitavust√∂√∂riistad kontrollivad:

**Latentsus:** Kui kiiresti agent vastab? Pikk ooteaeg halvendab kasutajakogemust. Sa peaksid m√µ√µtma latentsust √ºlesannete ja √ºksikute sammude l√µikes, pidades silmas agendi k√§ivitusi. N√§iteks agent, kes kulutab k√µigile mudeli p√§ringutele 20 sekundit, v√µiks kiirendada, kasutades kiirust mudelit v√µi tehes mudelip√§ringuid paralleelselt.

**Kulud:** Mis on kulu √ºhe agendi k√§ivituse kohta? AI-agentid tuginevad tihti LLM-p√§ringutele, mis arveldatakse tokenite v√µi v√§liste API-de p√µhjal. Tihe t√∂√∂riistade kasutamine v√µi mitmed sisendid v√µivad kulusid kiiresti t√µsta. N√§iteks, kui agent kutsub LLM-i viis korda v√§hese kvaliteedit√µusu nimel, tuleb hinnata, kas kulu on √µigustatud v√µi saaks p√§ringute arvu v√§hendada v√µi odavamat mudelit kasutada. Reaalajas j√§lgimine aitab ka tuvastada ootamatuid h√ºppeid (nt vead, mis p√µhjustavad liigseid API-kordusi).

**P√§ringute vead:** Mitu p√§ringut agent eba√µnnestus? See v√µib h√µlmata API vigu v√µi t√∂√∂riistade eba√µnnestunud v√§ljakutseid. Selleks, et muuta agent tootmises vastupidavamaks, saad seada tagavaramehhanisme v√µi katsetada taask√§ivitust. N√§iteks, kui LLM-teenus A ei t√∂√∂ta, siis l√ºlitud LLM-teenusele B varundusena.

**Kasutajate tagasiside:** Otse kasutaja hinnangute kogumine annab v√§√§rtuslikke teadmisi. See v√µib olla selged hinnangud (üëçheaks/üëéhalb, ‚≠ê1-5 t√§rni) v√µi tekstilised kommentaarid. P√ºsiv negatiivne tagasiside peaks sind hoiatama, sest see n√§itab, et agent ei t√∂√∂ta ootusp√§raselt.

**Kaudne kasutajate tagasiside:** Kasutajate k√§itumine annab kaudset tagasisidet ilma selgete hinnanguteta. See v√µib olla k√ºsimuste √ºmber s√µnastamine kohe, korduvad p√§ringud v√µi taask√§ivituse nupule vajutamine. N√§iteks, kui n√§ed, et kasutajad k√ºsivad korduvalt sama k√ºsimust, on see m√§rk, et agent ei t√∂√∂ta ootusp√§raselt.

**T√§pneus:** Kui sageli toodab agent korrektseid v√µi soovitud tulemusi? T√§psuse m√§√§ratlused v√µivad erineda (nt probleemide lahendamise √µigsus, andmete t√§psus, kasutaja rahulolu). Esimene samm on m√§√§ratleda, milline edukas tulemus sinu agendi puhul v√§lja n√§eb. Sa saad j√§lgida t√§psust automaatkontrollide, hindamisskooride v√µi √ºlesannete t√§itmise siltide kaudu. N√§iteks m√§rgistades j√§ljed "√µnnestunud" v√µi "eba√µnnestunud".

**Automatiseeritud hindamism√µ√µdikud:** Sa v√µid kasutada ka automaatseid hindamisi. N√§iteks saad LLM-i kasutada agendi v√§ljundi hindamiseks, kas see on abistav, t√§pne v√µi mitte. On ka mitmeid avatud l√§htekoodiga raamatukogusid, mis aitavad hinnata agendi erinevaid aspekte. Nt [RAGAS](https://docs.ragas.io/) RAG-agentidele v√µi [LLM Guard](https://llm-guard.com/) kahjuliku keele v√µi sisendi s√ºstimiste avastamiseks.

Praktikas annab nende m√µ√µdikute kombinatsioon parima √ºlevaate AI-agendi seisundist. K√§esolevas peat√ºkis [n√§idism√§rkmikus](./code_samples/10_autogen_evaluation.ipynb) n√§itame, kuidas need m√µ√µdikud reaalses n√§ites v√§lja n√§evad, kuid k√µigepealt √µpime, milline n√§eb v√§lja t√º√ºpiline hindamistoiming.

## Instrumeneeri oma agent

J√§lgimisandmete kogumiseks on vaja instrumeneerida oma kood. Eesm√§rk on instrumeneerida agendi kood nii, et ta v√§ljastaks j√§lgi ja m√µ√µdikuid, mida saab j√§lgitavuse platvorm p√º√ºda, t√∂√∂delda ja visualiseerida.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) on kujunenud t√∂√∂stusharu standardiks LLM-j√§lgitavuse jaoks. See pakub API-sid, SDK-sid ja t√∂√∂riistu telemeetria andmete genereerimiseks, kogumiseks ja eksportimiseks.

On palju instrumendiraamatukogusid, mis m√§hivad olemasolevaid agendi raamistikke ja muudavad OpenTelemetry kestade eksportimise j√§lgitavust√∂√∂riistale lihtsaks. Allolev n√§ide demonstreerib AutoGen agendi instrumendiks tegemist kasutades [OpenLit instrumendiraamatukogu](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

Selles peat√ºkis olev [n√§idism√§rkmik](./code_samples/10_autogen_evaluation.ipynb) n√§itab, kuidas oma AutoGen agent instrumeneerida.

**Kestade k√§sitsi loomine:** Kuigi instrumendiraamatukogud annavad hea p√µhja, on olukordi, kus on vaja t√§psemat v√µi kohandatud infot. Sa saad k√§sitsi luua kestasid, et lisada kohandatud rakendusloogikat. K√µige olulisem on, et saab rikastada automaatselt v√µi k√§sitsi loodud kestasid kohandatud atribuutidega (tuntud ka kui sildid v√µi metaandmed). Need atribuudid v√µivad sisaldada √§ri-spetsiifilisi andmeid, vahepealseid arvutusi v√µi konteksti, mis v√µib olla kasulik silumiseks v√µi anal√º√ºsiks, n√§iteks `user_id`, `session_id` v√µi `model_version`.

N√§ide j√§lgede ja kestade k√§sitsi loomisest kasutades [Langfuse Python SDK-d](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Agendi hindamine

J√§lgitavus annab meile m√µ√µdikud, aga hindamine on see protsess, kus anal√º√ºsitakse neid andmeid (ja sooritatakse teste), et m√§√§rata, kui h√§sti AI-agent t√∂√∂tab ja kuidas seda saab parandada. Teisis√µnu, kui sul on need j√§ljed ja m√µ√µdikud olemas, kuidas sa neid kasutad, et hinnata agenti ja teha otsuseid?

Regulaarne hindamine on oluline, sest AI-agentid on tihti mitte-determineerivad ja v√µivad aja jooksul areneda (uuenduste v√µi mudeli k√§itumise k√µikumise kaudu) ‚Äì ilma hindamiseta sa ei teaks, kas sinu "tark agent" t√µesti t√§idab h√§sti oma √ºlesannet v√µi on ta taandunud.

AI-agentide hindamisi on kahte kategooriasse: **veebihindamine (online evaluation)** ja **offline hindamine**. M√µlemad on v√§√§rtuslikud ja t√§iendavad teineteist. Tavaliselt alustame offline hindamisest, sest see on minimaalne samm enne √ºksk√µik millise agendi juurutamist.

### Offline hindamine

![Andmekogumi √ºksused Langfuses](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

See t√§hendab agendi hindamist kontrollitud keskkonnas, tavaliselt testandmekogumitega, mitte otsekasutaja p√§ringutega. Sa kasutad kureeritud andmekogumeid, kus tead, milline on oodatav v√§ljund v√µi √µige k√§itumine, ja k√§ivitad oma agendi nende peal.

N√§iteks kui oled loonud matemaatika s√µnaprobleemide agendi, v√µib sul olla [testandmekogu](https://huggingface.co/datasets/gsm8k) 100 probleemiga, mille vastused on teada. Offline hindamist tehakse sageli arendamise ajal (ja see v√µib olla osa CI/CD t√∂√∂voogudest), et kontrollida parendusi v√µi kaitsta tagasiminekute eest. Eelis on see, et see on **korduv ja annab selged t√§psuse m√µ√µdikud, kuna on olemas t√µeandmed**. Sa v√µid ka simuleerida kasutajap√§ringuid ja m√µ√µta agendi vastuseid ideaalkommentaaride vastu v√µi kasutada automaatseid m√µ√µdikuid nagu eespool kirjeldatud.

Offline hindamise peamine v√§ljakutse on tagada, et sinu testandmekogu on p√µhjalik ja ajakohane ‚Äì agent v√µib h√§sti sooritada fikseeritud testkogul, kuid tootmises v√µib kokku puutuda hoopis erinevate p√§ringutega. Seet√µttu peaks testkogusid regulaarselt uuendama uutest piirsituatsioonidest ja reaalsete stsenaariumite n√§idetest. Kasulik on kasutada nii v√§ikeseid "suitsuteste" kui ka suuremaid hindamiskogumeid: v√§ikseid kiireteks kontrollideks ja suuremaid laiemate j√µudlusm√µ√µdikute jaoks.

### Veebihindamine (online evaluation)

![J√§lgitavuse m√µ√µdikute √ºlevaade](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

See t√§hendab agendi hindamist elavas, reaalajas keskkonnas, st tegeliku kasutamise ajal tootmises. Veebihindamine h√µlmab agendi j√µudluse j√§lgimist p√§ris kasutajate interaktsioonidel ja tulemuste pidevat anal√º√ºsi.

N√§iteks v√µid j√§lgida √µnnestumiste m√§√§ra, kasutajate rahulolu skoori v√µi teisi m√µ√µdikuid reaalajas liiklusel. Veebihindamise eelis on see, et see **p√º√ºab kinni asju, mida sa laboris oodata ei pruugi** ‚Äì sa saad j√§lgida mudelite k√§itumise muutusi aja jooksul (kui agendi t√µhusus halveneb, kuna sisendi mustrid muutuvad) ja tabada ootamatuid p√§ringuid v√µi olukordi, mis testandmekogus polnud. See annab t√µelise pildi sellest, kuidas agent looduses k√§itub.

Veebihindamine sisaldab sageli kaudse ja otsese kasutajate tagasiside kogumist, nagu mainitud, ning v√µib-olla varjuteste v√µi A/B-teste (kus uus agent k√§ivitub paralleelselt vana vastu v√µrdlemiseks). V√§ljakutse on, et reaalajas interaktsioonide jaoks v√µib olla keeruline saada usaldusv√§√§rseid silte v√µi skoorisid ‚Äì v√µid tugineda kasutajate tagasisidele v√µi edasistele m√µ√µdikutele (kas kasutaja klikkis tulemusele).

### Kahe meetodi kombineerimine

Veebihindamine ja offline hindamine ei v√§lista teineteist; need t√§iendavad suurep√§raselt √ºksteist. Veebij√§lgimise teadmisi (nt uued kasutajap√§ringute t√º√ºbid, millele agent halvasti vastab) saab kasutada offline testandmekogude t√§iustamiseks ja parandamiseks. Vastupidiselt saab offline testides h√§sti sooritanud agente siis kindlamalt juurutada ja reaalajas j√§lgida.

Tegelikult kasutavad paljud meeskonnad j√§rgmist ts√ºklit:

_offline hindamine -> juurutamine -> veebij√§lgimine -> uute eba√µnnestumiste kogumine -> lisamine offline andmestikku -> agendi t√§iendamine -> kordamine_.

## Levinud probleemid

AI-agentide tootmisse viimisel v√µid kokku puutuda erinevate v√§ljakutsetega. Siin on m√µned t√º√ºpilised probleemid ja v√µimalikud lahendused:

| **Probleem**    | **V√µimalik lahendus**   |
| ------------- | ------------------ |
| AI-agent ei t√§ida √ºlesandeid j√§rjepidevalt | - T√§iusta agendile antud sisendit; ole eesm√§rkides konkreetne.<br>- M√§√§ra, kus saab √ºlesandeid jaotada alam√ºlesanneteks ja las need t√§idavad mitmed agentid. |
| AI-agent j√§√§b l√µpututesse ts√ºklitesse  | - Veendu, et on selged protsessi l√µpetamise tingimused, et agent teaks, millal protsess l√µpetada.<br>- Keeruliste √ºlesannete puhul, mis n√µuavad m√µtlemist ja planeerimist, kasuta suuremat ja spetsialiseeritud mudelit. |
| AI-agendi t√∂√∂riistade v√§ljakutsed ei t√§ida h√§sti oma √ºlesandeid | - Testi ja valideeri t√∂√∂riistade v√§ljundit v√§ljaspool agenti.<br>- T√§iusta t√∂√∂riistadele antud parameetreid, sisendeid ja nimetusi.  |
| Mitmeagendi s√ºsteem ei t√∂√∂ta j√§rjepidevalt | - T√§iusta igale agendile antud sisendeid, et need oleksid spetsiifilised ja omavahel erinevad.<br>- Ehita hierarhiline s√ºsteem, kasutades "liigutaja" v√µi kontroller-agent, mis otsustab, milline agent on √µige. |

Paljusid neist probleemidest saab t√µhusamalt tuvastada j√§lgitavusega. Eespool arutletud j√§ljed ja m√µ√µdikud aitavad t√§pselt paikneda, kus agendi t√∂√∂voos probleemid tekivad, muutes silumise ja optimeerimise t√µhusamaks.

## Kulude juhtimine
Siin on m√µned strateegiad AI-agendi tootmisse juurutamise kulude haldamiseks:

**V√§iksemate mudelite kasutamine:** V√§ikesed keelemudelid (SLM-id) v√µivad teatud agentidega seotud kasutusjuhtudel h√§sti toimida ning v√§hendavad oluliselt kulusid. Nagu eelnevalt mainitud, on parim viis hinnata ja v√µrrelda suuremate mudelitega nende toimivust ehitada hindamiss√ºsteem, mis aitab m√µista, kui h√§sti SLM teie kasutusjuhtumil toimib. M√µelge SLM-ide kasutamisele lihtsamate √ºlesannete puhul, nagu kavatsuse klassifitseerimine v√µi parameetrite eraldamine, samal ajal kui keerulisema m√µtlemise jaoks kasutatakse suuremaid mudeleid.

**Marsruutimudeli kasutamine:** Sarnane strateegia on kasutada mitmekesisust mudelite ja suuruste osas. V√µite kasutada LLM-i/SLM-i v√µi serverivaba funktsiooni, et marsruutida p√§ringud keerukuse p√µhjal sobivaimatele mudelitele. See aitab samuti kulusid v√§hendada ja tagab soorituse √µigete √ºlesannete puhul. N√§iteks suunake lihtsad p√§ringud v√§iksemate ja kiiremate mudelite poole ning kasutage kulukaid suuri mudeleid vaid keerukate ratsionaalsete √ºlesannete jaoks.

**Vastuste vahem√§llu salvestamine:** √úldiste p√§ringute ja √ºlesannete tuvastamine ning nende vastuste ette pakkumine enne, kui nad agent-s√ºsteemi l√§bivad, on hea viis v√§hendada sarnaste p√§ringute hulka. V√µite isegi rakendada voogu, mis m√§√§rab, kui sarnane p√§ring on teie vahem√§llu salvestatud p√§ringutele, kasutades selleks lihtsamaid AI-mudeleid. See strateegia v√µib oluliselt v√§hendada kulusid sagedaste k√ºsimuste v√µi tavap√§raste t√∂√∂protsesside puhul.

## Vaatame, kuidas see praktikas toimib

Selles [sektsiooni n√§itenootebigis](./code_samples/10_autogen_evaluation.ipynb) n√§eme n√§iteid, kuidas saame kasutada j√§lgimisvahendeid, et meie agenti j√§lgida ja hinnata.


### Kas sul on veel k√ºsimusi AI agentide tootmises?

Liitu [Microsoft Foundry Discordiga](https://aka.ms/ai-agents/discord), et kohtuda teiste √µppuritega, osaleda t√∂√∂aegadel ja saada vastused AI Agentide k√ºsimustele.

## Eelmine √µppet√ºkk

[Metakognitsiooni disainimuster](../09-metacognition/README.md)

## J√§rgmine √µppet√ºkk

[Agent-seadustikud](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Vastutusest loobumine**:
See dokument on t√µlgitud kasutades tehisintellektil p√µhinevat t√µlketeenust [Co-op Translator](https://github.com/Azure/co-op-translator). Kuigi p√º√ºame t√§psust, palun arvestage, et automaatsel t√µlkel v√µivad esineda vead v√µi ebat√§psused. Originaaldokument oma emakeeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste ega valesti m√µistmiste eest.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->