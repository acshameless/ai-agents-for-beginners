[![Agentic RAG](../../../translated_images/fa/lesson-5-thumbnail.20ba9d0c0ae64fae.webp)](https://youtu.be/WcjAARvdL7I?si=BCgwjwFb2yCkEhR9)

> _(برای مشاهده ویدیوی این درس بر روی تصویر بالا کلیک کنید)_

# Agentic RAG

این درس یک مرور جامع بر روی Agentic Retrieval-Augmented Generation (Agentic RAG) ارائه می‌دهد، یک پارادایم نوظهور در هوش مصنوعی که در آن مدل‌های زبانی بزرگ (LLM) به‌صورت خودکار برنامه‌ریزی برای گام‌های بعدی خود را انجام می‌دهند و هم‌زمان اطلاعات را از منابع خارجی استخراج می‌کنند. بر خلاف الگوهای ایستا که ابتدا بازیابی می‌کنند و سپس می‌خوانند، Agentic RAG شامل فراخوان‌های تکراری به LLM است که با فراخوانی ابزار یا تابع و خروجی‌های ساختار یافته ترکیب می‌شود. سیستم نتایج را ارزیابی می‌کند، پرسش‌ها را پالایش می‌کند، ابزارهای بیشتری را در صورت نیاز فرا می‌خواند و این چرخه را ادامه می‌دهد تا زمانی که راه‌حلی قابل قبول به دست آید.

## مقدمه

این درس موارد زیر را پوشش می‌دهد

- **درک Agentic RAG:** درباره پارادایم نوظهور در هوش مصنوعی بیاموزید که در آن مدل‌های زبانی بزرگ (LLM) به‌صورت خودکار گام‌های بعدی خود را برنامه‌ریزی می‌کنند در حالی که اطلاعات را از منابع داده خارجی استخراج می‌کنند.
- **درک سبک سازنده-بازرس تکراری:** حلقه فراخوان‌های تکراری به LLM که با فراخوانی ابزار یا توابع و خروجی‌های ساختار یافته ترکیب شده‌اند را درک کنید، که برای بهبود دقت و رسیدگی به پرسش‌های ناقص طراحی شده است.
- **بررسی کاربردهای عملی:** سناریوهایی را شناسایی کنید که Agentic RAG در آنها می‌درخشد، مانند محیط‌های با اولویت صحت، تعاملات پیچیده با پایگاه داده و جریان‌های کاری گسترده.

## اهداف یادگیری

پس از اتمام این درس، شما خواهید دانست چگونه/درک خواهید کرد:

- **درک Agentic RAG:** درباره پارادایم نوظهور در هوش مصنوعی بیاموزید که در آن مدل‌های زبانی بزرگ (LLM) به‌صورت خودکار گام‌های بعدی خود را برنامه‌ریزی می‌کنند در حالی که اطلاعات را از منابع داده خارجی استخراج می‌کنند.
- **سبک سازنده-بازرس تکراری:** مفهوم حلقه فراخوان‌های تکراری به LLM که با فراخوانی ابزار یا توابع و خروجی‌های ساختار یافته ترکیب شده‌اند را درک کنید، که برای بهبود دقت و رسیدگی به پرسش‌های ناقص طراحی شده است.
- **مالکیت فرآیند استدلال:** توانایی سیستم برای مالکیت فرآیند استدلال خود را درک کنید، تصمیم‌گیری درباره نحوه برخورد با مشکلات را بدون تکیه بر مسیرهای از پیش تعریف شده.
- **جریان کاری:** درک کنید چگونه یک مدل عامل به‌طور مستقل تصمیم می‌گیرد گزارش‌های روند بازار را بازیابی کند، داده‌های رقبا را شناسایی کند، معیارهای فروش داخلی را همبسته کند، یافته‌ها را ترکیب نماید و استراتژی را ارزیابی کند.
- **حلقه‌های تکراری، ادغام ابزار و حافظه:** درباره تکیه سیستم به الگوی تعامل حلقوی، نگهداری حالت و حافظه در مراحل مختلف برای جلوگیری از حلقه‌های تکراری و اتخاذ تصمیمات آگاهانه بیاموزید.
- **رسیدگی به حالات شکست و خوداصلاحی:** مکانیزم‌های قوی خوداصلاحی سیستم، از جمله تکرار و بازپرسش، استفاده از ابزارهای تشخیصی و تکیه بر نظارت انسانی را بررسی کنید.
- **مرزهای آژانسی:** محدودیت‌های Agentic RAG را درک کنید، با تمرکز بر خودمختاری محدود به حوزه، وابستگی به زیرساخت‌ها و احترام به قواعد و محدودیت‌ها.
- **موارد استفاده عملی و ارزش:** سناریوهایی را شناسایی کنید که Agentic RAG در آنها می‌درخشد، مانند محیط‌های با اولویت صحت، تعاملات پیچیده با پایگاه داده و جریان‌های کاری گسترده.
- **حکمرانی، شفافیت و اعتماد:** درباره اهمیت حکمرانی و شفافیت، از جمله استدلال قابل توضیح، کنترل تعصب و نظارت انسانی بیاموزید.

## Agentic RAG چیست؟

Agentic Retrieval-Augmented Generation (Agentic RAG) یک پارادایم نوظهور در هوش مصنوعی است که در آن مدل‌های زبانی بزرگ (LLM) به‌صورت خودکار گام‌های بعدی خود را برنامه‌ریزی می‌کنند در حالی که اطلاعات را از منابع خارجی استخراج می‌کنند. بر خلاف الگوهای ایستا که ابتدا بازیابی می‌کنند و سپس می‌خوانند، Agentic RAG شامل فراخوان‌های تکراری به LLM است که با فراخوانی ابزار یا توابع و خروجی‌های ساختار یافته ترکیب می‌شود. سیستم نتایج را ارزیابی می‌کند، پرسش‌ها را پالایش می‌کند، ابزارهای بیشتری را در صورت نیاز فرا می‌خواند و این چرخه را ادامه می‌دهد تا زمانی که راه‌حلی قابل قبول به دست آید. این سبک “سازنده-بازرس” تکراری دقت را بهبود می‌بخشد، پرسش‌های ناقص را مدیریت می‌کند و نتایج با کیفیت بالا را تضمین می‌کند.

سیستم فرآیند استدلال خود را به‌صورت فعال در اختیار دارد، پرسش‌های ناموفق را بازنویسی می‌کند، روش‌های بازیابی متفاوتی را انتخاب می‌کند و ابزارهای متعددی را مانند جستجوی برداری در Azure AI Search، پایگاه داده‌های SQL یا API‌های سفارشی پیش از نهایی کردن پاسخ خود ادغام می‌کند. کیفیت تمایز دهنده یک سیستم عاملی، توانایی آن در مالکیت فرآیند استدلال خود است. پیاده‌سازی‌های سنتی RAG به مسیرهای از پیش تعیین شده تکیه دارند، اما یک سیستم عاملی به‌صورت خودکار توالی گام‌ها را بر اساس کیفیت اطلاعاتی که می‌یابد تعیین می‌کند.

## تعریف Agentic Retrieval-Augmented Generation (Agentic RAG)

Agentic Retrieval-Augmented Generation (Agentic RAG) یک پارادایم نوظهور در توسعه هوش مصنوعی است که در آن مدل‌های زبانی بزرگ نه تنها اطلاعات را از منابع داده خارجی استخراج می‌کنند، بلکه به‌طور خودکار گام‌های بعدی خود را برنامه‌ریزی می‌کنند. بر خلاف الگوهای ایستا که ابتدا بازیابی می‌کنند و سپس می‌خوانند یا توالی‌های کاملاً اسکریپت شده درخواست‌ها، Agentic RAG شامل یک حلقه از فراخوان‌های تکراری به LLM است که با فراخوانی ابزار یا توابع و خروجی‌های ساختار یافته ترکیب می‌شود. در هر مرحله، سیستم نتایجی را که به دست آورده ارزیابی می‌کند، تصمیم می‌گیرد پرسش‌های خود را پالایش کند یا خیر، ابزارهای اضافی را در صورت نیاز فرا می‌خواند و این چرخه را تا زمانی که راه‌حل رضایت‌بخشی به دست آورد، ادامه می‌دهد.

این سبک عملکرد “سازنده-بازرس” تکراری برای بهبود دقت، رسیدگی به پرسش‌های ناقص به پایگاه‌های داده ساختارشده (مثلاً NL2SQL) و تضمین نتایج متعادل و با کیفیت طراحی شده است. به جای تکیه صرف بر زنجیره‌های درخواست‌های مهندسی شده، سیستم به‌طور فعال فرآیند استدلال خود را در اختیار دارد. می‌تواند پرسش‌هایی که شکست می‌خورند را بازنویسی کند، روش‌های بازیابی مختلفی را انتخاب نماید و چندین ابزار را مانند جستجوی برداری در Azure AI Search، پایگاه داده‌های SQL یا API‌های سفارشی قبل از نهایی کردن پاسخ خود ادغام کند. این نیاز به چارچوب‌های سازماندهی پیچیده را از بین می‌برد. در عوض، یک حلقه نسبتاً ساده از «فراخوان LLM → استفاده از ابزار → فراخوان LLM → …» می‌تواند خروجی‌های پیشرفته و مبتنی بر استدلال تولید کند.

![Agentic RAG Core Loop](../../../translated_images/fa/agentic-rag-core-loop.c8f4b85c26920f71.webp)

## مالکیت فرآیند استدلال

ویژگی تمایز دهنده‌ای که یک سیستم را «عاملی» می‌کند، توانایی مالکیت فرآیند استدلالش است. پیاده‌سازی‌های سنتی RAG اغلب به مسیر تعیین شده توسط انسان برای مدل تکیه دارند: یک زنجیره اندیشه که مشخص می‌کند چه چیزی و چه زمانی بازیابی شود.
اما زمانی که یک سیستم واقعاً عاملی است، به‌صورت داخلی تصمیم می‌گیرد چگونه به مسئله نزدیک شود. این فقط اجرای یک اسکریپت نیست؛ بلکه به‌صورت خودکار توالی گام‌ها را بر اساس کیفیت اطلاعاتی که می‌یابد تعیین می‌کند.
برای مثال، اگر از آن خواسته شود استراتژی راه‌اندازی محصولی را ایجاد کند، تنها به یک درخواست که کل جریان تحقیق و تصمیم‌گیری را مشخص می‌کند تکیه نمی‌کند. بلکه مدل عاملی به‌طور مستقل تصمیم می‌گیرد:

1. بازیابی گزارش‌های روند بازار فعلی با استفاده از Bing Web Grounding
2. شناسایی داده‌های مرتبط رقبا با استفاده از Azure AI Search.
3. همبسته‌سازی معیارهای فروش داخلی تاریخی با استفاده از Azure SQL Database.
4. ترکیب یافته‌ها به استراتژی یکپارچه هماهنگ شده از طریق Azure OpenAI Service.
5. ارزیابی استراتژی برای شکاف‌ها یا ناسازگاری‌ها و درخواست دور دوم بازیابی در صورت لزوم.
تمام این گام‌ها — پالایش پرسش‌ها، انتخاب منابع، تکرار تا رسیدن به «رضایت» نسبت به پاسخ — توسط مدل تصمیم‌گیری می‌شود، نه توسط یک انسان پیش‌اسکریپت شده.

## حلقه‌های تکراری، ادغام ابزار و حافظه

![Tool Integration Architecture](../../../translated_images/fa/tool-integration.0f569710b5c17c10.webp)

یک سیستم عاملی به یک الگوی تعامل حلقوی تکیه دارد:

- **فراخوان اولیه:** هدف کاربر (یا درخواست کاربر) به LLM ارائه می‌شود.
- **فراخوانی ابزار:** اگر مدل اطلاعات ناقص یا دستورالعمل‌های مبهم را شناسایی کند، یک ابزار یا روش بازیابی را انتخاب می‌کند — مانند پرس‌وجوی پایگاه داده برداری (مثلاً جستجوی ترکیبی Azure AI Search روی داده‌های خصوصی) یا یک فراخوان ساختارشده SQL — برای جمع‌آوری زمینه بیشتر.
- **ارزیابی و پالایش:** پس از بررسی داده برگشتی، مدل تصمیم می‌گیرد آیا اطلاعات کافی است یا خیر. اگر نیست، پرسش را پالایش می‌کند، ابزار متفاوتی را امتحان می‌کند یا رویکرد خود را تنظیم می‌کند.
- **تکرار تا رضایت:** این چرخه ادامه می‌یابد تا مدل تصمیم بگیرد که وضوح و شواهد کافی برای ارائه پاسخ نهایی و قابل توجیه دارد.
- **حافظه و حالت:** چون سیستم حالت و حافظه در مراحل مختلف را نگه می‌دارد، می‌تواند تلاش‌ها و نتایج قبلی را به یاد آورد، از حلقه‌های تکراری اجتناب کند و تصمیمات آگاهانه‌تری بگیرد.

با گذشت زمان، این حس فهم پیوسته ایجاد می‌شود که به مدل اجازه می‌دهد وظایف پیچیده چندمرحله‌ای را بدون نیاز به مداخله مستمر انسان یا تغییر مکرر درخواست هدایت کند.

## رسیدگی به حالات شکست و خوداصلاحی

خودمختاری Agentic RAG همچنین شامل مکانیزم‌های قوی خوداصلاحی است. زمانی که سیستم به بن‌بست می‌رسد — مانند بازیابی اسناد نامرتبط یا مواجهه با پرسش‌های ناقص — می‌تواند:

- **تکرار و بازپرسش:** به جای بازگرداندن پاسخ‌های کم‌ارزش، مدل استراتژی‌های جدید جستجو را امتحان می‌کند، پرس‌وجوهای پایگاه داده را بازنویسی می‌کند یا به مجموعه داده‌های جایگزین نگاه می‌کند.
- **استفاده از ابزارهای تشخیصی:** سیستم ممکن است توابع اضافی که برای کمک به خطایابی مراحل استدلال یا تأیید صحت داده‌های بازیابی شده طراحی شده‌اند را فراخوانی کند. ابزارهایی مانند Azure AI Tracing برای ایجاد قابلیت مشاهده و نظارت قوی اهمیت خواهند داشت.
- **پشتیبانی از نظارت انسانی:** برای سناریوهای حساس یا مواردی که مکرراً با شکست مواجه می‌شوند، مدل ممکن است عدم قطعیت را علامت‌گذاری کرده و درخواست راهنمایی انسانی کند. پس از دریافت بازخورد اصلاحی از انسان، مدل می‌تواند آن درس را در آینده به کار گیرد.

این رویکرد تکراری و پویا به مدل اجازه می‌دهد به‌طور مستمر بهبود یابد و اطمینان حاصل کند که سیستم تنها یکبار شلیک نیست بلکه از اشتباهات خود در طول یک جلسه یاد می‌گیرد.

![Self Correction Mechanism](../../../translated_images/fa/self-correction.da87f3783b7f174b.webp)

## مرزهای آژانسی

با وجود خودمختاری‌اش در یک وظیفه، Agentic RAG معادل هوش مصنوعی عمومی نیست. قابلیت‌های «عاملی» آن محدود به ابزارها، منابع داده و سیاست‌هایی است که توسط توسعه‌دهندگان انسانی ارائه شده‌اند. نمی‌تواند ابزارهای خود را اختراع کند یا از مرزهای حوزه‌های تعیین شده فراتر رود. بلکه در سازماندهی پویا منابع موجود عالی است.
تفاوت‌های کلیدی با اشکال پیشرفته‌تر هوش مصنوعی عبارتند از:

1. **خودمختاری خاص حوزه:** سیستم‌های Agentic RAG بر دستیابی به اهداف تعریف شده توسط کاربر در حوزه‌ای شناخته شده تمرکز دارند و از استراتژی‌هایی مانند بازنویسی پرسش یا انتخاب ابزار برای بهبود نتایج استفاده می‌کنند.
2. **وابسته به زیرساخت:** توانایی‌های سیستم به ابزارها و داده‌هایی که توسعه‌دهندگان ادغام کرده‌اند بستگی دارد. بدون دخالت انسان نمی‌تواند از این مرزها فراتر رود.
3. **احترام به محدودیت‌ها:** دستورالعمل‌های اخلاقی، قوانین تطبیق و سیاست‌های کسب‌وکار بسیار مهم باقی می‌مانند. آزادی عامل همیشه توسط تدابیر ایمنی و مکانیزم‌های نظارت محدود می‌شود (امیدواریم).

## موارد استفاده عملی و ارزش

Agentic RAG در سناریوهایی که نیاز به پالایش تکراری و دقت دارد می‌درخشد:

1. **محیط‌های با اولویت صحت:** در بررسی‌های تطبیق، تحلیل‌های نظارتی یا تحقیقات حقوقی، مدل عاملی می‌تواند بارها حقیقت‌ها را بررسی کند، منابع متعدد را مشورت کند و پرسش‌ها را تا تولید پاسخی کاملاً بررسی شده بازنویسی کند.
2. **تعاملات پیچیده پایگاه داده:** هنگام کار با داده‌های ساختاربندی شده که پرسش‌ها ممکن است اغلب شکست بخورند یا نیاز به تنظیم داشته باشند، سیستم می‌تواند پرسش‌های خود را با استفاده از Azure SQL یا Microsoft Fabric OneLake اصلاح کرده و اطمینان حاصل کند بازیابی نهایی با نیت کاربر مطابقت دارد.
3. **جریان‌های کاری گسترده:** جلسات طولانی‌تر ممکن است با ظهور اطلاعات جدید تکامل یابند. Agentic RAG می‌تواند به طور مداوم داده‌های جدید را وارد کند و استراتژی‌ها را در حالی که بیشتر درباره فضای مسئله می‌آموزد، تغییر دهد.

## حکمرانی، شفافیت و اعتماد

با خودمختارتر شدن این سیستم‌ها در استدلال، حکمرانی و شفافیت حیاتی می‌شود:

- **استدلال قابل توضیح:** مدل می‌تواند یک روند حسابرسی از پرسش‌هایی که انجام داده، منابعی که مشورت کرده و مراحل استدلالی که به نتیجه‌گیری رسیده است، ارائه دهد. ابزارهایی مانند Azure AI Content Safety و Azure AI Tracing / GenAIOps می‌توانند به حفظ شفافیت و کاهش ریسک‌ها کمک کنند.
- **کنترل تعصب و بازیابی متعادل:** توسعه‌دهندگان می‌توانند استراتژی‌های بازیابی را تنظیم کنند تا منابع داده متعادل و نمایندگی شده لحاظ شوند و به طور منظم خروجی‌ها را برای تشخیص تعصب یا الگوهای انحرافی با استفاده از مدل‌های سفارشی برای سازمان‌های پیشرفته علم داده Azure Machine Learning ارزیابی کنند.
- **نظارت انسانی و تطبیق:** برای وظایف حساس، بازبینی انسانی ضروری باقی می‌ماند. Agentic RAG جایگزین قضاوت انسانی در تصمیمات حساس نمی‌شود — بلکه آن را با ارائه گزینه‌های کاملاً بررسی شده قابل ارتقا می‌دهد.

داشتن ابزارهایی که سوابق واضحی از اقدامات فراهم می‌کنند ضروری است. بدون آن‌ها عیب‌یابی یک فرآیند چند مرحله‌ای می‌تواند بسیار دشوار باشد. مثال زیر از Literal AI (شرکتی پشت Chainlit) برای یک اجرای Agent را ببینید:

![AgentRunExample](../../../translated_images/fa/AgentRunExample.471a94bc40cbdc0c.webp)

## نتیجه‌گیری

Agentic RAG نمایانگر یک تحول طبیعی در نحوه مدیریت سیستم‌های هوش مصنوعی برای وظایف پیچیده و داده‌محور است. با اتخاذ الگوی تعامل حلقوی، انتخاب خودکار ابزارها و پالایش پرسش‌ها تا رسیدن به نتیجه‌ای با کیفیت بالا، سیستم فراتر از تبعیت ایستا از درخواست‌ها حرکت کرده و به تصمیم‌گیری تطبیقی، آگاه به زمینه تبدیل می‌شود. در حالی که هنوز محدود به زیرساخت‌ها و دستورالعمل‌های اخلاقی تعریف شده توسط انسان است، این قابلیت‌های عاملی تعاملات هوش مصنوعی غنی‌تر، پویا‌تر و در نهایت مفیدتری را برای سازمان‌ها و کاربران نهایی فراهم می‌کنند.

### سوالات بیشتری درباره Agentic RAG دارید؟

به [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) بپیوندید تا با دیگر یادگیرندگان ملاقات کنید، در ساعات اداری شرکت کنید و سوالات خود درباره AI Agents را مطرح نمایید.

## منابع اضافی
- <a href="https://learn.microsoft.com/training/modules/use-own-data-azure-openai" target="_blank">اجرای تولید تقویت‌شده با بازیابی (RAG) با سرویس Azure OpenAI: یاد بگیرید چگونه از داده‌های خود با سرویس Azure OpenAI استفاده کنید. این ماژول مایکروسافت لرن راهنمای جامعی درباره اجرای RAG ارائه می‌دهد</a>
- <a href="https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-approach-gen-ai" target="_blank">ارزیابی برنامه‌های هوش مصنوعی مولد با Microsoft Foundry: این مقاله به ارزیابی و مقایسه مدل‌ها روی مجموعه داده‌های عمومی، شامل برنامه‌های هوش مصنوعی عامل‌محور و معماری‌های RAG می‌پردازد</a>
- <a href="https://weaviate.io/blog/what-is-agentic-rag" target="_blank">Agentic RAG چیست | Weaviate</a>
- <a href="https://ragaboutit.com/agentic-rag-a-complete-guide-to-agent-based-retrieval-augmented-generation/" target="_blank">Agentic RAG: راهنمای کامل برای تولید تقویت‌شده بازیابی مبتنی بر عامل – اخبار از نسل RAG</a>
- <a href="https://huggingface.co/learn/cookbook/agent_rag" target="_blank">Agentic RAG: افزایش قدرت RAG خود با بازفرموله کردن پرسش و خودپرسش! کتاب آشپزی هوش مصنوعی متن‌باز Hugging Face</a>
- <a href="https://youtu.be/aQ4yQXeB1Ss?si=2HUqBzHoeB5tR04U" target="_blank">اضافه کردن لایه‌های عامل‌محور به RAG</a>
- <a href="https://www.youtube.com/watch?v=zeAyuLc_f3Q&t=244s" target="_blank">آینده دستیارهای دانش: جری لیو</a>
- <a href="https://www.youtube.com/watch?v=AOSjiXP1jmQ" target="_blank">چگونه سیستم‌های Agentic RAG بسازیم</a>
- <a href="https://ignite.microsoft.com/sessions/BRK102?source=sessions" target="_blank">استفاده از سرویس عامل Microsoft Foundry برای گسترش عوامل هوش مصنوعی شما</a>

### مقالات علمی

- <a href="https://arxiv.org/abs/2303.17651" target="_blank">2303.17651 Self-Refine: تصحیح تکراری با بازخورد خود</a>
- <a href="https://arxiv.org/abs/2303.11366" target="_blank">2303.11366 Reflexion: عوامل زبانی با یادگیری تقویتی کلامی</a>
- <a href="https://arxiv.org/abs/2305.11738" target="_blank">2305.11738 CRITIC: مدل‌های زبان بزرگ می‌توانند خود را با نقد تعاملی ابزار اصلاح کنند</a>
- <a href="https://arxiv.org/abs/2501.09136" target="_blank">2501.09136 تولید تقویت‌شده بازیابی عامل‌محور: یک بررسی درباره Agentic RAG</a>

## درس قبلی

[الگوی طراحی استفاده از ابزار](../04-tool-use/README.md)

## درس بعدی

[ساخت عوامل هوش مصنوعی قابل اعتماد](../06-building-trustworthy-agents/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً آگاه باشید که ترجمه‌های خودکار ممکن است حاوی خطا یا نادرستی باشند. سند اصلی به زبان بومی خود باید منبع معتبر تلقی شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئول هیچ گونه سوء تفاهم یا تفسیر نادرستی که از استفاده این ترجمه ناشی شود، نیستیم.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->