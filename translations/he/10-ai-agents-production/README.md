# סוכני AI בפרודקשן: נראות והערכה

[![סוכני AI בפרודקשן](../../../translated_images/he/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

כאשר סוכני AI עוברים מפרוטוטייפים ניסויים ליישומים בעולם האמיתי, היכולת להבין את ההתנהגות שלהם, לעקוב אחרי הביצועים שלהם ולהעריך באופן שיטתי את התוצרים שלהם הופכת לחשובה.

## מטרות הלמידה

בסיום השיעור הזה תדעו איך/תבינו:
- מושגי יסוד של נראות והערכה של סוכנים
- טכניקות לשיפור ביצועים, עלויות ויעילות של סוכנים
- מה ואיך להעריך את סוכני ה-AI שלכם באופן שיטתי
- איך לשלוט בעלויות כשמפעילים סוכני AI בפרודקשן
- איך לאבזר סוכנים שנבנו עם AutoGen

המטרה היא לצייד אתכם בידע להפוך את הסוכנים שלכם ה""תיבה השחורה" למערכות שקופות, ניתנות לניהול ואמינות.

_**הערה:** חשוב לפרוס סוכני AI שהם בטוחים ואמינים. עברו גם על השיעור [בניית סוכני AI מוסריים](./06-building-trustworthy-agents/README.md)._

## עקבות ופסים

כלי נראות כמו [Langfuse](https://langfuse.com/) או [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) בדרך כלל מייצגים ריצות של סוכן כעקבות ופסים.

- **עקבות** מייצגים משימה סופית של הסוכן מתחילתו ועד לסופו (כמו טיפול בשאילתא משתמש).
- **פסים** הם שלבים בודדים בתוך העקבות (כמו קריאה למודל שפה או אחזור נתונים).

![עץ עקבות ב-Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

ללא נראות, סוכן AI יכול להרגיש כמו "קופסה שחורה" – הסטטוס הפנימי וההסקה שלו אינם ברורים, מה שמקשה לאבחן בעיות או לייעל את הביצועים. עם נראות, הסוכנים הופכים ל"קופסאות זכוכית," ומציעים שקיפות שהיא חיונית לבניית אמון ולהבטיח שהם פועלים כמצופה.

## למה נראות חשובה בסביבות פרודקשן

מעבר סוכני AI לסביבת פרודקשן מציב סט חדש של אתגרים ודרישות. נראות אינה עוד "דבר נחמד שיש", אלא יכולת קריטית:

*   **איתור שגיאות וניתוח שורש הבעיה**: כאשר סוכן נכשל או מפיק פלט בלתי צפוי, כלים לנראות מספקים את העקבות הדרושים כדי למקם את מקור השגיאה. זה חשוב במיוחד בסוכנים מורכבים שעשויים לכלול קריאות מרובות ל-LLM, אינטראקציה עם כלים ולוגיקה מותנית.
*   **ניהול אחוז זמן תגובה ועלויות**: סוכני AI נשענים לעיתים קרובות על קריאות ל-LLM ו-APIs חיצוניים שמחויבים לפי טוקן או קריאה. נראות מאפשרת מעקב מדויק אחר הקריאות האלה, ומסייעת לזהות פעולות שהן איטיות מדי או יקרות מדי. זה מאפשר לצוותים לייעל פרומפטים, לבחור מודלים יעילים יותר או לעצב תהליכים מחדש כדי לנהל עלויות ולהבטיח חווית משתמש טובה.
*   **אמון, בטיחות וציות**: ביישומים רבים חשוב להבטיח שסוכנים מתנהגים בצורה בטוחה ואתית. נראות מספקת מסלול ביקורת של פעולות והחלטות הסוכן. זה משמש לזיהוי ומיתון בעיות כמו הזרקת פרומפט, יצירת תוכן מזיק או טיפול שגוי במידע אישי מזהה (PII). לדוגמה, ניתן לסקור עקבות כדי להבין מדוע הסוכן נתן תגובה מסוימת או השתמש בכלי מסוים.
*   **לופים של שיפור מתמשך**: נתוני נראות הם בסיס לתהליך פיתוח איטרטיבי. על ידי מעקב אחר ביצועי הסוכנים בעולם האמיתי, צוותים יכולים לזהות אזורים לשיפור, לאסוף נתונים לכוונון מדויק של המודלים ולאמת את השפעת השינויים. זה יוצר לולאת משוב שבה תובנות מההערכה המקוונת בפרודקשן משפיעות על ניסויים ושיפורים מחוץ לקו, מה שמוביל לשיפור ביצועים הדרגתי.

## מדדים מרכזיים למעקב

כדי לעקוב ולהבין את התנהגות הסוכן, יש לעקוב אחרי מגוון מדדים ואינדיקטורים. בעוד שהמדדים הספציפיים עשויים להשתנות בהתאם למטרת הסוכן, יש מספר מדדים שחשובים באופן כללי.

להלן כמה מהמדדים הנפוצים שכלי נראות עוקבים אחריהם:

**זמן תגובה (Latency):** כמה מהר הסוכן מגיב? זמני המתנה ארוכים פוגעים בחוויית המשתמש. יש למדוד זמן תגובה למשימות ולשלבים בודדים על ידי מעקב אחר ריצות הסוכן. לדוגמה, סוכן שלוקח 20 שניות לכל הקריאות למודל יכול להיות מואץ על ידי שימוש במודל מהיר יותר או קריאות מקביליות.

**עלויות:** מה העלות לכל ריצת סוכן? סוכני AI מסתמכים על קריאות ל-LLM שנגבות לפי טוקן או API חיצוני. שימוש תכוף בכלים או מספר רב של פרומפטים יכול להגדיל במהירות את העלויות. לדוגמה, אם סוכן קורא ל-LLM חמש פעמים לשיפור שוליים באיכות, יש להעריך אם העלות מוצדקת או אם ניתן לצמצם קריאות או להשתמש במודל זול יותר. ניטור בזמן אמת יכול גם לסייע לזהות זינוק בלתי צפוי (למשל, באגים שגורמים ללולאות API מיותרות).

**שגיאות בבקשות:** כמה בקשות נכשלו? זה יכול לכלול שגיאות API או קריאות לכלים שנכשלו. כדי לחזק את הסוכן כנגד אלו בפרודקשן, ניתן להגדיר מנגנוני גיבוי או ניסיון מחדש. לדוגמה, אם ספק LLM א' לא זמין, עוברים לספק B כגיבוי.

**משוב משתמש:** יישום הערכות ישירות ממשתמשים מספק תובנות חשובות. זה יכול לכלול דירוג מפורש (👍אהבתי/👎לא, ⭐1-5 כוכבים) או תגובות טקסטואליות. משוב שלילי עקבי צריך להדליק נורה אדומה מכיוון שזה סימן שהסוכן לא פועל כמצופה.

**משוב משתמש מרומז:** התנהגויות משתמש מספקות משוב עקיף גם ללא דירוג מפורש. זה יכול לכלול ניסוחים מחדש מיידיים של שאלה, שאילתות חוזרות או לחיצה על כפתור ניסיון חוזר. לדוגמה, אם רואים שמשתמשים שואלים שוב ושוב את אותו השאלה, זה סימן שהסוכן לא פועל כמצופה.

**דיוק:** באיזו תדירות הסוכן מייצר תוצרים נכונים או רצויים? הגדרות דיוק משתנות (למשל, נכונות פתרון בעיות, דיוק אחזור מידע, שביעות רצון משתמש). השלב הראשון הוא להגדיר מה נחשב הצלחה עבור הסוכן שלך. ניתן לעקוב אחרי דיוק באמצעות בדיקות אוטומטיות, ציוני הערכה או תוויות השלמת משימות. לדוגמה, סימון עקבות כ"נכשלו" או "הצליחו".

**מדדים הערכה אוטומטיים:** ניתן גם להגדיר הערכות אוטומטיות. למשל, שימוש ב-LLM לציון תוצרי הסוכן לגבי היעילות, הדיוק או העזרתם. קיימות גם ספריות קוד פתוח שונות לסיוע בציון היבטים שונים של הסוכן. לדוגמה, [RAGAS](https://docs.ragas.io/) לסוכני RAG או [LLM Guard](https://llm-guard.com/) לגילוי שפה מזיקה או הזרקת פרומפט.

בעשייה מעשית, שילוב של מדדים אלה נותן את הכיסוי הטוב ביותר לבריאות סוכן AI. בדוגמת המחברת של פרק זה [example notebook](./code_samples/10_autogen_evaluation.ipynb) נראה איך מדדים אלה נראים בדוגמאות אמיתיות, אבל קודם נלמד איך נראה תהליך הערכה טיפוסי.

## אבזר את הסוכן שלך

כדי לאסוף נתוני מעקב, תצטרכו לאבזר את הקוד שלכם. המטרה היא לאבזר את קוד הסוכן להפיק עקבות ומדדים שניתן ללכוד, לעבד ולהציג בפלטפורמת נראות.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) התבררה כתקן תעשייתי לנראות LLM. היא מספקת סט API, SDK וכלים ליצירה, איסוף וייצוא נתוני טלמטריה.

קיימות ספריות אבזור רבות אשר עוטפות מסגרות סוכן קיימות ומקילות על ייצוא פסי OpenTelemetry לכלי נראות. להלן דוגמה לאבזור סוכן AutoGen עם ספריית האבזור [OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

המחברת [example notebook](./code_samples/10_autogen_evaluation.ipynb) בפרק זה תדגים כיצד לאבזר את סוכן AutoGen שלכם.

**יצירת פס ידנית:** בעוד שספריות האבזור מספקות בסיס טוב, לעיתים דרושים מידע מפורט או מותאם אישית יותר. ניתן ליצור פס ידנית להוספת לוגיקה מותאמת ביישום. חשוב יותר, ניתן להעשיר פס שנוצר אוטומטית או ידנית במאפיינים מותאמים (המכונים גם תגיות או מטא-נתונים). מאפיינים אלו יכולים לכלול נתונים עסקיים, חישובים ביניים או כל הקשר שיכול לסייע באיתור שגיאות או ניתוח, כמו `user_id`, `session_id`, או `model_version`.

דוגמה ליצירת עקבות ופסים ידנית עם [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## הערכת סוכן

נראות נותנת לנו מדדים, אבל הערכה היא תהליך ניתוח הנתונים (ועד ביצוע בדיקות) כדי לקבוע עד כמה סוכן AI מתפקד היטב ואיך ניתן לשפרו. במילים אחרות, אחרי שיש לכם עקבות ומדדים, איך משתמשים בהם כדי לשפוט את הסוכן ולקבל החלטות?

הערכת שגרה חשובה מכיוון שסוכני AI לרוב אינם דטרמיניסטיים ויכולים להתפתח (דרך עדכונים או סטייה בהתנהגות המודל) – בלי הערכה, לא תדעו אם ה"סוכן החכם" שלכם באמת עושה את עבודתו היטב או נסוג.

קיימות שתי קטגוריות של הערכות לסוכני AI: **הערכה מקוונת** ו**הערכה לא מקוונת**. שתיהן בעלות ערך, ומשלימות זו את זו. לרוב מתחילים בהערכה לא מקוונת, כיוון שזה הצעד המינימלי הנדרש לפני פריסת כל סוכן.

### הערכה לא מקוונת

![פריטי אוסף נתונים ב-Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

תהליך זה כולל הערכת הסוכן בסביבה מבוקרת, בדרך כלל באמצעות אוספי נתונים לבדיקה, לא שאילתות משתמש בזמן אמת. משתמשים באוספי נתונים מובחרים שבהם ידועים הפלט המצופה או ההתנהגות הנכונה, ואז מריצים את הסוכן עליהם.

לדוגמה, אם בניתם סוכן לפתירת בעיות מילוליות במתמטיקה, יכול להיות לכם [אוסף נתונים לבדיקה](https://huggingface.co/datasets/gsm8k) שמכיל 100 בעיות עם תשובות ידועות. הערכה לא מקוונת נעשית לעיתים קרובות במהלך פיתוח (ולעיתים כחלק מצינורות CI/CD) לבדוק שיפורים או למנוע נסיגות. היתרון הוא שזה **ניתן לחזרה וניתן לקבל מדדי דיוק ברורים כי יש אמת קרקעית**. ניתן גם לדמות שאילתות משתמש ולמדוד את תגובות הסוכן אל מול תשובות אידיאליות או להשתמש במדדים אוטומטיים כפי שתואר למעלה.

האתגר המרכזי בהערכה לא מקוונת הוא להבטיח שאוסף הנתונים לבדיקה הוא מקיף ונשאר רלוונטי – ייתכן שהסוכן יפעל היטב על קבוצה קבועה של מבחן אך ייתקל בשאילתות שונות מאוד בפרודקשן. לכן, יש לעדכן אוספי נתונים עם מקרים חדשים ודוגמאות המשקפות תרחישים אמיתיים. תערובת של מקרים קטנים לבדיקה מהירה ושל אוספים גדולים יותר למדדים רחבים מועילה: אוספים קטנים לבדיקות מהירות ואוספים גדולים לביצועי כלל.

### הערכה מקוונת

![סקירת מדדי נראות](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

הכוונה היא להערכת הסוכן בסביבת אמת, בשימוש חי בפרודקשן. הערכה מקוונת כוללת ניטור ביצועי הסוכן באינטראקציות משתמש אמיתיות וניתוח תוצאות באופן רציף.

לדוגמה, אפשר לעקוב אחרי שיעורי הצלחה, ציוני שביעות רצון המשתמש, או מדדים אחרים על תעבורה חיה. היתרון של הערכה מקוונת הוא שהיא **לוכדת דברים שאולי לא צפיתם להם במעבדה** – ניתן לצפות בסטייה של המודל לאורך זמן (אם יעילות הסוכן יורדת כאשר דפוסי הקלט משתנים) ולתפוס שאילתות או מצבים בלתי צפויים שלא היו באוסף הנתונים לבדיקה. היא מספקת תמונה אמיתית של התנהגות הסוכן בשטח.

הערכה מקוונת כוללת לרוב איסוף משוב משתמש מפורש ומרומז, כמו שנדון, ואולי הרצת בדיקות צל או בדיקות A/B (כאשר גרסה חדשה של הסוכן רצים במקביל להשוות לגרסה הוותיקה). האתגר הוא שקשה לקבל תוויות או ציונים אמינים לאינטראקציות חיות – ייתכן שתסתמכו על משוב משתמש או מדדים מזורמים (כגון האם המשתמש לחץ על התוצאה).

### שילוב בין השניים

הערכת מקוונת ולא מקוונת אינן בלעדיות זו לזו; הן משלימות זו את זו מאוד. תובנות מניטור מקוון (למשל, סוגים חדשים של שאילתות שבהן הסוכן מתפקד גרוע) יכולות לשמש להרחיב ולשפר אוספי הנתונים לבדיקה לא מקוונת. להפך, סוכנים שמתפקדים טוב בבדיקות לא מקוונות יכולים להיות מופעלים ולנוטרים בביטחון רב יותר באונליין.

למעשה, צוותים רבים מאמצים לולאה:

_להעריך לא מקוון -> לפרוס -> לנטר מקוון -> לאסוף מקרים נכשלים חדשים -> להוסיף לאוסף לא מקוון -> לשפר את הסוכן -> לחזור על התהליך_.

## בעיות נפוצות

כשתפרסו סוכני AI בפרודקשן, ייתכן ותיתקלו באתגרים שונים. להלן כמה בעיות נפוצות ופתרונות אפשריים:

| **בעיה**    | **פתרון פוטנציאלי**   |
| ------------- | ------------------ |
| סוכן AI לא מבצע משימות בעקביות | - שפרו את הפרומפט שניתן לסוכן; היו ברורים במטרות.<br>- זהו היכן חלוקה למשימות משנה וטיפול על ידי סוכנים מרובים יכולים לסייע. |
| סוכן AI נכנס ללולאות מתמשכות  | - ודאו שיש לכם תנאי סיום ברורים שהסוכן יודע מתי לעצור.<br>- למשימות מורכבות שדורשות הסקה ותכנון, השתמשו במודל גדול המתמחה במשימות הסקה. |
| קריאות כלים של סוכן AI אינן מתפקדות היטב   | - בדקו ואמתו את הפלט של הכלים מחוץ למערכת הסוכן.<br>- שפרו את הפרמטרים, הפרומפטים ושמות הכלים.  |
| מערכת רב-סוכנים איננה מתפקדת עקבית | - שפרו את הפרומפטים שניתנו לכל סוכן כדי לוודא שהם ספציפיים ומובחנים זה מזה.<br>- בנו מערכת הירארכית עם סוכן "ניתוב" או בקרה שיקבע איזה סוכן נכון. |

רבים מהבעיות הללו ניתן לזהות ביעילות רבה יותר עם נראות בשטח. העקבות והמדדים שדיברנו עליהם לעיל מסייעים לזהות בדיוק היכן בזרימת העבודה של הסוכן הבעיה מתרחשת, מה שהופך איתור תקלות ואופטימיזציה ליעילים יותר.

## ניהול עלויות
הנה כמה אסטרטגיות לניהול עלויות פריסת סוכני AI בפרודקשן:

**שימוש במודלים קטנים יותר:** מודלים שפתיים קטנים (SLMs) יכולים לבצע היטב במקרים שימוש סוכניים מסוימים ויפחיתו עלויות משמעותית. כפי שהוזכר קודם, בניית מערכת הערכה לקביעת ביצועים והשוואתם מול מודלים גדולים יותר היא הדרך הטובה ביותר להבין עד כמה SLM יתאים לשימוש שלך. שקול להשתמש ב-SLM למשימות פשוטות יותר כמו סיווג כוונות או חילוץ פרמטרים, תוך שמירת מודלים גדולים יותר למשימות סבוכות יותר של הסקה.

**שימוש במודל נתב:** אסטרטגיה דומה היא להשתמש במגוון מודלים וגדלים. ניתן להשתמש ב-LLM/SLM או פונקציונליות ללא שרת כדי לנתב בקשות על בסיס מורכבות למודלים המתאימים ביותר. זה גם יסייע להפחית עלויות תוך הבטחת ביצועים במשימות הנכונות. לדוגמה, לנתב שאילתות פשוטות למודלים קטנים ומהירים יותר, ולהשתמש רק במודלים גדולים ויקרים למשימות הסקה מורכבות.

**מטמון תגובות:** זיהוי בקשות ומשימות נפוצות ומתן תגובות לפני שהן עוברות דרך המערכת הסוכנית שלך היא דרך טובה להפחית את נפח הבקשות הדומות. ניתן אפילו ליישם זרימה לזיהוי דמיון של בקשות לבקשות השמורות במטמון באמצעות מודלי AI בסיסיים יותר. אסטרטגיה זו יכולה להפחית משמעותית עלויות עבור שאלות נפוצות או תהליכים חוזרים.

## בוא נראה איך זה עובד בפועל

ב[מחברת הדוגמה של פרק זה](./code_samples/10_autogen_evaluation.ipynb), נראה דוגמאות לאיך ניתן להשתמש בכלי תצפית כדי לעקוב ולהעריך את הסוכן שלנו.


### יש לך שאלות נוספות על סוכני AI בפרודקשן?

הצטרף ל[Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) כדי לפגוש לומדים אחרים, להשתתף בשעות פתוחות ולקבל תשובות לשאלות על סוכני AI.

## השיעור הקודם

[תבנית עיצוב מטה-קוגניציה](../09-metacognition/README.md)

## השיעור הבא

[פרוטוקולים סוכניים](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**כתב הודעה בדבר הגבלת אחריות**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). בעוד שאנו שואפים לדיוק, יש לקחת בחשבון כי תרגומים אוטומטיים עלולים לכלול שגיאות או אי-דיוקים. מסמך המקור בשפתו המקורית הוא המקור הרשמי והמהימן. למידע קריטי מומלץ להיעזר בתרגום מקצועי על ידי אדם. איננו אחראים לכל אי-הבנה או פרשנות שגויה העלולה לנבוע משימוש בתרגום זה.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->