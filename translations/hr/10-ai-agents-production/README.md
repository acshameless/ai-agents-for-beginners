# AI agenti u proizvodnji: promatranje i evaluacija

[![AI Agents in Production](../../../translated_images/hr/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

Kako AI agenti prelaze iz eksperimentalnih prototipova u stvarne primjene, sposobnost razumijevanja njihovog ponaÅ¡anja, praÄ‡enje njihove izvedbe i sustavna evaluacija njihovih izlaza postaju vaÅ¾ni.

## Ciljevi uÄenja

Nakon dovrÅ¡etka ove lekcije znat Ä‡ete kako/razumjeti:
- Osnovne koncepte promatranja i evaluacije agenata
- Tehnike za poboljÅ¡anje izvedbe, troÅ¡kova i uÄinkovitosti agenata
- Å to i kako sustavno evaluirati svoje AI agente
- Kako kontrolirati troÅ¡kove pri uvoÄ‘enju AI agenata u proizvodnju
- Kako instrumentirati agente izgraÄ‘ene s AutoGen

Cilj je opremiti vas znanjem za pretvaranje vaÅ¡ih "crnih kutija" agenata u transparentne, upravljive i pouzdane sustave.

_**Napomena:** vaÅ¾no je implementirati AI agente koji su sigurni i pouzdani. Pogledajte i lekciju [Izgradnja pouzdanih AI agenata](./06-building-trustworthy-agents/README.md)._

## TragaÄi i segmenti

Alati za promatranje poput [Langfuse](https://langfuse.com/) ili [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) obiÄno predstavljaju izvoÄ‘enja agenata kao tragove i segmente.

- **Trag** predstavlja cjelovit zadatak agenta od poÄetka do kraja (npr. obrada korisniÄkog upita).
- **Segmenti** su pojedinaÄni koraci unutar traga (npr. pozivanje jeziÄnog modela ili dohvat podataka).

![Trace tree in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Bez promatranja, AI agent moÅ¾e djelovati kao "crna kutija" - njegovo unutarnje stanje i razmiÅ¡ljanje su neprozirni, Å¡to oteÅ¾ava dijagnosticiranje problema ili optimizaciju izvedbe. S promatranjem, agenti postaju "staklene kutije", pruÅ¾ajuÄ‡i transparentnost koja je kljuÄna za izgradnju povjerenja i osiguranje da rade kako je predviÄ‘eno.

## ZaÅ¡to promatranje ima znaÄaj u proizvodnim okruÅ¾enjima

Prijenos AI agenata u proizvodna okruÅ¾enja donosi nove izazove i zahtjeve. Promatranje viÅ¡e nije "lijepa za imati" nego kritiÄna sposobnost:

*   **Otklanjanje pogreÅ¡aka i analiza uzroka:** Kad agent zakaÅ¾e ili proizvede neoÄekivani rezultat, alati za promatranje pruÅ¾aju tragove potrebne za toÄno lociranje izvora pogreÅ¡ke. To je posebno vaÅ¾no kod sloÅ¾enih agenata koji mogu ukljuÄivati viÅ¡e poziva na LLM, interakciju s alatima i uvjetnu logiku.
*   **Upravljanje kaÅ¡njenjem i troÅ¡kovima:** AI agenti Äesto ovise o LLM-ovima i drugim vanjskim API-jima koji se naplaÄ‡uju po tokenu ili pozivu. Promatranje omoguÄ‡uje precizno praÄ‡enje tih poziva, pomaÅ¾uÄ‡i identificirati operacije koje su pretjerano spore ili skupe. To omoguÄ‡uje timovima optimizaciju upita, izbor uÄinkovitijih modela ili redizajn tijekova rada za kontrolu operativnih troÅ¡kova i osiguranje dobrog korisniÄkog iskustva.
*   **Povjerenje, sigurnost i usklaÄ‘enost:** U mnogim aplikacijama vaÅ¾no je osigurati da agenti djeluju sigurno i etiÄki. Promatranje pruÅ¾a zapis o akcijama i odlukama agenta. To se moÅ¾e koristiti za otkrivanje i sprjeÄavanje problema poput unosa Å¡tetnih uputa, generiranja Å¡tetnog sadrÅ¾aja ili neprimjerene obrade osobnih podataka (PII). Na primjer, moÅ¾ete pregledati tragove da biste razumjeli zaÅ¡to je agent dao odreÄ‘eni odgovor ili upotrijebio odreÄ‘eni alat.
*   **Kontinuirani poboljÅ¡anja:** Podaci iz promatranja temelj su iterativnog razvojnog procesa. PraÄ‡enjem izvedbe agenata u stvarnom svijetu, timovi mogu identificirati podruÄja za poboljÅ¡anje, prikupiti podatke za fino podeÅ¡avanje modela i potvrditi utjecaj promjena. To stvara povratnu petlju u kojoj uvidi iz proizvodne evaluacije online informiraju offline eksperimentiranje i usavrÅ¡avanje, dovodeÄ‡i do postupno bolje izvedbe agenata.

## KljuÄni metriÄki pokazatelji za praÄ‡enje

Za praÄ‡enje i razumijevanje ponaÅ¡anja agenata treba pratiti niz metrika i signala. Iako se specifiÄne metrike mogu razlikovati ovisno o namjeni agenta, neke su univerzalno vaÅ¾ne.

Ovdje su neke od najÄeÅ¡Ä‡ih metrika koje alati za promatranje prate:

**KaÅ¡njenje (Latency):** Koliko brzo agent odgovara? Dugo Äekanje negativno utjeÄe na korisniÄko iskustvo. Trebali biste mjeriti kaÅ¡njenje za zadatke i pojedinaÄne korake prateÄ‡i izvoÄ‘enje agenata. Na primjer, agent koji sve pozive modela obavi za 20 sekundi mogao bi se ubrzati koriÅ¡tenjem brÅ¾eg modela ili paralelnim izvoÄ‘enjem poziva.

**TroÅ¡kovi:** Koliki su troÅ¡kovi po izvoÄ‘enju agenta? AI agenti ovise o pozivima LLM-a koji se naplaÄ‡uju po tokenu ili o vanjskim API-jima. ÄŒesto koriÅ¡tenje alata ili viÅ¡estruki upiti mogu brzo poveÄ‡ati troÅ¡kove. Na primjer, ako agent pet puta pozove LLM za neznatno poboljÅ¡anje kvalitete, morate procijeniti je li troÅ¡ak opravdan ili moÅ¾ete smanjiti broj poziva ili koristiti jeftiniji model. PraÄ‡enje u stvarnom vremenu takoÄ‘er moÅ¾e pomoÄ‡i u otkrivanju neoÄekivanih skokova (npr. bugovi koji uzrokuju pretjerane petlje poziva API-ja).

**PogreÅ¡ke zahtjeva:** Koliko je zahtjeva agent uspio obraditi? Ovo moÅ¾e ukljuÄivati pogreÅ¡ke API-ja ili neuspjele pozive alata. Da biste svog agenta uÄinili robusnijim u proizvodnji, moÅ¾ete postaviti rezervne opcije ili pokuÅ¡aje ponovnog poziva. Npr. ako LLM pruÅ¾atelj A nije dostupan, moÅ¾ete se prebaciti na LLM pruÅ¾atelja B kao rezervu.

**Povratne informacije korisnika:** Implementiranjem direktnih korisniÄkih evaluacija dobivate vrijedne uvide. To moÅ¾e ukljuÄivati eksplicitne ocjene (ğŸ‘za/ğŸ‘protiv, â­1-5 zvjezdica) ili tekstualne komentare. Konzistentno negativne povratne informacije trebale bi vas upozoriti jer su znak da agent ne radi kako se oÄekuje.

**Implicitne povratne informacije korisnika:** KorisniÄko ponaÅ¡anje pruÅ¾a neizravne povratne informacije Äak i bez eksplicitnih ocjena. To moÅ¾e ukljuÄivati trenutne preformulacije pitanja, ponovljene upite ili klikanje na gumb za ponovni pokuÅ¡aj. Npr. ako vidite da korisnici viÅ¡e puta postavljaju isto pitanje, to je znak da agent ne radi kako se oÄekuje.

**ToÄnost:** Koliko Äesto agent proizvodi toÄne ili poÅ¾eljne rezultate? Definicije toÄnosti variraju (npr. rjeÅ¡enje problema, toÄnost dohvaÄ‡anja informacija, zadovoljstvo korisnika). Prvi je korak definirati Å¡to je uspjeh za vaÅ¡eg agenta. ToÄnost moÅ¾ete pratiti preko automatiziranih provjera, rezultata evaluacije ili oznaka za zavrÅ¡etak zadatka. Na primjer, oznaÄavanjem tragova kao "uspjeÅ¡no" ili "neuspjeÅ¡no".

**Automatizirane evaluacijske metrike:** TakoÄ‘er moÅ¾ete postaviti automatizirane evaluacije. Na primjer, moÅ¾ete koristiti LLM za ocjenu izlaza agenta npr. je li koristan, toÄan ili nije. Postoji nekoliko open source biblioteka koje pomaÅ¾u ocijeniti razliÄite aspekte agenta. Npr. [RAGAS](https://docs.ragas.io/) za RAG agente ili [LLM Guard](https://llm-guard.com/) za otkrivanje Å¡tetnog jezika ili unosa Å¡tetnih uputa.

U praksi, kombinacija ovih metrika daje najbolju pokrivenost zdravstvenog stanja AI agenta. U ovom poglavlju [primjer biljeÅ¾nice](./code_samples/10_autogen_evaluation.ipynb) pokazat Ä‡emo vam kako ove metrike izgledaju u stvarnim primjerima, ali prvo Ä‡emo nauÄiti kako izgleda tipiÄni tijek evaluacije.

## Instrumentirajte svog agenta

Za prikupljanje podataka traga bit Ä‡ete u potrebi instrumentirati svoj kod. Cilj je instrumentirati kod agenta da emitira tragove i metrike koje moÅ¾e hvatati, obraÄ‘ivati i vizualizirati platforma za promatranje.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) postao je industrijski standard za promatranje LLM-ova. PruÅ¾a skup API-ja, SDK-a i alata za generiranje, skupljanje i izvoz telemetrijskih podataka.

Postoji mnogo biblioteka za instrumentaciju koje omotavaju postojeÄ‡e okvire za agente i olakÅ¡avaju izvoz OpenTelemetry segmenata u alat za promatranje. Ispod je primjer instrumentiranja AutoGen agenta s [OpenLit instrumentacijskom bibliotekom](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

Primjer biljeÅ¾nice u ovom poglavlju ([example notebook](./code_samples/10_autogen_evaluation.ipynb)) pokazat Ä‡e kako instrumentirati vaÅ¡ AutoGen agent.

**RuÄno kreiranje segmenata:** Iako instrumentacijske biblioteke pruÅ¾aju dobru osnovu, Äesto su potrebni detaljniji ili prilagoÄ‘eni podaci. MoÅ¾ete ruÄno kreirati segmente za dodavanje prilagoÄ‘ene aplikacijske logike. JoÅ¡ vaÅ¾nije, mogu obogatiti automatski ili ruÄno stvarane segmente s prilagoÄ‘enim atributima (poznatima i kao oznake ili metapodaci). Ti atributi mogu ukljuÄivati poslovno specifiÄne podatke, meÄ‘urezultate ili bilo koji kontekst koji moÅ¾e biti koristan za otklanjanje pogreÅ¡aka ili analizu, kao Å¡to su `user_id`, `session_id` ili `model_version`.

Primjer ruÄnog kreiranja tragova i segmenata s [Langfuse Python SDK-om](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Evaluacija agenta

Promatranje nam daje metrike, ali evaluacija je proces analize tih podataka (i izvoÄ‘enja testova) za odreÄ‘ivanje koliko dobro AI agent radi i kako se moÅ¾e poboljÅ¡ati. Drugim rijeÄima, kad imate te tragove i metrike, kako ih koristiti za ocjenu agenta i donoÅ¡enje odluka?

Redovita evaluacija je vaÅ¾na jer AI agenti Äesto nisu deterministiÄki i mogu se mijenjati (kroz nadogradnje ili drift ponaÅ¡anja modela) â€“ bez evaluacije ne biste znali radi li vaÅ¡ "pametni agent" dobar posao ili je nazadovao.

Postoje dvije kategorije evaluacija za AI agente: **online evaluacija** i **offline evaluacija**. Obje su vrijedne i nadopunjuju se. ObiÄno poÄinjemo s offline evaluacijom, jer je to minimalni nuÅ¾ni korak prije uvoÄ‘enja bilo kojeg agenta.

### Offline evaluacija

![Dataset items in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

To ukljuÄuje evaluaciju agenta u kontroliranom okruÅ¾enju, tipiÄno koriÅ¡tenjem testnih skupova podataka, a ne uÅ¾ivo korisniÄkih upita. Koristite kurirane skupove podataka gdje znate oÄekivani izlaz ili ispravno ponaÅ¡anje, a zatim pokreÄ‡ete svog agenta na njima.

Na primjer, ako ste napravili agenta za rjeÅ¡avanje matematiÄkih zadataka iz rijeÄi, mogli biste imati [testni skup podataka](https://huggingface.co/datasets/gsm8k) od 100 problema s poznatim odgovorima. Offline evaluacija se Äesto izvodi tijekom razvoja (i moÅ¾e biti dio CI/CD procesa) za provjeru poboljÅ¡anja ili zaÅ¡titu od regresija. Prednost je Å¡to je **ponovljivo i moÅ¾ete dobiti jasne metrike toÄnosti jer imate stvarne istinite podatke**. TakoÄ‘er moÅ¾ete simulirati korisniÄke upite i mjeriti odgovore agenta prema idealnim odgovorima ili koristiti automatizirane metrike koje smo ranije opisali.

Glavni je izazov kod offline evaluacije osigurati da je vaÅ¡ testni skup podataka sveobuhvatan i relevantan â€“ agent moÅ¾e dobro raditi na fiksnom testnom skupu, ali se u proizvodnji suoÄiti s vrlo razliÄitim upitima. Stoga trebate redovito aÅ¾urirati testne skupove novim rubnim sluÄajevima i primjerima koji odraÅ¾avaju stvarne scenarije. Korisna je kombinacija manjeg "smoke test" skupa i veÄ‡ih evaluacijskih setova: manji setovi za brze provjere i veÄ‡i za Å¡iru izvedbenu metriku.

### Online evaluacija

![Observability metrics overview](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Ovo oznaÄava evaluaciju agenta u Å¾ivom, stvarnom okruÅ¾enju, tj. tijekom stvarne upotrebe u proizvodnji. Online evaluacija ukljuÄuje praÄ‡enje izvedbe agenta na stvarnim korisniÄkim interakcijama i kontinuiranu analizu rezultata.

Na primjer, moÅ¾ete pratiti stope uspjeha, ocjene zadovoljstva korisnika ili druge metrike na Å¾ivom prometu. Prednost online evaluacije je da **uhvati stvari koje ne biste mogli predvidjeti u laboratorijskom postavu** â€“ moÅ¾ete uoÄiti drift modela tijekom vremena (ako uÄinkovitost agenta opada kako se obrasci ulaza mijenjaju) i uoÄiti neoÄekivane upite ili situacije koje nisu bile u vaÅ¡im testnim podacima. Ona pruÅ¾a stvarnu sliku o ponaÅ¡anju agenta u prirodnom okruÅ¾enju.

Online evaluacija Äesto ukljuÄuje prikupljanje implicitnih i eksplicitnih povratnih informacija korisnika, kao Å¡to je ranije objaÅ¡njeno, te moguÄ‡e provoÄ‘enje shadow testova ili A/B testova (gdje nova verzija agenta radi paralelno kako bi se usporedila s starom). Izazov je Å¡to je teÅ¡ko dobiti pouzdane oznake ili ocjene za Å¾ive interakcije â€“ moÅ¾da se oslanjate na povratne informacije korisnika ili na izvedbene metrike (npr. je li korisnik kliknuo rezultat).

### Kombiniranje dvaju pristupa

Online i offline evaluacije nisu meÄ‘usobno iskljuÄive; one su vrlo komplementarne. Uvidi iz online nadzora (npr. novi tipovi korisniÄkih upita na kojima agent loÅ¡e radi) mogu se koristiti za nadopunu i poboljÅ¡anje offline testnih skupova. Suprotno, agenti koji dobro prolaze offline testove mogu se onda s veÄ‡im povjerenjem implementirati i pratiti online.

Mnogi timovi zapravo usvajaju petlju:

_evaluacija offline -> implementacija -> nadzor online -> prikupljanje novih sluÄajeva neuspjeha -> dodavanje u offline skup -> fino podeÅ¡avanje agenta -> ponavljanje_.

## UobiÄajeni problemi

Prilikom uvoÄ‘enja AI agenata u proizvodnju, moÅ¾ete naiÄ‡i na razliÄite izazove. Evo nekoliko uobiÄajenih problema i moguÄ‡ih rjeÅ¡enja:

| **Problem**    | **MoguÄ‡e rjeÅ¡enje**   |
| ------------- | ------------------ |
| AI agent ne izvrÅ¡ava zadatke dosljedno | - PoboljÅ¡ajte prompt dan AI agentu; budite jasni o ciljevima.<br>- Identificirajte gdje dijeljenje zadataka u podzadace koje obavljaju razliÄiti agenti moÅ¾e pomoÄ‡i. |
| AI agent zapada u kontinuirane petlje | - Osigurajte jasne uvjete zaustavljanja procesa da agent zna kada treba prekinuti.<br>- Za sloÅ¾ene zadatke koji zahtijevaju rezoniranje i planiranje koristite veÄ‡i model specijaliziran za te zadatke. |
| Pozivi alatu AI agenta ne funkcioniraju dobro | - Testirajte i validirajte izlaz alata izvan sustava agenta.<br>- Precizirajte definirane parametre, upite i imenovanje alata.  |
| Multi-agentni sustav ne radi dosljedno | - PoboljÅ¡ajte upite danim svakom agentu kako bi bili specifiÄni i razliÄiti.<br>- Izgradite hijerarhijski sustav koristeÄ‡i "routing" ili kontrolni agent za odabir ispravnog agenta. |

Mnogi od ovih problema mogu se uÄinkovitije identificirati s implementiranim promatranjem. Tragovi i metrike koje smo prethodno opisali pomaÅ¾u precizno locirati problem u tijeku rada agenta, Å¡to otklanjanje pogreÅ¡aka i optimizaciju Äini mnogo uÄinkovitijima.

## Upravljanje troÅ¡kovima
Evo nekoliko strategija za upravljanje troÅ¡kovima implementacije AI agenata u produkciju:

**KoriÅ¡tenje manjih modela:** Mali jeziÄni modeli (SLM) mogu dobro funkcionirati u odreÄ‘enim agentnim sluÄajevima koriÅ¡tenja i znaÄajno smanjiti troÅ¡kove. Kao Å¡to je ranije spomenuto, izrada sustava za evaluaciju koji Ä‡e odrediti i usporediti performanse u odnosu na veÄ‡e modele najbolji je naÄin da razumijete koliko Ä‡e se SLM dobro pokazati za vaÅ¡ sluÄaj koriÅ¡tenja. Razmislite o koriÅ¡tenju SLM-ova za jednostavnije zadatke poput klasifikacije namjere ili izdvajanja parametara, dok veÄ‡e modele rezervirate za sloÅ¾eno zakljuÄivanje.

**KoriÅ¡tenje rutera modela:** SliÄna strategija je koriÅ¡tenje raznolikosti modela i veliÄina. MoÅ¾ete koristiti LLM/SLM ili serverless funkciju za usmjeravanje zahtjeva temeljem sloÅ¾enosti prema modelima koji najbolje odgovaraju. Ovo Ä‡e takoÄ‘er pomoÄ‡i u smanjenju troÅ¡kova, a istovremeno osigurati performanse na pravim zadacima. Na primjer, jednostavne upite usmjerite na manje, brÅ¾e modele, a skupe velike modele koristite samo za sloÅ¾ene zadatke zakljuÄivanja.

**KeÅ¡iranje odgovora:** Identificiranje Äestih zahtjeva i zadataka te pruÅ¾anje odgovora prije nego Å¡to proÄ‘u kroz vaÅ¡ agentni sustav dobar je naÄin smanjenja volumena sliÄnih zahtjeva. MoÅ¾ete Äak implementirati tijek rada za odreÄ‘ivanje koliko je zahtjev sliÄan onima koje ste veÄ‡ keÅ¡irali koristeÄ‡i osnovnije AI modele. Ova strategija moÅ¾e znaÄajno smanjiti troÅ¡kove za Äesto postavljana pitanja ili uobiÄajene radne tokove.

## Pogledajmo kako ovo funkcionira u praksi

U [primjernom biljeÅ¾niku ovog odjeljka](./code_samples/10_autogen_evaluation.ipynb) vidjet Ä‡emo primjere kako moÅ¾emo koristiti alate za promatranje i procjenu naÅ¡eg agenta.


### Imate li joÅ¡ pitanja o AI agentima u produkciji?

PridruÅ¾ite se [Microsoft Foundry Discordu](https://aka.ms/ai-agents/discord) kako biste se upoznali s drugim polaznicima, sudjelovali na uredskim satima i dobili odgovore na vaÅ¡a pitanja o AI agentima.

## Prethodna lekcija

[Metakognitivni obrazac dizajna](../09-metacognition/README.md)

## SljedeÄ‡a lekcija

[Agentni protokoli](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Odricanje od odgovornosti**:
Ovaj dokument je preveden pomoÄ‡u AI servis za prijevod [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo postiÄ‡i toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba se smatrati sluÅ¾benim i vjerodostojnim izvorom. Za vaÅ¾ne informacije preporuÄuje se profesionalni ljudski prijevod. Ne snosimo odgovornost za bilo kakva nesporazuma ili pogreÅ¡ne interpretacije koje proizlaze iz koriÅ¡tenja ovog prijevoda.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->