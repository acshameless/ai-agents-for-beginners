# 本番環境におけるAIエージェント：可観測性と評価

[![本番環境におけるAIエージェント](../../../translated_images/ja/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

AIエージェントが実験的プロトタイプから実際のアプリケーションへ移行するにつれて、その挙動を理解し、性能を監視し、出力を体系的に評価する能力が重要になります。

## 学習目標

このレッスンを終えると、以下のことができる/理解できるようになります：
- エージェントの可観測性と評価のコア概念
- エージェントの性能、コスト、および有効性を改善するための手法
- AIエージェントを体系的に評価する対象と方法
- AIエージェントを本番環境に展開する際のコスト管理方法
- AutoGenで構築したエージェントの計装方法

目的は、あなたの「ブラックボックス」的なエージェントを透明で管理可能、かつ信頼できるシステムに変える知識を提供することです。

_**Note:** It is important to deploy AI Agents that are safe and trustworthy. Check out the [Building Trustworthy AI Agents](./06-building-trustworthy-agents/README.md) lesson as well._

## トレースとスパン

Observability tools such as [Langfuse](https://langfuse.com/) or [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) usually represent agent runs as traces and spans.

- **Trace** は、開始から終了までのエージェントのタスク全体を表します（例：ユーザーの問い合わせ対応）。
- **Spans** は、トレース内の個々のステップを表します（例：言語モデルの呼び出しやデータ取得）。

![Langfuseのトレースツリー](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

可観測性がないと、AIエージェントは「ブラックボックス」のように感じられます — 内部状態や推論過程が不透明で、問題の診断や性能最適化が難しくなります。可観測性があれば、エージェントは「ガラス箱」となり、信頼構築や意図どおりに動作していることを確認するために不可欠な透明性を提供します。

## なぜ本番環境で可観測性が重要なのか

AIエージェントを本番環境に移行すると、新たな課題や要件が生じます。可観測性はもはや「あると良いもの」ではなく、重要な能力です：

*   **デバッグと根本原因分析**：エージェントが失敗したり予期しない出力を生成した場合、可観測性ツールはエラーの原因を特定するためのトレースを提供します。これは、複数のLLM呼び出し、ツールとの相互作用、条件付きロジックを含む複雑なエージェントで特に重要です。
*   **レイテンシとコスト管理**：AIエージェントはしばしばトークン単位や呼び出し単位で課金されるLLMや外部APIに依存します。可観測性によりこれらの呼び出しを正確に追跡でき、過度に遅いまたは高コストな操作を特定するのに役立ちます。これにより、プロンプトの最適化、より効率的なモデルの選択、ワークフローの再設計などで運用コストを管理し、良好なユーザー体験を確保できます。
*   **信頼性、安全性、コンプライアンス**：多くのアプリケーションでは、エージェントが安全かつ倫理的に振る舞うことを保証することが重要です。可観測性はエージェントの行動や意思決定の監査証跡を提供します。これを用いてプロンプトインジェクション、有害なコンテンツの生成、個人を特定できる情報（PII）の誤扱いなどの問題を検出および緩和できます。例えば、なぜエージェントが特定の応答をしたのか、あるいはなぜ特定のツールを使用したのかをトレースで確認できます。
*   **継続的改善ループ**：可観測性データは反復的な開発プロセスの基盤です。エージェントが実際の世界でどのように動作しているかを監視することで、改善点を特定し、モデルの微調整に必要なデータを収集し、変更の影響を検証できます。これにより、本番で得られたオンライン評価の洞察がオフラインの実験と改良に反映され、段階的にエージェントの性能が向上するフィードバックループが構築されます。

## 追跡すべき主要な指標

エージェントの挙動を監視・理解するために、さまざまな指標やシグナルを追跡する必要があります。具体的な指標はエージェントの用途によって異なりますが、普遍的に重要なものがあります。

以下は可観測性ツールが監視する最も一般的な指標です：

**Latency（レイテンシ）:** エージェントはどれくらい迅速に応答するか？長い待ち時間はユーザー体験に悪影響を与えます。エージェントの実行や個々のステップのレイテンシをトレースすることで計測すべきです。例えば、すべてのモデル呼び出しに20秒かかるエージェントは、より高速なモデルへの切替やモデル呼び出しの並列化によって高速化できます。

**Costs（コスト）:** エージェント実行あたりの費用はどのくらいか？AIエージェントはトークン単位や外部APIで課金されるLLM呼び出しに依存します。頻繁なツール使用や複数のプロンプトはコストを急速に増加させます。例えば、エージェントが品質向上のためにLLMを5回呼び出しているなら、そのコストが正当化されるか、呼び出し回数を減らすか安価なモデルを使えるかを評価する必要があります。リアルタイムの監視は、予期しないスパイク（例：バグによる過剰なAPIループ）を検出するのにも役立ちます。

**Request Errors（リクエストエラー）:** エージェントが失敗したリクエストはどれくらいか？これにはAPIエラーやツール呼び出しの失敗が含まれます。本番でこれらに対してエージェントをより堅牢にするために、フォールバックやリトライを設定できます。例えば、LLMプロバイダAがダウンした場合にバックアップとしてLLMプロバイダBに切り替える、などです。

**User Feedback（ユーザーフィードバック）:** 直接的なユーザー評価の実装は貴重な洞察を提供します。これには明示的な評価（👍thumbs-up/👎down、⭐1-5）やテキストコメントが含まれます。継続的なネガティブフィードバックはエージェントが期待どおりに機能していない兆候として警告します。

**Implicit User Feedback（暗黙のユーザーフィードバック）:** ユーザー行動は明示的な評価がなくても間接的なフィードバックを提供します。これには即時の質問の言い換え、同じクエリの繰り返し、リトライボタンのクリックなどが含まれます。例えば、ユーザーが同じ質問を繰り返し行っているのを見たら、それはエージェントが期待どおりに動作していない兆候です。

**Accuracy（正確性）:** エージェントはどのくらいの頻度で正しいまたは望ましい出力を生成するか？正確性の定義は用途により異なります（例：問題解決の正確さ、情報検索の精度、ユーザー満足度）。まずエージェントにとって成功が何を意味するかを定義します。自動チェック、評価スコア、タスク完了ラベルなどで正確性を追跡できます。例えば、トレースに「succeeded」または「failed」とマークするなどです。

**Automated Evaluation Metrics（自動化された評価指標）:** 自動評価を設定することもできます。例えば、LLMを用いてエージェントの出力が有用か正確かをスコア付けすることができます。また、エージェントのさまざまな側面をスコアリングするのに役立ついくつかのオープンソースライブラリもあります。例：RAGエージェント向けの [RAGAS](https://docs.ragas.io/) や、有害な言語やプロンプトインジェクションを検出する [LLM Guard](https://llm-guard.com/)。

実務では、これらの指標を組み合わせることでAIエージェントの健全性を最も包括的にカバーできます。本章の[example notebook](./code_samples/10_autogen_evaluation.ipynb)では、これらの指標が実際の例でどのように見えるかを示しますが、まず典型的な評価ワークフローを学びます。

## エージェントの計装（Instrumentation）

トレースデータを収集するには、コードに計装を施す必要があります。目標は、トレースやメトリクスを発行できるようにエージェントコードを計装し、それらを可観測性プラットフォームでキャプチャ、処理、可視化できるようにすることです。

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) はLLM可観測性の業界標準として浮上しています。これにより、テレメトリデータを生成、収集、エクスポートするためのAPI、SDK、ツールのセットが提供されます。

既存のエージェントフレームワークをラップし、OpenTelemetryスパンを可観測性ツールにエクスポートしやすくする計装ライブラリが多数あります。以下は、[OpenLit instrumentation library](https://github.com/openlit/openlit) を使ってAutoGenエージェントに計装を施す例です：

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

この章の[example notebook](./code_samples/10_autogen_evaluation.ipynb)では、AutoGenエージェントの計装方法を実演します。

**Manual Span Creation（手動スパン作成）:** 計装ライブラリは良いベースラインを提供しますが、より詳細またはカスタムな情報が必要なケースがしばしばあります。カスタムアプリケーションロジックを追加するためにスパンを手動で作成できます。さらに重要なのは、自動または手動で作成したスパンにカスタム属性（タグやメタデータとも呼ばれる）を付与して強化できることです。これらの属性には、業務固有のデータや中間計算、デバッグや分析に有用なコンテキスト（例：`user_id`、`session_id`、`model_version`）が含まれる場合があります。

[Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3) を使ってトレースとスパンを手動で作成する例：

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## エージェント評価

可観測性は指標を提供しますが、評価はそのデータを分析（およびテストの実行）して、AIエージェントがどれだけ性能を発揮しているか、どのように改善できるかを判断するプロセスです。言い換えれば、トレースや指標を得た後、それらをどのように使ってエージェントを評価し意思決定に結びつけるかということです。

AIエージェントは非決定的であり、更新やモデル挙動のドリフトにより進化することが多いため、定期的な評価が重要です — 評価がなければ「スマートなエージェント」が本当に役立っているのか、あるいは性能が低下しているのかを知ることができません。

AIエージェントの評価には、**オンライン評価**と**オフライン評価**の2つのカテゴリがあります。どちらも有用で相互補完的です。通常はオフライン評価から始めます。これはエージェントを展開する前の最低限必要なステップだからです。

### オフライン評価

![Langfuseのデータセット項目](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

これは制御された環境で、通常はテストデータセットを用いてエージェントを評価することを意味します。期待される出力や正しい振る舞いが分かっているキュレーションされたデータセットを使用してエージェントを実行します。

例えば、数学の文章題エージェントを構築した場合、既知の解答がある100問の[test dataset](https://huggingface.co/datasets/gsm8k)を持っているかもしれません。オフライン評価は開発中によく行われ（CI/CDパイプラインの一部にもなり得ます）、改善の確認や回帰の防止に役立ちます。利点は、**再現可能であり、正解があるため明確な精度指標を得られる**ことです。ユーザークエリをシミュレートしてエージェントの応答を理想的な解答と比較したり、前述の自動指標を使用したりすることができます。

オフライン評価の主な課題は、テストデータセットが包括的であり続けることを保証する点です — 固定のテストセットでうまく動作しても、本番では非常に異なるクエリに遭遇する可能性があります。したがって、テストセットを新しいエッジケースや実世界のシナリオを反映する例で更新し続けるべきです。小さな「スモークテスト」ケースと大きな評価セットの混合が有用です：迅速なチェック用の小さなセットと、より広範な性能指標のための大きなセットです。

### オンライン評価

![可観測性メトリクス概要](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

これは本番環境、つまり実使用中にエージェントを評価することを指します。オンライン評価は実際のユーザーインタラクションでのエージェント性能を継続的に監視・分析することを含みます。

例えば、ライブトラフィック上で成功率、ユーザー満足度スコア、その他の指標を追跡することができます。オンライン評価の利点は、**ラボ環境では想定しにくい事象を捉えられる**点です — 入力パターンの変化によるモデルドリフトを観察したり、テストデータにはなかった予期しないクエリや状況を検出したりできます。本番での実際の振る舞いが明確に分かります。

オンライン評価では、前述のように暗黙的および明示的なユーザーフィードバックを収集したり、シャドウテストやA/Bテスト（新バージョンを並行実行して古いバージョンと比較する）を実施したりすることがよくあります。課題は、ライブインタラクションに対して信頼できるラベルやスコアを得るのが難しい場合があることです — ユーザーフィードバックや下流のメトリクス（例：ユーザーが結果をクリックしたかどうか）に依存することがあります。

### 両者の組み合わせ

オンライン評価とオフライン評価は排他的ではなく、相互に補完します。オンライン監視からの洞察（例：エージェントが苦手とする新しいタイプのユーザークエリ）はオフラインのテストデータセットを拡充・改善するために利用できます。逆に、オフラインテストで良好なパフォーマンスを示したエージェントは、本番に自信を持ってデプロイされ、オンラインで監視されます。

多くのチームは次のようなループを採用しています：

_evaluate offline -> deploy -> monitor online -> collect new failure cases -> add to offline dataset -> refine agent -> repeat_.

## よくある問題

AIエージェントを本番にデプロイすると、さまざまな課題に直面することがあります。以下は一般的な問題とその可能な解決策です：

| **Issue**    | **Potential Solution**   |
| ------------- | ------------------ |
| AI Agent not performing tasks consistently | - Refine the prompt given to the AI Agent; be clear on objectives.<br>- Identify where dividing the tasks into subtasks and handling them by multiple agents can help. |
| AI Agent running into continuous loops  | - Ensure you have clear termination terms and conditions so the Agent knows when to stop the process.<br>- For complex tasks that require reasoning and planning, use a larger model that is specialized for reasoning tasks. |
| AI Agent tool calls are not performing well   | - Test and validate the tool's output outside of the agent system.<br>- Refine the defined parameters, prompts, and naming of tools.  |
| Multi-Agent system not performing consistently | - Refine prompts given to each agent to ensure they are specific and distinct from one another.<br>- Build a hierarchical system using a "routing" or controller agent to determine which agent is the correct one. |

これらの多くの問題は、可観測性を導入することでより効果的に特定できます。前述のトレースやメトリクスにより、エージェントワークフローのどの箇所で問題が発生しているかを正確に突き止められるため、デバッグと最適化が大幅に効率化されます。

## コスト管理
以下は、AIエージェントを本番環境にデプロイする際のコストを管理するためのいくつかの戦略です。

**小規模モデルの使用:** 小規模言語モデル (SLMs) は、特定のエージェント的ユースケースで十分に機能し、コストを大幅に削減できます。前述のとおり、パフォーマンスを評価し大規模モデルと比較する評価システムを構築することが、SLM があなたのユースケースでどの程度機能するかを理解する最善の方法です。インテント分類やパラメータ抽出のようなより単純なタスクには SLM を使用し、複雑な推論には大規模モデルを温存することを検討してください。

**ルーターモデルの利用:** 同様の戦略として、さまざまなモデルやサイズを使い分ける方法があります。LLM/SLM やサーバーレス関数を使って、リクエストの複雑さに応じて最適なモデルにルーティングすることができます。これにより、コストを削減しつつ、適切なタスクでのパフォーマンスを確保できます。例えば、単純なクエリはより小さく高速なモデルにルーティングし、複雑な推論タスクに対してのみ高価な大規模モデルを使用する、という運用が考えられます。

**レスポンスのキャッシュ:** よくあるリクエストやタスクを特定し、それらがエージェント処理を通る前に応答を返すことは、類似リクエストの総数を減らす良い方法です。より基本的な AI モデルを使って、あるリクエストがキャッシュされたリクエストとどの程度類似しているかを判定するフローを実装することもできます。この戦略は、頻繁に問い合わせのある質問や一般的なワークフローに対するコストを大幅に削減できます。

## 実際にどのように機能するか見てみましょう

このセクションの[サンプルノートブック](./code_samples/10_autogen_evaluation.ipynb)では、可観測性ツールを使用してエージェントを監視および評価する方法の例を示します。


### 本番環境のAIエージェントについてさらに質問がありますか？

他の学習者と交流したり、オフィスアワーに参加したり、AI エージェントに関する質問に答えてもらうには、[Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) に参加してください。

## 前のレッスン

[メタ認知デザインパターン](../09-metacognition/README.md)

## 次のレッスン

[エージェントプロトコル](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
免責事項：
本書はAI翻訳サービス「Co-op Translator」（https://github.com/Azure/co-op-translator）を使用して翻訳されました。正確さを期していますが、自動翻訳には誤りや不正確な点が含まれる可能性があることをご承知おきください。重要な情報については、原文（原言語の文書）を正本とみなし、専門の人による翻訳をお勧めします。本翻訳の利用により生じた誤解や解釈の相違については責任を負いかねます。
<!-- CO-OP TRANSLATOR DISCLAIMER END -->