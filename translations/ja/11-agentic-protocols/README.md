# エージェントプロトコルの使用 (MCP, A2A and NLWeb)

[![エージェントプロトコル](../../../translated_images/ja/lesson-11-thumbnail.b6c742949cf1ce2a.webp)](https://youtu.be/X-Dh9R3Opn8)

> _(上の画像をクリックしてこのレッスンの動画を視聴してください)_

AIエージェントの利用が拡大するにつれて、標準化、セキュリティ、オープンイノベーションを支援するプロトコルの必要性も高まっています。このレッスンでは、そのニーズに応えようとする 3 つのプロトコル—Model Context Protocol (MCP)、Agent to Agent (A2A)、および Natural Language Web (NLWeb)—について説明します。

## はじめに

このレッスンでは、次の内容を扱います：

• **MCP** が AI エージェントに外部ツールやデータへアクセスさせ、ユーザーのタスクを完了させる仕組み。

• **A2A** が異なる AI エージェント間の通信と協働を可能にする方法。

• **NLWeb** が任意のウェブサイトに自然言語インターフェースをもたらし、AI エージェントがコンテンツを発見して操作できるようにする方法。

## 学習目標

• **識別する**: AI エージェントの文脈における MCP、A2A、NLWeb の主要な目的と利点を識別する。

• **説明する**: 各プロトコルがどのように LLM、ツール、および他のエージェント間の通信と相互作用を促進するかを説明する。

• **認識する**: 複雑なエージェントシステムを構築する上で各プロトコルが担う異なる役割を認識する。

## モデルコンテキストプロトコル

Model Context Protocol (MCP) は、アプリケーションが LLM にコンテキストやツールを提供するための標準化された方法を提供するオープン標準です。これにより AI エージェントが一貫した方法で接続できる「ユニバーサルアダプタ」として、さまざまなデータソースやツールに対応できます。

ここでは MCP の構成要素、直接 API を利用する場合との利点の比較、そして AI エージェントが MCP サーバーをどのように利用するかの例を見ていきます。

### MCP のコア構成要素

MCP は **クライアント - サーバーアーキテクチャ** で動作し、コアコンポーネントは次のとおりです：

• **Hosts** は MCP サーバーへの接続を開始する LLM アプリケーション（例：VSCode のようなコードエディタ）です。

• **Clients** はホストアプリケーション内のコンポーネントで、サーバーとの一対一の接続を維持します。

• **Servers** は特定の機能を公開する軽量プログラムです。

プロトコルには MCP サーバーの機能である 3 つのコアプリミティブが含まれます：

• **Tools**: これらは AI エージェントが呼び出してアクションを実行できる個別の操作や関数です。例えば、天気サービスは「天気を取得する」ツールを公開したり、e コマースサーバーは「商品を購入する」ツールを公開したりします。MCP サーバーは各ツールの名前、説明、および入力/出力スキーマを機能一覧で宣伝します。

• **Resources**: これらは MCP サーバーが提供できる読み取り専用のデータ項目やドキュメントで、クライアントは必要に応じてそれらを取得できます。例としてはファイルの内容、データベースレコード、ログファイルなどがあります。Resources はテキスト（コードや JSON のような）やバイナリ（画像や PDF のような）になり得ます。

• **Prompts**: これらは提案プロンプトを提供する事前定義されたテンプレートで、より複雑なワークフローを可能にします。

### MCP の利点

MCP は AI エージェントにとって重要な利点を提供します：

• **Dynamic Tool Discovery**: エージェントはサーバーから利用可能なツールの一覧とそれが何をするかの説明を動的に受け取ることができます。これは統合に静的なコーディングを必要とする従来の API とは対照的で、API の変更があればコードの更新が必要になります。MCP は「一度統合する」アプローチを提供し、適応性を高めます。

• **Interoperability Across LLMs**: MCP は異なる LLM 間で動作するため、コアモデルを切り替えてより良いパフォーマンスを評価する柔軟性を提供します。

• **Standardized Security**: MCP は標準的な認証方法を含んでおり、追加の MCP サーバーへのアクセスを追加する際のスケーラビリティを向上させます。これはさまざまな従来の API に対する異なるキーや認証タイプを管理するよりも簡潔です。

### MCP の例

![MCP ダイアグラム](../../../translated_images/ja/mcp-diagram.e4ca1cbd551444a1.webp)

ユーザーが MCP を利用する AI アシスタントを使ってフライトを予約したいと想像してみましょう。

1. **Connection**: AI アシスタント（MCP クライアント）は航空会社が提供する MCP サーバーに接続します。

2. **Tool Discovery**: クライアントは航空会社の MCP サーバーに「どんなツールが利用可能ですか？」と尋ねます。サーバーは「フライト検索」や「フライト予約」などのツールを返します。

3. **Tool Invocation**: 次に、あなたが AI アシスタントに「ポートランドからホノルルへのフライトを検索して」と依頼します。AI アシスタントはその LLM を用いて「フライト検索」ツールを呼び出す必要があると判断し、関連するパラメーター（出発地、目的地）を MCP サーバーに渡します。

4. **Execution and Response**: MCP サーバーはラッパーとして実際に航空会社の内部予約 API を呼び出します。そしてフライト情報（例えば JSON データ）を受け取り、それを AI アシスタントに返します。

5. **Further Interaction**: AI アシスタントはフライトのオプションを提示します。あなたがフライトを選択すると、アシスタントは同じ MCP サーバー上の「フライト予約」ツールを呼び出して予約を完了するかもしれません。

## Agent-to-Agent Protocol (A2A)

MCP が LLM をツールに接続することに焦点を当てる一方で、**Agent-to-Agent (A2A) プロトコル** はさらに一歩進んで、異なる AI エージェント間の通信と協働を可能にします。A2A は異なる組織、環境、技術スタックにまたがる AI エージェントを接続して、共有タスクを完了させます。

ここでは A2A の構成要素と利点、旅行アプリケーションでの適用例を見ていきます。

### A2A のコア構成要素

A2A はエージェント間の通信を可能にし、ユーザーのサブタスクを共同で完了させることに重点を置いています。プロトコルの各コンポーネントはこれに寄与します：

#### Agent Card

MCP サーバーがツールの一覧を共有するのと似て、Agent Card には次のような情報が含まれます：
- エージェントの名前
- そのエージェントが一般的に行うタスクの説明
- 他のエージェント（あるいは人間のユーザー）に対して、そのエージェントを呼び出すべき状況や理由を理解してもらうための、説明付きの具体的なスキルのリスト
- エージェントの現在のエンドポイント URL
- ストリーミング応答やプッシュ通知などの、エージェントのバージョンや機能

#### Agent Executor

Agent Executor は、**ユーザーチャットのコンテキストをリモートエージェントに渡す** 役割を担います。リモートエージェントはこれを必要として、完了すべきタスクを理解します。A2A サーバーでは、エージェントが自分自身の Large Language Model (LLM) を使って受信リクエストを解析し、自身の内部ツールを用いてタスクを実行します。

#### Artifact

リモートエージェントが要求されたタスクを完了すると、その成果物はアーティファクトとして作成されます。アーティファクトはエージェントの作業結果、完了した内容の説明、およびプロトコルを通じて送信されたテキストコンテキストを含みます。アーティファクトが送信された後、リモートエージェントとの接続は再度必要になるまで切断されます。

#### Event Queue

このコンポーネントは更新の処理やメッセージの受け渡しに使用されます。タスク完了に時間がかかる場合でも、エージェント間の接続がタスク完了前に閉じられるのを防ぐために、エージェントシステムを本番環境で運用する際に特に重要です。

### A2A の利点

• **Enhanced Collaboration**: 異なるベンダーやプラットフォームのエージェントが相互にやり取りし、コンテキストを共有し協働できるようにし、従来は切り離されていたシステム間でシームレスな自動化を促進します。

• **Model Selection Flexibility**: 各 A2A エージェントは自身がリクエストに応答するために使用する LLM を選択でき、エージェントごとに最適化されたモデルやファインチューニングされたモデルを利用できます。これは一部の MCP シナリオでの単一 LLM 接続とは異なります。

• **Built-in Authentication**: 認証は A2A プロトコルに直接組み込まれており、エージェント間のやり取りに対する堅牢なセキュリティフレームワークを提供します。

### A2A の例

![A2A ダイアグラム](../../../translated_images/ja/A2A-Diagram.8666928d648acc26.webp)

旅行予約シナリオを拡張して、今回は A2A を使う場合を考えてみましょう。

1. **User Request to Multi-Agent**: ユーザーは「来週ホノルルへのフライト、ホテル、レンタカーを含む旅行全体を予約して」といったリクエストを "Travel Agent" A2A クライアント/エージェントに行うかもしれません。

2. **Orchestration by Travel Agent**: Travel Agent はこの複雑なリクエストを受け取ります。自身の LLM を使ってタスクを推論し、他の専門エージェントと連携する必要があると判断します。

3. **Inter-Agent Communication**: Travel Agent は A2A プロトコルを使って、異なる企業が作成した "Airline Agent"、"Hotel Agent"、"Car Rental Agent" などの下流エージェントに接続します。

4. **Delegated Task Execution**: Travel Agent はこれらの専門エージェントに「ホノルル行きのフライトを探して」「ホテルを予約して」「レンタカーを手配して」などの具体的なタスクを送信します。各専門エージェントは自分の LLM を実行し、必要に応じて自身のツール（それらが MCP サーバーである可能性もあります）を利用して、予約の一部を実行します。

5. **Consolidated Response**: 下流のすべてのエージェントがタスクを完了すると、Travel Agent は結果（フライトの詳細、ホテルの確認、レンタカーの予約）をまとめ、包括的なチャット形式の応答をユーザーに返します。

## Natural Language Web (NLWeb)

ウェブサイトは長らく、ユーザーがインターネット上の情報やデータにアクセスする主要な手段でした。

ここでは NLWeb のさまざまな構成要素、利点、および旅行アプリケーションを例にして NLWeb がどのように機能するかを見ていきます。

### NLWeb の構成要素

- **NLWeb Application (Core Service Code)**: 自然言語の質問を処理するシステムです。プラットフォームのさまざまな部分を結びつけて応答を作成します。ウェブサイトの自然言語機能を動かす「エンジン」と考えることができます。

- **NLWeb Protocol**: ウェブサイトとの自然言語インタラクションのための基本的なルールセットです。JSON 形式（多くの場合 Schema.org を使用）で応答を返します。その目的は、HTML がドキュメントをオンラインで共有可能にしたのと同様に、「AI Web」のためのシンプルな基盤を作ることです。

- **MCP Server (Model Context Protocol Endpoint)**: 各 NLWeb 設定は MCP サーバーとしても動作します。つまり、他の AI システムとツール（「ask」メソッドなど）やデータを共有できるということです。実際には、これによりウェブサイトのコンテンツと機能が AI エージェントに利用可能になり、サイトがより広い「エージェントエコシステム」の一部となります。

- **Embedding Models**: これらのモデルはウェブサイトのコンテンツをベクトル（埋め込み）と呼ばれる数値表現に変換するために使用されます。これらのベクトルは意味をコンピュータが比較・検索できる形で捉えます。ベクトルは専用のデータベースに保存され、ユーザーは使用する埋め込みモデルを選択できます。

- **Vector Database (Retrieval Mechanism)**: このデータベースはウェブサイトコンテンツの埋め込みを保存します。誰かが質問をしたとき、NLWeb はベクトルデータベースをチェックして最も関連性の高い情報を迅速に見つけます。類似度に基づいてランク付けされた候補を高速に返します。NLWeb は Qdrant、Snowflake、Milvus、Azure AI Search、Elasticsearch など、さまざまなベクトルストレージシステムと連携します。

### NLWeb の例

![NLWeb](../../../translated_images/ja/nlweb-diagram.c1e2390b310e5fe4.webp)

改めて旅行予約のウェブサイトを考えてみましょう。今回はそのサイトが NLWeb によって強化されているとします。

1. **Data Ingestion**: 旅行サイトの既存の製品カタログ（例：フライト一覧、ホテルの説明、ツアーパッケージ）は Schema.org を使ってフォーマットするか、RSS フィード経由で読み込まれます。NLWeb のツールはこの構造化データを取り込み、埋め込みを作成してローカルまたはリモートのベクトルデータベースに保存します。

2. **Natural Language Query (Human)**: ユーザーがサイトを訪れ、メニューを辿る代わりにチャットインターフェースに「来週のホノルルでプールがあって家族向けのホテルを探して」と入力します。

3. **NLWeb Processing**: NLWeb アプリケーションはこのクエリを受信します。クエリを理解するために LLM に送信すると同時に、関連するホテルのリスティングを探すために自分のベクトルデータベースを検索します。

4. **Accurate Results**: LLM はデータベースの検索結果を解釈するのを助け、「家族向け」「プール」「ホノルル」といった条件に基づいて最適な一致を特定し、自然言語の応答に整形します。重要なのは、応答がサイトのカタログにある実際のホテルを参照しており、捏造された情報を避けている点です。

5. **AI Agent Interaction**: NLWeb が MCP サーバーとして機能するため、外部の AI 旅行エージェントもこのサイトの NLWeb インスタンスに接続できます。AI エージェントは `ask("Are there any vegan-friendly restaurants in the Honolulu area recommended by the hotel?")` のように `ask` MCP メソッドを使ってサイトに直接問い合わせることができます。NLWeb インスタンスは、（ロードされていれば）レストラン情報のデータベースを活用してこれを処理し、構造化された JSON 応答を返します。

### MCP/A2A/NLWeb に関してさらに質問がありますか？

ご質問がある場合は、[Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) に参加して他の学習者と交流したり、オフィスアワーに参加したりして、AI エージェントに関する質問の回答を得てください。

## リソース

- [MCP for Beginners](https://aka.ms/mcp-for-beginners)  
- [MCP Documentation](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic-kernel/semantic_kernel/connectors/mcp)
- [NLWeb Repo](https://github.com/nlweb-ai/NLWeb)
- [Semantic Kernel Guides](https://learn.microsoft.com/semantic-kernel/)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
免責事項：
この文書は、AI翻訳サービス「Co-op Translator」(https://github.com/Azure/co-op-translator) を使用して翻訳されました。正確を期していますが、自動翻訳には誤りや不正確な点が含まれる場合がありますのでご注意ください。原文（原言語の文書）を権威ある正本として扱ってください。重要な情報については、専門の人による翻訳を推奨します。本翻訳の利用により生じた誤解や解釈の相違について、当方は一切責任を負いません。
<!-- CO-OP TRANSLATOR DISCLAIMER END -->