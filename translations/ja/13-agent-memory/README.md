# AI エージェントのメモリ 
[![エージェントのメモリ](../../../translated_images/ja/lesson-13-thumbnail.959e3bc52d210c64.webp)](https://youtu.be/QrYbHesIxpw?si=qNYW6PL3fb3lTPMk)

AIエージェントを作成することのユニークな利点を論じるとき、主に2つの点が議論されます：タスクを完了するためにツールを呼び出す能力と、時間とともに改善する能力です。メモリは、自己改善するエージェントを作成し、ユーザーにより良い体験を提供するための基盤です。

このレッスンでは、AIエージェントのメモリとは何か、それをどのように管理し、アプリケーションの利益のために活用できるかを見ていきます。

## はじめに

このレッスンでは以下を扱います：

• **AIエージェントのメモリの理解**：メモリとは何か、なぜエージェントにとって不可欠なのか。

• **メモリの実装と保存**：短期メモリと長期メモリに焦点を当て、AIエージェントにメモリ機能を追加する実践的方法。

• **AIエージェントを自己改善させる方法**：メモリがどのように過去のインタラクションから学習し、時間とともに改善を可能にするか。

## 利用可能な実装

このレッスンには2つの包括的なノートブックチュートリアルが含まれます：

• **[13-agent-memory.ipynb](./13-agent-memory.ipynb)**：Mem0とAzure AI SearchをSemantic Kernelフレームワークで使用してメモリを実装します

• **[13-agent-memory-cognee.ipynb](./13-agent-memory-cognee.ipynb)**：Cogneeを用いて構造化メモリを実装し、埋め込みに支えられた知識グラフを自動構築、グラフの可視化、インテリジェントな検索を行います

## 学習目標

このレッスンを修了した後、あなたは以下を理解できるようになります：

• **作業メモリ、短期メモリ、長期メモリなど、さまざまな種類のAIエージェントメモリを区別する方法**。ペルソナやエピソード記憶のような特殊な形式も含みます。

• **Semantic Kernelフレームワークを使用してAIエージェントの短期メモリと長期メモリを実装・管理する方法**。Mem0、Cognee、WhiteboardメモリなどのツールやAzure AI Searchとの統合を活用します。

• **自己改善するAIエージェントの原則**と、堅牢なメモリ管理システムが継続的な学習と適応にどのように貢献するかを理解すること。

## AIエージェントのメモリを理解する

本質的に、**AIエージェントのメモリとは、情報を保持して想起できるようにする仕組みを指します**。この情報は会話の特定の詳細、ユーザーの好み、過去の行動、あるいは学習したパターンであることがあります。

メモリがないと、AIアプリケーションはしばしばステートレスになり、各インタラクションがゼロから始まります。これはエージェントが以前の文脈や好みを「忘れて」しまうため、繰り返しがちでフラストレーションのたまるユーザー体験につながります。

### なぜメモリが重要なのか？

エージェントの知能は過去の情報を想起し活用する能力に深く結びついています。メモリによりエージェントは以下のことが可能になります：

• **省察的**：過去の行動や結果から学習する。

• **対話的**：進行中の会話で文脈を維持する。

• **先読みと反応**：履歴データに基づいてニーズを予測したり適切に応答したりする。

• **自律的**：蓄積した知識を引き出すことでより独立して動作する。

メモリを実装する目的は、エージェントをより**信頼性が高く、有能にする**ことです。

### メモリの種類

#### 作業メモリ

これは、エージェントが単一の進行中のタスクや思考過程で使用するスクラッチペーパーのようなものだと考えてください。次のステップを計算するために必要な即時情報を保持します。

AIエージェントにとって、作業メモリは会話から最も関連性の高い情報を捉えることが多く、チャット履歴が長いまたは切り詰められている場合でも重要な要素を抽出します。要件、提案、決定、アクションなどのキーメッセージの抽出に焦点を当てます。

**作業メモリの例**

旅行予約エージェントでは、作業メモリはユーザーの現在のリクエスト（例："I want to book a trip to Paris"）を捉えるかもしれません。この具体的な要件は現在のやりとりを導くためにエージェントの直近の文脈に保持されます。

#### 短期メモリ

このタイプのメモリは単一の会話やセッションの間、情報を保持します。現在のチャットの文脈であり、エージェントが対話内の以前のターンを参照できるようにします。

**短期メモリの例**

ユーザーが「How much would a flight to Paris cost?」と尋ね、その後に「What about accommodation there?」と続けた場合、短期メモリによりエージェントは同じ会話内で「there」が「Paris」を指していることを把握します。

#### 長期メモリ

これは複数の会話やセッションにわたって持続する情報です。ユーザーの好み、過去のやりとり、あるいは長期にわたる一般的な知識を記憶することで、パーソナライズ化を可能にします。

**長期メモリの例**

長期メモリは「Benはスキーやアウトドア活動を楽しみ、山の景色のあるコーヒーが好きで、過去の怪我のため上級コースを避けたい」というような情報を保存するかもしれません。これらは過去のやりとりから学習された情報で、将来の旅行計画の推奨に影響を与え、非常にパーソナライズされた提案を可能にします。

#### ペルソナメモリ

この特殊なメモリタイプは、エージェントが一貫した「性格」や「ペルソナ」を持つのを助けます。エージェント自身やその想定される役割についての詳細を覚えておくことで、やりとりがより流暢で焦点の定まったものになります。

**ペルソナメモリの例**
旅行エージェントが「スキーの専門家」として設計されている場合、ペルソナメモリはこの役割を強化し、応答が専門家の口調や知識に沿うように影響します。

#### ワークフロー/エピソードメモリ

このメモリは、複雑なタスク中にエージェントが取る一連のステップ（成功や失敗を含む）を保存します。特定の「エピソード」や過去の経験を記憶して学習するようなものです。

**エピソードメモリの例**

エージェントが特定のフライトを予約しようとしたが空席がなく失敗した場合、エピソードメモリはこの失敗を記録し、次回の試行時に代替フライトを試す、あるいはユーザーにより情報に基づいた形で問題を報告することを可能にします。

#### エンティティメモリ

これは会話から特定のエンティティ（人、場所、物など）や出来事を抽出して記憶することを含みます。エージェントが議論された主要要素の構造化された理解を構築できるようにします。

**エンティティメモリの例**

過去の旅行に関する会話から、エージェントは「Paris」「Eiffel Tower」「dinner at Le Chat Noir restaurant」などをエンティティとして抽出するかもしれません。将来のやりとりで、エージェントは「Le Chat Noir」を思い出して、そこへの新しい予約を提案することができます。

#### 構造化RAG（Retrieval Augmented Generation）

RAGはより広い手法ですが、「構造化RAG」は強力なメモリ技術として強調されます。これは会話、メール、画像などさまざまなソースから緻密で構造化された情報を抽出し、それを応答の精度、検索力、速度の向上に利用します。単に意味的類似性に依存する従来のRAGとは異なり、構造化RAGは情報の固有の構造を活用します。

**構造化RAGの例**

キーワードの単純な一致だけでなく、構造化RAGはメールからフライトの詳細（目的地、日付、時刻、航空会社）を解析して構造化された形で保存できます。これにより「火曜日にパリ行きでどのフライトを予約したか？」のような正確な照会が可能になります。

## メモリの実装と保存

AIエージェントのメモリを実装するには、生成、保存、検索、統合、更新、さらには「忘却」（削除）を含む体系的なプロセスである**メモリ管理**が必要です。特に重要なのは検索（リトリーバル）です。

### 専門的なメモリツール

#### Mem0

エージェントのメモリを保存・管理する一つの方法はMem0のような専門ツールを使うことです。Mem0は永続的なメモリ層として機能し、エージェントが関連するやりとりを想起し、ユーザーの好みや事実的な文脈を保存し、成功や失敗から学習することを可能にします。ここでの考え方は、ステートレスなエージェントをステートフルに変えることです。

Mem0は**抽出と更新の2段階メモリパイプライン**を通じて動作します。まず、エージェントのスレッドに追加されたメッセージはMem0サービスに送られ、LLMを使用して会話履歴を要約し、新しいメモリを抽出します。その後、LLM駆動の更新フェーズにより、これらのメモリを追加、修正、削除するかどうかが判断され、ベクトル、グラフ、キー・バリューのデータベースを含むハイブリッドデータストアに保存されます。このシステムはさまざまなメモリタイプをサポートし、エンティティ間の関係を管理するためのグラフメモリを組み込むこともできます。

#### Cognee

もう一つの強力なアプローチは**Cognee**を使うことです。Cogneeはオープンソースのエージェント向けセマンティックメモリで、構造化データと非構造化データを埋め込みに基づくクエリ可能な知識グラフに変換します。Cogneeはベクトル類似検索とグラフ関係を組み合わせた**デュアルストアアーキテクチャ**を提供し、エージェントが情報の類似性だけでなく概念同士の関係も理解できるようにします。

Cogneeはベクトル類似性、グラフ構造、LLM推論を融合させる**ハイブリッドリトリーバル**に優れており、生のチャンク検索からグラフ対応の質問応答まで対応します。システムはクエリ可能な一つの接続されたグラフとして進化し成長する**生きたメモリ**を維持し、短期セッションコンテキストと長期永続メモリの両方をサポートします。

Cogneeのノートブックチュートリアル（[13-agent-memory-cognee.ipynb](./13-agent-memory-cognee.ipynb)）は、この統一メモリ層の構築を示し、多様なデータソースの取り込み、知識グラフの可視化、エージェントのニーズに合わせた異なる検索戦略でのクエリの実例を提供します。

### RAGを用いたメモリの保存

mem0 , のような専門的なメモリツールに加えて、特に構造化RAGのために、**Azure AI Searchをメモリの保存と取得のバックエンドとして活用する**ことができます。

これにより、エージェントの応答を独自データで裏付けることができ、より関連性が高く正確な回答を保証します。Azure AI Searchはユーザー固有の旅行メモリ、製品カタログ、あるいはその他のドメイン固有の知識を保存するために使用できます。

Azure AI Searchは会話履歴、メール、画像など大規模データセットから濃密で構造化された情報を抽出・検索する**構造化RAG**のような機能をサポートします。これは従来のテキストチャンク化や埋め込みアプローチと比べて「人間を超えた精度と検索力」を提供します。

## AIエージェントを自己改善させる

自己改善するエージェントの一般的なパターンとして、**「ナレッジエージェント」**を導入することがあります。この別のエージェントは、ユーザーと主要エージェントとの会話を観察します。その役割は次のとおりです：

1. **価値のある情報を特定する**：会話のどの部分が一般的な知識や特定のユーザーの好みとして保存する価値があるかを判断する。

2. **抽出と要約**：会話から本質的な学びや好みを抽出して要約する。

3. **ナレッジベースに保存する**：抽出した情報をベクトルデータベースに保存するなどして永続化し、後で取り出せるようにする。

4. **将来のクエリを補強する**：ユーザーが新しいクエリを開始したとき、ナレッジエージェントは関連する保存情報を取り出してユーザーのプロンプトに付加し、主要エージェントに重要な文脈を提供する（RAGに類似）。

### メモリの最適化

• **レイテンシ管理**：ユーザーインタラクションを遅延させないために、最初はより安価で高速なモデルを使用して情報を保存・取得する価値があるかを素早くチェックし、必要な場合にのみより複雑な抽出/検索プロセスを呼び出すことができます。

• **ナレッジベースの保守**：増大するナレッジベースに対しては、使用頻度の低い情報をコスト管理のために「コールドストレージ」に移動することができます。

## エージェントのメモリについてもっと質問がありますか？

他の学習者と出会い、オフィスアワーに参加し、AIエージェントに関する質問に答えを得るには [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) に参加してください。

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
免責事項：
本書は AI 翻訳サービス「Co-op Translator」(https://github.com/Azure/co-op-translator) を用いて翻訳されました。正確性には努めていますが、自動翻訳には誤りや不正確な表現が含まれる可能性があります。原文（原言語の文書）を正式な情報源としてご確認ください。重要な内容については、専門の人による翻訳を推奨します。本翻訳の利用により生じた誤解や解釈の相違について、当方は一切の責任を負いません。
<!-- CO-OP TRANSLATOR DISCLAIMER END -->