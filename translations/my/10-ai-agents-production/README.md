# ထုတ်လုပ်မှုရှိ AI အေးဂျင့်များ: ထောက်လှမ်းနိုင်ခြင်းနှင့် အကဲဖြတ်ခြင်း

[![ထုတ်လုပ်မှုရှိ AI အေးဂျင့်များ](../../../translated_images/my/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

AI အေးဂျင့်များကို ဓါတ်ပုံနှင့် စမ်းသပ်ပုံစံများမှ တကယ့်ကမ္ဘာအသုံးပြုမှုသို့ ရောက်ရှိလာစဉ်၊ ၎င်းတို့၏ ပြုမူမှုကို နားလည်ခြင်း၊ စွမ်းဆောင်ရည်ကို စောင့်ကြည့်ခြင်းနှင့် ထွက်လာသော အဖြေများကို စနစ်တကျ အကဲဖြတ်နိုင်ရေးဖြစ်စေသည့် စွမ်းရည်သည် အရေးကြီး ဖြစ်လာသည်။

## သင်ယူရန် ရည်မှန်းချက်များ

ဤသင်ခန်းစာကို ပြီးမြောက်ပြီးနောက် သင်သည် အောက်ပါများကို သိရှိ/နားလည်ထားပါလိမ့်မည်။
- အေးဂျင့် ထောက်လှမ်းနိုင်ခြင်းနှင့် အကဲဖြတ်မှု၏ အဓိက အယူအဆများ
- အေးဂျင့်များ၏ စွမ်းဆောင်ရည်၊ ကုန်ကျစရိတ်နှင့် ထိရောက်မှုကို တိုးတက်စေရန်နည်းလမ်းများ
- သင့် AI အေးဂျင့်များကို ဘာတွေကို၊ ဘယ်လိုစနစ်တကျ အကဲဖြတ်ရမည်နည်း
- AI အေးဂျင့်များကို ထုတ်လုပ်မှုသို့ ထည့်သွင်းရာတွင် ကုန်ကျစရိတ်ကို ထိန်းချုပ်နည်း
- AutoGen ဖြင့် တည်ဆောက်ထားသော အေးဂျင့်များကို ဘယ်လို တပ်ဆင် (instrument) မှတ်တမ်းယူရမည်နည်း

ရည်မှန်းချက်မှာ သင့် "အမှောင်ဘူး" အေးဂျင့်များကို ဖန်တီးရင်း ထူးခြားပိုင်နက်ရှိ၊ စီမံခန့်ခွဲရ လွယ်ကူပြီး ယုံကြည်စိတ်ချရသော စနစ်များအဖြစ် ပြောင်းလဲနိုင်ရန် ဗဟုသုတပေးရန် ဖြစ်သည်။

_**မှတ်ချက်။**_ AI အေးဂျင့်များကို ဘေးကင်း၍ ယုံကြည်စိတ်ချရအောင် ထုတ်လုပ်မှုတွင် ထည့်သွင်းရန် အရေးကြီးသည်။ [Building Trustworthy AI Agents](./06-building-trustworthy-agents/README.md) သင်ခန်းစာကိုလည်း ကြည့်ပါ။

## Traces and Spans

[Langfuse](https://langfuse.com/) သို့မဟုတ် [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) ကဲ့သို့သော ထောက်လှမ်းစောင့်ကြည့်စနစ်များမှာ အေးဂျင့်၏ လည်ပတ်မှုများကို အများအားဖြင့် trace နှင့် span များအဖြစ် ကိုယ်စားပြုသည်။

- **Trace** သည် စတင်မှပြီးဆုံးအထိ အေးဂျင့်၏ ပြည့်စုံသော တာဝန်တစ်ခုကို ကိုယ်စားပြုသည် (အသုံးပြုသူမေးခွန်းကို 처리ခြင်း ကဲ့သို့)။
- **Spans** သည် trace အတွင်းရှိ တစ်ခုချင်းစီသော အဆင့်များဖြစ်သည် (LLM ကို ခေါ်ဆိုခြင်း သို့မဟုတ္ ဒေတာ ရယူခြင်း ကဲ့သို့)။

![Langfuse တွင် Trace သစ်ပင်](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

ထောက်လှမ်းစက်မရှိပါက AI အေးဂျင့်တစ်ခုကို "အမှောင်ဘူး" ကဲ့သို့ ခံစားရနိုင်သည် - ၎င်း၏ အတွင်းရေးအခြေအနေ၊ ချဉ်းကပ်ချက်များကို မမြင်ရသောကြောင့် ပြဿနာ ရှာဖွေခြင်း သို့မဟုတ် စွမ်းဆောင်ရည် အထူးပြုပြင်မှုများ ပြုလုပ်ရန် ခက်ခဲတတ်သည်။ ထောက်လှမ်းစနစ်ဖြင့် အေးဂျင့်များသည် "ဖန်လင်းပုံး" အဖြစ် ပြောင်းလဲလာကာ ယုံကြည်စိတ်ချမှုတည်ဆောက်ရန်နှင့် ရည်ရွယ်ချက်အတိုင်း လည်ပတ်စေရန် အလွန်အရေးကြီးသည့် ဖော်ပြချက်များကို ပေးစွမ်းနိုင်သည်။

## ထုတ်လုပ်မှုပတ်ဝန်းကျင်များတွင် ထောက်လှမ်းနိုင်ခြင်း ကအရေးကြီးသည့် အကြောင်းရင်း

AI အေးဂျင့်များကို ထုတ်လုပ်မှုသို့ ကူးပြောင်းရာတွင် အစုံအလင် စိန်ခေါ်မှုများနှင့် လိုအပ်ချက်အသစ်များ ရှိလာသည်။ ထောက်လှမ်းနိုင်ခြင်းသည် "ရှိသင့်သော" အရာမှ အရေးပါသော စွမ်းဆောင်ရည်တစ်ခုဖြစ်လာသည်။

*   **ကဒ်ဂျစ်နှင့် အမှန်တရား ရှာဖွေရေး (Debugging and Root-Cause Analysis):** အေးဂျင့် လုပ်မိမှုမမှန်ပါက သို့မဟုတ် မမှန်သော ရလဒ် များပေါ်လာပါက ထောက်လှမ်းစက်က သွားရောက်ကြည့်ရန် trace များပေးကူပေးသည်။ ၎င်းသည် หลาย LLM ခေါ်ဆိုမှုများ၊ ကိရိယာ အပြန်အလှန် လုပ်ဆောင်မှုများ နှင့် အခြေအနေဆိုင်ရာ သဘောတရားများ ပါဝင်နိုင်သည့် များပြားသော agent များ၌ အထူးအရေးကြီးသည်။
*   **နောက်ကျချိန်နှင့် ကုန်ကျစရိတ် စီမံခြင်း:** AI အေးဂျင့်များသည် token အလိုက် သို့မဟုတ် ခေါ်ဆိုမှုအလိုက် ငွေကြေး ထမ်းဆောင်သည့် LLM များနှင့် အခြား API များအား များအား အသုံးပြုတတ်သည်။ ထောက်လှမ်းစနစ်က ဤခေါ်ဆိုမှုများကို တိကျစွာ မှတ်တမ်းတင်ရန် အခွင့်အလမ်းပေးပြီး နောက်ကျချိန် သို့မဟုတ် အသင့်မဟုတ်သော ငွေကြေးစရိတ် ကဲ့သို့သော အလုပ်များကို ထောက်လိုက်နိုင်စေသည်။ ၎င်းက prompt များကို တိုးတက်စေရန်၊ ပိုမိုထိရောက်သော မော်ဒယ်များ ရွေးချယ်ရန် သို့မဟုတ် အလုပ်စဉ်များကို ပြန်လည်ออกแบบရန် အဖွဲ့များကို အကူအညီပေးသည်။
*   **ယုံကြည်မှု၊ ဘေးမဲ့ခြင်းနှင့် အညီအမျှလိုက်နာမှု:** အက်ပလီကေးရှင်းအများအပြားတွင် အေးဂျင့်များက လုံခြုံစိတ်ချရ၍ ကိုက်ညီစေရန် အရေးကြီးသည်။ ထောက်လှမ်းစနစ်က agent ၏ လုပ်ဆောင်ချက်များနှင့် ဆုံးဖြတ်ချက်များ၏ audit trail ကို ပံ့ပိုးပေးသည်။ ဤသည်က prompt injection, ပျက်စီးသော အကြောင်းအရာ ထုတ်ပြန်ခြင်း သို့မဟုတ် ကိုယ်ပိုင်အချက်အလက် (PII) များကို မမှန်မြောက်စွာ ကိုင်တွယ်မှုကဲ့သို့သော ပြဿနာများကို တွေ့ရှိကာ လျော့နည်းစေရန် အသုံးပြုနိုင်သည်။ ဥပမာအားဖြင့် သင့်အေးဂျင့်က အချို့သော စကားလုံးကို မည်သို့ ဖြေကြားခဲ့သလဲ သို့မဟုတ် မည်သည့် ကိရိယာကို အသုံးပြုခဲ့သလဲ ဆိုတာကို trace များကြည့်၍ နားလည်နိုင်သည်။
*   **ဆက်တိုက်တိုးတက်မှု Loop များ:** ထောက်လှမ်းစနစ်မှ ဒေတာများသည် iterative ဖွံ့ဖြိုးရေး လုပ်ငန်းစဉ်၏ အခြေခံဖြစ်သည်။ အေးဂျင့်များကို တကယ့်ကမ္ဘာတွင် မည်သို့ လုပ်ဆောင်သလဲ စောင့်ကြည့်ကာ အဖွဲ့များသည် တိုးတက်စရာ အပိုင်းများကို တွေ့ရှိနိုင်ပြီး မော်ဒယ်များအား fine-tune ပြုလုပ်ရန် ဒေတာစုဆောင်းနိုင်သလို ပြင်ဆင်မှုများ၏ အကျိုးသက်ရောက်မှုကို သက်မှတ်နိုင်သည်။ ဤသည်က အွန်လိုင်း အကဲဖြတ်မှ အော့ဖ်လိုင်း စမ်းသပ်မှုများသို့ အချက်အလက်များ ပေးပို့သော feedback loop တစ်ခုကို ဖန်တီးပြီး အေးဂျင့် စွမ်းဆောင်ရည်ကို အဆင့်ဆင့် တိုးတက်စေတတ်သည်။

## စောင့်ကြည့်ရန် အဓိက မီထရစ်များ

အေးဂျင့်၏ ပြုမူမှုကို စောင့်ကြည့်ပြီး နားလည်ရန် မျိုးမျိုးသော မီထရစ်များနှင့် အချက်အလက်များကို မှတ်တမ်းတင်သင့်သည်။ သတ်မှတ်ထားသော မီထရစ်များသည် အေးဂျင့်၏ ရည်ရွယ်ချက်ပေါ်မူတည်၍ မတူနိုင်သော်လည်း အချို့ကို ဘယ်နောက်တိုင်းလည်း အရေးကြီးသည်။

အောက်တွင် ထောက်လှမ်းစနစ်များမှ မကြာခဏ စောင့်ကြည့်သော မီထရစ်များကို ဖော်ပြထားသည်။

**Latency:** အေးဂျင့်သည် ဘယ်လောက်မြန်မြန် ဖြေကြားသနည်း။ ကြာမြင့်ချိန်များသည် အသုံးပြုသူအတွေ့အကြုံကို နစ်နာစေသည်။ အလုပ်တာဝန်များနှင့် တစ်ခုချင်းစီအဆင့်များ၏ latency ကို agent run များကို trace ပြုလုပ်ခြင်းဖြင့် တိုင်းတာသင့်သည်။ ဥပမာ၊ အေးဂျင့်တစ်ခုသည် မော်ဒယ်ခေါ်ဆိုမှုအားလုံးအတွက် 20 စက္ကန့်ယူလျှင် ပိုမြန်သော မော်ဒယ်ကို အသုံးပြုခြင်း သို့မဟုတ် မော်ဒယ်ခေါ်ဆိုမှုများကို 병렬 실행ခြင်းဖြင့် အချိန်လျှော့ချနိုင်သည်။

**Costs:** တစ်ကြိမ့် agent run အတွက် စရိတ် ဘယ်လောက်လဲ။ AI အေးဂျင့်များသည် token အလိုက် သို့မဟုတ် အခေါ်အတွက် ငွေကြေးများအား အပေါ်မူတည်၍ LLM ခေါ်ဆိုမှုများနှင့် အခြား API များကို အားထားတတ်သည်။ ကိရိယာများကို မကြာခဏ အသုံးပြုခြင်း သို့မဟုတ် prompt များ များပြားစွာ ခေါ်ဆိုခြင်းက စရိတ်မြင့်တတ်သည်။ ဥပမာ၊ အေးဂျင့်က quality အနည်းငယ် တိုးမြှင့်ရန် LLM ကို ငါးကြိမ်ခေါ်ဆိုခဲ့ပါက ဤကုန်ကျစရိတ်သည် တန်ဘိုးရှိမရှိကို သတ်မှတ်ရန် လိုအပ်သည် သို့မဟုတ် ခေါ်ဆိုမှုအရေအတွက်ကို လျော့ချပေးရန် သို့မဟုတ် စျေးအနိမ့်သော မော်ဒယ်ကို အသုံးပြုနိုင်မည်နည်းဆိုတာ စိစစ်ရမည်။ တိုက်ရိုက်စောင့်ကြည့်မှုက မမျှော်လင့်ထားသော spike များ (ဥပမာ၊ အခန်းကဏ္ဍများကြောင့် API loop များ အသွားအလာများ) ကို ဖော်ထုတ်နိုင်သည်။

**Request Errors:** အေးဂျင့်က မည်နှစ်ခါ တောင်းဆိုမှု မအောင်မြင်ခဲ့သလဲ။ ၎င်းတွင် API အမှားများ သို့မဟုတ် ကိရိယာခေါ်ဆိုမှု မအောင်မြင်ခြင်းများ ပါဝင်နိုင်သည်။ ထုတ်လုပ်မှုတွင် ၎င်းတို့နှင့် ပိုမိုခံနိုင်ရည်ရှိစေရန် fallback များ သို့မဟုတ် retry များ ထည့်သွင်းနိုင်သည်။ ဥပမာ၊ LLM ပံ့ပိုးရေးသူ A က ဖျက်သိမ်းခံရပါက backup အဖြစ် LLM ပံ့ပိုးသူ B သို့ ပြောင်းနိုင်သည်။

**User Feedback:** တိုက်ရိုက် အသုံးပြုသူအကဲဖြတ်ချက်များကို အကောင်အထည်ဖော်ခြင်းသည် တန်ဖိုးရှိသော အသိပညာသဏ္ဍာန်ပေးသည်။ ၎င်းတွင် တိုက်ရိုက် အဆင့်သတ်မှတ်ချက်များ (👍thumbs-up/👎down, ⭐1-5 အကြာအမြင်) သို့မဟုတ် စာသားမှတ်ချက်များ ပါဝင်နိုင်သည်။ ဆက်တိုက် အနုတ်လက္ခဏာများရှိပါက ၎င်းသည် အေးဂျင့်သည် မျှော်မှန်းထားသလို လည်ပတ်နေရက်မဟုတ်ကြောင်း သတိပေးသည်။

**Implicit User Feedback:** အသုံးပြုသူ၏ အပြုအမူများက တိုက်ရိုက် အကဲဖြတ်ချက် မရှိဘဲလည်း အကြောင်းပြချက် အချို့ပေးသည်။ ဥပမာ တိုက်ရိုက်မေးခွန်းကို ပြန်လည်ထပ်မေးခြင်း၊ မေးခွန်းများကို ထပ်မံမေးခြင်း သို့မဟုတ် retry ခလုတ်နှိပ်ခြင်းတို့ ပါဝင်နိုင်သည်။ ဥပမာ၊ အသုံးပြုသူများသည် တစ်ပါတည်းတောင်းဆိုချက်ကို ထပ်မံမေးသည်ကို တွေ့ရလျှင် ၎င်းသည် အေးဂျင့်သည် မမျှော်မှန်းထားသလို လည်ပတ်ခြင်း မဟုတ်ကြောင်း သတိပေးသည်။

**Accuracy:** အေးဂျင့်သည် မှန်ကန်သော သို့မဟုတ် လိုလားရသော ထွက်ရှိမှုများကို ဘယ်နှစ်ခါထုတ်ပြန်သနည်း။ Accuracy ကို သတ်မှတ်ခြင်းသည် အသီးသီးကွဲပြားနိုင်သည် (ဥပမာ၊ အခက်အခဲ ဖြေရှင်းနိုင်မှု မှန်ကန်မှု၊ အချက်အလက် ရယူမှု မှန်ကန်မှု၊ အသုံးပြုသူ စိတ်ကျေနပ်မှု)။ ပထမ ဦး ဆံုး နေ့က သင့်သတ်မှတ်ချက်အနေဖြင့် အောင်မြင်မှု ဘာပဲ ဖြစ်ကြောင်း သတ်မှတ်ရန်လိုသည်။ Accuracy ကို automated checks, evaluation scores, သို့မဟုတ် task completion label များဖြင့် မှတ်တမ်းတင်နိုင်သည်။ ဥပမာ၊ trace များကို "succeeded" သို့မဟုတ် "failed" ဟု သတ်မှတ်နိုင်သည်။

**Automated Evaluation Metrics:** Automated eval များကိုလည်း စီစဉ်နိုင်သည်။ ဥပမာ၊ LLM ကို အသုံးပြုပြီး အေးဂျင့်၏ output ကို အကဲဖြတ်ပေးစေ၍ အကူအညီဖြစ်/မှား၊ တိကျမှုရှိ/မရှိ စသည်ဖြင့် သတ်မှတ်နိုင်သည်။ ထို့အပြင် အေးဂျင့်၏ မျိုးစုံသော အစိတ်အပိုင်းများကို အမှတ်ပေးရန် အများအားဖြင့် open source 라이ဘရေရီများလည်း ရှိသည်။ ဥပမာ၊ RAG အေးဂျင့်များအတွက် [RAGAS](https://docs.ragas.io/) သို့မဟုတ် အန္တရာယ်ဖြစ်စေသော စကားလုံး သို့မဟုတ် prompt injection ကို တွေ့ရှိရန် [LLM Guard](https://llm-guard.com/) အစရှိသည်။

လက်တွေ့တွင် ဤမီထရစ်များပေါင်းစပ်မှုမှာ AI အေးဂျင့်၏ ကျန်းမာရေးကို အကောင်းဆုံး ဖုံးလွှမ်းပေးသည်။ ဤအခန်း၏ [example notebook](./code_samples/10_autogen_evaluation.ipynb) တွင် ဤမီထရစ်များကို တကယ့် ဥပမာများတွင် ဘယ်လို တွေ့ရသည်ကို ပြသမည် ဖြစ်သော်လည်း ပထမဆုံး ကျွန်ုပ်တို့သည် သာမာန် အကဲဖြတ်လုပ်ငန်းစဉ် တစ်ခု ဘယ်လို ရှိသည်ကို လေ့လာပါမည်။

## သင့်အေးဂျင့်ကို instrument ပြုလုပ်ရေး

tracing ဒေတာကို စုဆောင်းရန် အတွက် သင်၏ ကုဒ်ကို instrument ပြုလုပ်ရန် လိုအပ်မည်။ ရည်မှန်းချက်မှာ agent ကုဒ်ကို trace နှင့် မီထရစ်များ ထုတ်ပေးရန် instrument ပြုလုပ်ပြီး ၎င်းများကို ထောက်လှမ်းစနစ်ဖြင့် ဖမ်းယူ၊ ဖြေသိမ်းနှင့် 시각화လုပ်နိုင်ရန် ဖြစ်သည်။

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) သည် LLM ထောက်လှမ်းနိုင်ခြင်းအတွက် စက်မှုလက်မှတ်အဖြစ် ပေါ်ထွက်လာသည်။ ၎င်းသည် telemetry ဒေတာများ ထုတ်လုပ်ခြင်း၊ စုဆောင်းခြင်းနှင့် export ပြုလုပ်ရန် API များ၊ SDK များနှင့် ကိရိယာများကို ပံ့ပိုးပေးသည်။

အဆိုပါ instrumentation လိုက်ဘရေရီများသည် ရှိပြီးသား agent ဖရေမြွကတ်များကို အထုပ်အပိုးထည့်၍ OpenTelemetry span များကို ထောက်လှမ်းစနစ်သို့ အလွယ်တကူ export ပြုလုပ်နိုင်စေသည်။ အောက်တွင် [OpenLit instrumentation library](https://github.com/openlit/openlit) ဖြင့် AutoGen agent ကို instrument ပြုလုပ်သည့် ဥပမာတစ်ခု ရှိသည်။

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```


ဤအခန်းရှိ [example notebook](./code_samples/10_autogen_evaluation.ipynb) သည် သင့် AutoGen အေးဂျင့်ကို ဘယ်လို instrument ပြုလုပ်ရမည်ကို ပြသမည်ဖြစ်သည်။

**Manual Span Creation:** instrumentation 라이ဘရေရီများက အခြေခံအဆင့်အတွက် ကောင်းမွန်သော်လည်း များသောအားဖြင့် အသေးစိတ် သို့မဟုတ် စိတ်ကြိုက် ထည့်သွင်းလိုသည့် အချက်အလက်များ ရှိတတ်သည်။ ထိုအတွက် သင်သည် span များကို လက်ဖြင့် ဖန်တီး၍ စိတ်ကြိုက် လုပ်ငန်းလိုဂစ်များ ထည့်နိုင်သည်။ အရေးကြီးဆုံးမှာ သင်သည် သဘာဝအားဖြင့် သို့မဟုတ် လက်ဖြင့် ဖန်တီးထားသော span များကို စီးပွားရေးဆိုင်ရာ အချက်အလက်များ၊ အလယ်အလတ်တွက်ချက်ချက် အချက်အလက်များ သို့မဟုတ် debugging/စိစစ်မှုအတွက် အသုံးဝင်နိုင်သည့် context များဖြင့် စိတ်ကြိုက် attribute (tag သို့မဟုတ် metadata ဟုလည်း ခေါ်) ဖြင့် မြှင့်တင်နိုင်သည်။ ဥပမာ `user_id`, `session_id`, `model_version` စသည့် attribute များ ပါရမည်။

[Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3) ဖြင့် trace နှင့် span များကို လက်ဖြင့် ဖန်တီးခြင်းအပေါ် ဥပမာ:

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```


## အေးဂျင့် အကဲဖြတ်ခြင်း

ထောက်လှမ်းမှုသည် မီထရစ်များ ပေးစွမ်းပေမယ့် အကဲဖြတ်ခြင်းဆိုသည်မှာ အချက်အလက်များကို ခွဲခြမ်းစိတ်ဖြာခြင်း (နှင့် စမ်းသပ်မှုများ ပြုလုပ်ခြင်း) ဖြစ်ပြီး AI အေးဂျင့်၏ စွမ်းဆောင်ရည် ဘယ်လောက်ကောင်းမွန်သည်နှင့် ဘယ်လို တိုးတက်စေမည်ကို သတ်မှတ်ရန် သတ်မှတ်ချက်များကို ဖော်ဆောင်သည့် လုပ်ငန်းစဉ်ဖြစ်သည်။ အခြားစကားဖြင့်၊ သင်တွင် ထို trace များနှင့် မီထရစ်များ ရှိပါက ၎င်းတို့ကို မည့်သို့ အသုံးချကာ အေးဂျင့်ကို တိုင်ကြား၍ ဆုံးဖြတ်ချက်များ ပြုလုပ်မည်နည်း။

စနစ်တကျ အကဲဖြတ်ခြင်းသည် အရေးကြီးသည်၊ များသောအားဖြင့် AI အေးဂျင့်များသည် non-deterministic ဖြစ်ပြီး ဖွံ့ဖြိုးတိုးတက်နိုင်ကြောင်း (update များ သို့မဟုတ် model behavior drift ကြောင့်) — အကဲဖြတ်မှုမရှိပါက သင်၏ “စမတ် အေးဂျင့်” သည် တကယ်မှန်ကန်စွာ လုပ်ဆောင်နေပါသလား သို့မဟုတ် regression ဖြစ်သွားပါသလား မသိနိုင်ပါ။

AI အေးဂျင့်များအတွက် အကဲဖြတ်မှုနှစ်မျိုး ရှိသည် — **online evaluation** နှင့် **offline evaluation**။ နှစ်မျိုးလုံးသည် တန်ဖိုးရှိပြီး သစ်ကို ထောက်ပံ့ပေးကြသည်။ ကျွန်ုပ်တို့သည် မကြာခဏ အောက်ပိုင်းအလိုက် offline evaluation ဖြင့် စတင်ပါသည်၊ ၎င်းသည် မည်သည့်အေးဂျင့်ကိုမဆို ထုတ်လုပ်မှုသို့တင်ခြင်းမပြုမီ အနည်းဆုံး လိုသည်။

### Offline Evaluation

![Langfuse တွင် Dataset item များ](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

ဤသည်သည် အေးဂျင့်ကို ထိန်းချုပ်ထားသော ပတ်ဝန်းကျင်တွင် အကဲဖြတ်ခြင်းဖြစ်ပြီး သာမန်အားဖြင့် စမ်းသပ် dataset များကို အသုံးပြု၍ လုပ်ဆောင်သည်၊ တိုက်ရိုက် အသုံးပြုသူ မေးခွန်းများ မဟုတ်ပါ။ သင်သည် မျှော်မှန်းထားသော ထုတ်လွှတ်ချက် သို့မဟုတ် မှန်ကန်သော ပြုမူကို သိထားသည့် curated dataset များကို အသုံးပြုကာ agent ကို ပြေးဆွဲရမည်။

 ဥပမာ၊ သင်သည် သင်၏ math word-problem agent ကို တည်ဆောက်ခဲ့ပါက [test dataset](https://huggingface.co/datasets/gsm8k) အဖြစ် ဖြေရှင်းချက်သိထားသော 100 ချက်ရှိ dataset တစ်ခုထားနိုင်သည်။ Offline evaluation ကို အဖွံ့ဖြိုးရေးအချိန် (CI/CD pipeline များ၏ အစိတ်အပိုင်းအဖြစ်) တွင် ပြုလုပ်တတ်ပြီး တိုးတက်မှုများကို စိစစ်ခြင်း သို့မဟုတ် regression များကို ကာကွယ်နိုင်သည်။ အားသာချက်မှာ ၎င်းသည် **ပြန်လည်နှုတ်ယူနိုင်ပြီး သင်တွင် ground truth ရှိသောကြောင့် တိကျသော accuracy မီထရစ်များကို ရနိုင်သည်**။ သင်သည် user query များကို simulation လုပ်၍ အေးဂျင့်ထုတ်သော အဖြေများကို အကောင်းဆုံးဖြေရာများနှင့် နှိုင်းယှဉ်နိုင်သလို အထက်ဖော်ပြထားသည့် automated metrics များကို အသုံးပြုနိုင်သည်။

Offline eval ၏ အဓိက စိန်ခေါ်မှုမှာ သင့် စမ်းသပ် dataset သည် လုံလောက်စွာ ဖုံးလွှမ်းပြီး သက်ဆိုင်မှုရှိနေစေဖို့ ဖြစ်သည် — အေးဂျင့်သည် ရှေ့နေသော fixed test set ပေါ်တွင် ကောင်းမွန်နိုင်သော်လည်း ထုတ်လုပ်မှုတွင် အလွန်ကွာခြားသော မေးခွန်းများနှင့် တွေ့ဆုံနိုင်သည်။ ထို့ကြောင့် test set များကို edge case အသစ်များနှင့် တကယ့်ကမ္ဘာဆိုင်ရာ နမူနာများနှင့် အပ်ဒိတ်ပြုလုပ်ထားသင့်သည်။ သေးငယ်သည့် “smoke test” များနှင့် ပိုမိုကြီးမားသော evaluation set များကို ရောထွေးအသုံးပြုခြင်းက ကောင်းသည် — သေးငယ်သော set များကို အမြန်စစ်ဆေးရန်၊ ကြီးမားသော set များကို ကျယ်ပြန့်သော စွမ်းဆောင်ရည် မီထရစ်များအတွက်။

### Online Evaluation

![ထောက်လှမ်းမှု မီထရစ် အမြင်အနှာ](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

ဤသည်မှာ တိုက်ရိုက် တကယ့်အသုံးပြုသူပတ်ဝန်းကျင် (ထုတ်လုပ်မှု) တွင် အေးဂျင့်ကို အကဲဖြတ်ခြင်းကို ဆိုလိုသည်။ Online evaluation တွင် တိုက်ရိုက် အသုံးပြုသူ အပြန်အလှန်ပေါ်တွင် အေးဂျင့်၏ စွမ်းဆောင်ရည်ကို စောင့်ကြည့်၍ အိုက်လုပ်ငန်းများကို ဆက်တိုက် သုံးသပ်သည်။

ဥပမာ အွန်လိုင်း traffic ပေါ်တွင် success rate, user satisfaction score များ သို့မဟုတ် အခြားမီထရစ်များကို စောင့်ကြည့်နိုင်သည်။ online evaluation ၏ အားသာချက်မှာ သင်သည် စမ်းခန်းအခြေအနေတွင် မမျှော်လင့်ခဲ့နိုင်သော အချက်များကို ဖမ်းယူနိုင်သည် — မော်ဒယ် drift ကို အချိန်နှင့် တပြေးညီ တွေ့ရှိနိုင်ပြီး (input pattern များပြောင်းလဲသဖြင့် အေးဂျင့်၏ ထိရောက်မှု ဆင်းရဲခြင်းကို) ထုတ်လုပ်မှုဒေတာတွင် မပါသည့် မေးခွန်းများ သို့မဟုတ် အခြေအနေများကို ဖမ်းဆီးနိုင်သည်။ ၎င်းသည် အေးဂျင့်၏ တကယ့်အပြုအမူကို အမှန်တကယ် မြင်နိုင်စေသည်။

Online evaluation တွင် implicit နှင့် explicit user feedback များကို စုဆောင်းခြင်း (အပေါ်တွင် ဆွေးနွေးခဲ့သည်) နှင့် shadow test များ သို့မဟုတ် A/B tests (agent ၏ အသစ်သော ဗားရှင်းကို အဟောင်းနှင့် 병렬တွင် chạy ကြည့်ခြင်း) များကို တင်သွင်းနိုင်သည်။ အခက်အခဲမှာ တိုက်ရိုက်အသုံးပြုသူအစီရင်ခံများအတွက် ယုံကြည်စိတ်ချရသော label များ သို့မဟုတ် score များ ရရှိရန် ခက်ခဲသည့်အချက်ဖြစ်နိုင်သည် — သင်သည် အသုံးပြုသူတုံ့ပြန်မှုသို့မဟုတ် downstream metric များ (ဥပမာ၊ အသုံးပြုသူက ရလဒ်ကို နှိပ်ကြည့်ခဲ့ပါသလား) အပေါ် အသုံးပြုနိုင်သည်။

### နှစ်ခုကို ပေါင်းစည်းခြင်း

Online နှင့် offline အကဲဖြတ်မှုများသည် ချင်းမရှူးမကြာမဖြစ်သော မဟုတ်ကြပေ။ ၎င်းတို့သည် ထောက်ပံ့ဆောင်ရန် အလွန်ကို အထောက်အကူဖြစ်သည်။ online စောင့်ကြည့်မှုမှ ထွက်လာသော အယူအဆများ (ဥပမာ၊ အေးဂျင့် မအောင်မြင်သော အသုံးပြုသူမေးခွန်း အမျိုးအစားအသစ်များ) ကို offline စမ္းသပ် dataset များအား တိုးတက်အောင် အသုံးပြုနိုင်သည်။ အခြားဘက်မှတော့ offline စမ်းသပ်များတွင် ကောင်းမွန်စွာ လုပ်နိုင်သော အေးဂျင့်များကို ထုတ်လုပ်မှုတွင် ယုံကြည်စိတ်ချစွာ တင်ပြ၍ online တွင် စောင့်ကြည့်နိုင်သည်။

ဘာမှမှန်သဘောထား၍ မဟုတ်ဘဲ အဖွဲ့များအများ်း loop တစ်ခုကို ချမှတ်တတ်ကြသည်။

_evaluate offline -> deploy -> monitor online -> collect new failure cases -> add to offline dataset -> refine agent -> repeat_.

## အထွေထွေ ပြဿနာများ

AI အေးဂျင့်များကို ထုတ်လုပ်မှုသို့ ထည့်သွင်းသည့်အခါ သင်သည် အမျိုးမျိုးသော အခက်အခဲများနှင့် ရင်ဆိုင်ရနိုင်သည်။ အောက်တွင် အချို့သော ပုံမှန် ပြဿနာများနှင့် အဖြေများကို ဖော်ပြထားသည်။

| **Issue**    | **Potential Solution**   |
| ------------- | ------------------ |
| AI Agent not performing tasks consistently | - Refine the prompt given to the AI Agent; be clear on objectives.<br>- Identify where dividing the tasks into subtasks and handling them by multiple agents can help. |
| AI Agent running into continuous loops  | - Ensure you have clear termination terms and conditions so the Agent knows when to stop the process.<br>- For complex tasks that require reasoning and planning, use a larger model that is specialized for reasoning tasks. |
| AI Agent tool calls are not performing well   | - Test and validate the tool's output outside of the agent system.<br>- Refine the defined parameters, prompts, and naming of tools.  |
| Multi-Agent system not performing consistently | - Refine prompts given to each agent to ensure they are specific and distinct from one another.<br>- Build a hierarchical system using a "routing" or controller agent to determine which agent is the correct one. |

ဤပြဿနာအများစုကို ထောက်လှမ်းမှုရှိပါက ပိုမိုထိရောက်စွာ ရှာဖွေတွေ့ရှိနိုင်သည်။ အထက်ဖော်ပြထားသော trace များနှင့် မီထရစ်များက agent workflow ၏ မည်သည့်အဆင့်တွင် ပြဿနာများ ဖြစ်ပျက်နေသည်ကို တိတိကျကျ ဖော်ထုတ်ကူညီပြီး debugging နှင့် အမှန်တကယ် တိုးတက်စေရန် အလွန်ထိရောက်စေသည်။

## ကုန်ကျစရိတ် စီမံခြင်း
Here are some strategies to manage the costs of deploying AI agents to production:

**အသေးစား မော်ဒယ်များ အသုံးပြုခြင်း:** Small Language Models (SLMs) သည် အချို့သော agentic အသုံးအမူများတွင် ကောင်းစွာ လည်ပတ်နိုင်ပြီး ကုန်ကျစရိတ်ကို လေးနက်စွာ လျော့နည်းစေပါသည်။ အဆိုပါ SLM များသည် သင့်အကြောင်းအရာတွင် ဘယ်လောက် ကောင်းမွန်စွာ လည်ပတ်မည်ကို နားလည်ရန်နှင့် ကြီးထွားမော်ဒယ်များနှင့် နှိုင်းယှဉ်ဖော်ထုတ်ရန် အကဲဖြတ်စနစ်တည်ဆောက်ထားခြင်းက အကောင်းဆုံးနည်းလမ်း ဖြစ်ပါသည်။ ရည်ရွယ်ချက် ဖော်ထုတ်ခြင်း (intent classification) သို့မဟုတ် ပါရာမီတာ ထုတ်ယူခြင်း (parameter extraction) ကဲ့သို့ ရိုးရှင်းသော လုပ်ငန်းများအတွက် SLM များကို အသုံးပြု၍၊ ရွေးချယ်၍ ရန်ထက်ရှုပ်ထွေးသော မှတ်ချက်ထောက်လှမ်းခြင်းများအတွက် ကြီးမားသော မော်ဒယ်များကို ထားရှိပါ။

**Router မော်ဒယ် အသုံးပြုခြင်း:** အလားတူ မဟာဗျူဟာတစ်ခုမှာ မော်ဒယ်များနှင့် အရွယ်အစား မျိုးစုံကို အသုံးပြုခြင်းဖြစ်သည်။ LLM/SLM သို့မဟုတ် serverless function တစ်ခုကို အသုံးပြု၍ တောင်းဆိုမှု၏ ရှုပ်ထွေးမှုအပေါ်အခြေခံ၍ လိုက်ဖက်သော မော်ဒယ်များသို့ လမ်းကြောင်းခွဲပေးနိုင်ပါသည်။ ၎င်းအရည်အသွေးသည် သက်သာစေသည်နှင့်အတူ သတ်မှတ်ထားသော လုပ်ငန်းများ၌ စွမ်းဆောင်ရည်ကို အာမခံပေးနိုင်စေပါသည်။ ဥပမာအားဖြင့် ရိုးရှင်းသော မေးခွန်းများကို အသေးနှောင့်၊ မြန်ဆန်သော မော်ဒယ်များသို့ လမ်းကြောင်းခွဲပေး၍၊ ရှုပ်ထွေးသော ဆင်ခြင်ချက်များအတွက်သာ တန်ဖိုးကြီးသော ကြီးမားသော မော်ဒယ်များကို အသုံးပြုပါ။

**တုံ့ပြန်ချက်များကို ကက်ရှ်ပြုလုပ်ခြင်း:** ပုံမှန်တောင်းဆိုမှုများနှင့် လုပ်ငန်းစဉ်များကို ရှာဖွေပြီး agentic စနစ်ဆီသို့ မသွားခင်မှာ ရရှိနိုင်သော တုံ့ပြန်ချက်များကို ပေးစွမ်းခြင်းသည် တူညီသော တောင်းဆိုမှုများ၏ အလေးအလံကို လျော့ချနိုင်သည်။ မူလက အခြေခံ AI မော်ဒယ်များကို အသုံးပြု၍ တောင်းဆိုမှုတစ်ခုနှင့် သိုလှောင်ထားသော တောင်းဆိုမှုများ၏ အချိုးအစား ဘယ်လောက်ဆန့်ကျင်နေသည်ကို ဖော်ထုတ်သတ်မှတ်နိုင်သော flow ကိုပါ အကောင်အထည်ဖော်နိုင်သည်။ ထိုနည်းလမ်းသည် မကြာခဏ မေးမြန်းသော မေးခွန်းများ သို့မဟုတ် ပေါင်းသားလမ်းစဉ်များအတွက် ကုန်ကျစရိတ်ကို အားတရား လျော့ချနိုင်ပါသည်။

## အကောင်အထည်ဖော်ရာတွင် ဘယ်လို အလုပ်လုပ်ကြောင်း ကြည့်ကြမယ်

In the [ဥပမာ notebook of this section](./code_samples/10_autogen_evaluation.ipynb), we’ll see examples of how we can use observability tools to monitor and evaluate our agent.


### ထုတ်လုပ်မှုရှိ AI Agents အကြောင်း ဆက်လက်မေးစရာများ ရှိပါသလား?

Join the [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) to meet with other learners, attend office hours and get your AI Agents questions answered.

## ယခင် သင်ခန်းစာ

[Metacognition Design Pattern](../09-metacognition/README.md)

## နောက်တစ်ခန်း သင်ခန်းစာ

[Agentic Protocols](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
အသိပေးချက်:
ဤစာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) ကို အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ တိကျမှုအတွက် ကြိုးပမ်းထားသော်လည်း အလိုအလျောက် ဘာသာပြန်ချက်များတွင် အမှားများ သို့မဟုတ် မမှန်ကန်သော အချက်အလက်များ ပါဝင်နိုင်သည်ကို သတိပြုပါ။ မူလစာတမ်းကို မူလဘာသာဖြင့်သာ အာဏာရှိသော အရင်းအမြစ်အဖြစ် ယူဆသင့်ပါသည်။ အရေးကြီးသော အချက်အလက်များအတွက် ဆိုလျှင် လူသားကျွမ်းကျင်သူများ၏ ပရော်ဖက်ရှင်နယ် ဘာသာပြန်ခြင်းကို အကြံပြုပါသည်။ ဤဘာသာပြန်ချက်ကို အသုံးပြုမှုကြောင့် ဖြစ်ပေါ်လာသည့် မှားယွင်း နားလည်မှုများ သို့မဟုတ် အဓိပ္ပာယ်လွဲမှားခြင်းများအတွက် ကျွန်ုပ်တို့ တာဝန်မဆောင်ပါ။
<!-- CO-OP TRANSLATOR DISCLAIMER END -->