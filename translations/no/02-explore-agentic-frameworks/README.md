[![Utforske AI Agent-rammeverk](../../../translated_images/no/lesson-2-thumbnail.c65f44c93b8558df.webp)](https://youtu.be/ODwF-EZo_O8?si=1xoy_B9RNQfrYdF7)

> _(Klikk p친 bildet over for 친 se video av denne leksjonen)_

# Utforsk AI Agent-rammeverk

AI-agentrammeverk er programvareplattformer designet for 친 forenkle opprettelsen, distribusjonen og administrasjonen av AI-agenter. Disse rammeverkene gir utviklere forh친ndsbygde komponenter, abstraksjoner og verkt칮y som effektiviserer utviklingen av komplekse AI-systemer.

Disse rammeverkene hjelper utviklere med 친 fokusere p친 de unike aspektene av deres applikasjoner ved 친 tilby standardiserte tiln칝rminger til vanlige utfordringer i utviklingen av AI-agenter. De forbedrer skalerbarhet, tilgjengelighet og effektivitet i bygging av AI-systemer.

## Introduksjon 

Denne leksjonen vil dekke:

- Hva er AI-agentrammeverk og hva gj칮r de mulig for utviklere 친 oppn친?
- Hvordan kan team bruke disse til 친 raskt prototype, iterere og forbedre agentens evner?
- Hva er forskjellene mellom rammeverkene og verkt칮yene laget av Microsoft <a href="https://aka.ms/ai-agents/autogen" target="_blank">AutoGen</a>, <a href="https://aka.ms/ai-agents-beginners/semantic-kernel" target="_blank">Semantic Kernel</a>, og <a href="https://aka.ms/ai-agents-beginners/ai-agent-service" target="_blank">Azure AI Agent Service</a>?
- Kan jeg integrere mine eksisterende Azure-칮kosystemverkt칮y direkte, eller trenger jeg frittst친ende l칮sninger?
- Hva er Azure AI Agents-tjenesten og hvordan hjelper denne meg?

## L칝ringsm친l

M친lene for denne leksjonen er 친 hjelpe deg 친 forst친:

- Rollen til AI-agentrammeverk i AI-utvikling.
- Hvordan utnytte AI-agentrammeverk til 친 bygge intelligente agenter.
- N칮kkelfunksjoner muliggjort av AI-agentrammeverk.
- Forskjellene mellom AutoGen, Semantic Kernel og Azure AI Agent Service.

## Hva er AI-agentrammeverk og hva gj칮r de mulig for utviklere 친 gj칮re?

Tradisjonelle AI-rammeverk kan hjelpe deg med 친 integrere AI i appene dine og gj칮re disse appene bedre p친 f칮lgende m친ter:

- **Personalisering**: AI kan analysere brukeradferd og preferanser for 친 gi personlige anbefalinger, innhold og opplevelser.
Eksempel: Str칮mmetjenester som Netflix bruker AI for 친 foresl친 filmer og serier basert p친 seerhistorikk, noe som 칮ker brukerengasjement og tilfredshet.
- **Automatisering og effektivitet**: AI kan automatisere repetitive oppgaver, effektivisere arbeidsflyt og forbedre operasjonell effektivitet.
Eksempel: Kundeserviceapper bruker AI-drevne chatboter for 친 h친ndtere vanlige henvendelser, noe som reduserer svartider og frigj칮r menneskelige agenter til mer komplekse saker.
- **Bedret brukeropplevelse**: AI kan forbedre totalopplevelsen ved 친 tilby intelligente funksjoner som stemmegjenkjenning, naturlig spr친kbehandling og prediktiv tekst.
Eksempel: Virtuelle assistenter som Siri og Google Assistant bruker AI for 친 forst친 og svare p친 stemmekommandoer, noe som gj칮r det enklere for brukere 친 interagere med enhetene sine.

### Det h칮res jo flott ut, men hvorfor trenger vi AI-agentrammeverket?

AI-agentrammeverk representerer noe mer enn bare AI-rammeverk. De er designet for 친 muliggj칮re opprettelsen av intelligente agenter som kan interagere med brukere, andre agenter og milj칮et for 친 oppn친 spesifikke m친l. Disse agentene kan opptre autonomt, ta beslutninger og tilpasse seg endrende forhold. La oss se p친 noen viktige egenskaper muliggjort av AI-agentrammeverk:

- **Agent-samarbeid og koordinering**: Gj칮r det mulig 친 opprette flere AI-agenter som kan jobbe sammen, kommunisere og koordinere for 친 l칮se komplekse oppgaver.
- **Automatisering og oppgaveh친ndtering**: Tilbyr mekanismer for 친 automatisere flertrinns arbeidsflyter, oppgavefordeling og dynamisk oppgaveh친ndtering mellom agenter.
- **Kontextforst친else og tilpasning**: Utrust agentene med evne til 친 forst친 kontekst, tilpasse seg skiftende milj칮er og ta beslutninger basert p친 sanntidsinformasjon.

Kort oppsummert lar agenter deg gj칮re mer, l칮fte automatiseringen til neste niv친, og skape mer intelligente systemer som kan tilpasse seg og l칝re av milj칮et sitt.

## Hvordan raskt prototype, iterere og forbedre agentens evner?

Dette er et raskt skiftende landskap, men det finnes noen ting som er vanlige p친 tvers av de fleste AI-agentrammeverk og som kan hjelpe deg 친 raskt prototype og iterere, nemlig modul칝re komponenter, samarbeidende verkt칮y og sanntidsl칝ring. La oss g친 n칝rmere inn p친 disse:

- **Bruk modul칝re komponenter**: AI-SDK-er tilbyr forh친ndsbygde komponenter som AI- og minnekontakter, funksjonskall ved bruk av naturlig spr친k eller kodeplugins, promptmaler og mer.
- **Dra nytte av samarbeidende verkt칮y**: Design agenter med spesifikke roller og oppgaver som gj칮r det mulig 친 teste og forbedre samarbeidsarbeidsflyter.
- **L칝r i sanntid**: Implementer tilbakemeldingssl칮yfer hvor agenter l칝rer av interaksjoner og justerer atferden sin dynamisk.

### Bruk modul칝re komponenter

SDK-er som Microsoft Semantic Kernel og LangChain tilbyr forh친ndsbygde komponenter som AI-kontakter, promptmaler og minneh친ndtering.

**Hvordan team kan bruke disse**: Team kan raskt sette sammen disse komponentene for 친 lage en funksjonell prototype uten 친 starte fra bunnen av, noe som muliggj칮r rask eksperimentering og iterasjon.

**Hvordan det fungerer i praksis**: Du kan bruke en forh친ndsbygget parser for 친 trekke ut informasjon fra brukerinput, en minnemodul for 친 lagre og hente data, og en promptgenerator for 친 interagere med brukere, alt uten 친 m친tte bygge disse komponentene fra grunnen av.

**Eksempelkode**. La oss se p친 eksempler p친 hvordan du kan bruke en forh친ndsbygd AI-kontakt med Semantic Kernel Python og .Net som bruker automatisk funksjonskall for 친 la modellen svare p친 brukerinput:

``` python
# Semantic Kernel Python-eksempel

import asyncio
from typing import Annotated

from semantic_kernel.connectors.ai import FunctionChoiceBehavior
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings
from semantic_kernel.contents import ChatHistory
from semantic_kernel.functions import kernel_function
from semantic_kernel.kernel import Kernel

# Definer et ChatHistory-objekt for 친 holde samtalens kontekst
chat_history = ChatHistory()
chat_history.add_user_message("I'd like to go to New York on January 1, 2025")


# Definer et eksempelplugin som inneholder funksjonen for 친 bestille reise
class BookTravelPlugin:
    """A Sample Book Travel Plugin"""

    @kernel_function(name="book_flight", description="Book travel given location and date")
    async def book_flight(
        self, date: Annotated[str, "The date of travel"], location: Annotated[str, "The location to travel to"]
    ) -> str:
        return f"Travel was booked to {location} on {date}"

# Opprett Kernel
kernel = Kernel()

# Legg til eksempelpluginet i Kernel-objektet
kernel.add_plugin(BookTravelPlugin(), plugin_name="book_travel")

# Definer Azure OpenAI AI-tilkoblingen
chat_service = AzureChatCompletion(
    deployment_name="YOUR_DEPLOYMENT_NAME", 
    api_key="YOUR_API_KEY", 
    endpoint="https://<your-resource>.azure.openai.com/",
)

# Definer foresp칮rselsinnstillingene for 친 konfigurere modellen med automatisk funksjonsanrop
request_settings = AzureChatPromptExecutionSettings(function_choice_behavior=FunctionChoiceBehavior.Auto())


async def main():
    # Send foresp칮rselen til modellen med gitt chathistorikk og foresp칮rselsinnstillinger
    # Kernel inneholder eksemplet som modellen vil be om 친 kj칮re
    response = await chat_service.get_chat_message_content(
        chat_history=chat_history, settings=request_settings, kernel=kernel
    )
    assert response is not None

    """
    Note: In the auto function calling process, the model determines it can invoke the 
    `BookTravelPlugin` using the `book_flight` function, supplying the necessary arguments. 
    
    For example:

    "tool_calls": [
        {
            "id": "call_abc123",
            "type": "function",
            "function": {
                "name": "BookTravelPlugin-book_flight",
                "arguments": "{'location': 'New York', 'date': '2025-01-01'}"
            }
        }
    ]

    Since the location and date arguments are required (as defined by the kernel function), if the 
    model lacks either, it will prompt the user to provide them. For instance:

    User: Book me a flight to New York.
    Model: Sure, I'd love to help you book a flight. Could you please specify the date?
    User: I want to travel on January 1, 2025.
    Model: Your flight to New York on January 1, 2025, has been successfully booked. Safe travels!
    """

    print(f"`{response}`")
    # Eksempel p친 svar fra AI-modellen: `Din flyvning til New York den 1. januar 2025 har blitt bestilt. God tur! 九걾잺游딯`

    # Legg modellens svar til v친r chathistorikk
    chat_history.add_assistant_message(response.content)


if __name__ == "__main__":
    asyncio.run(main())
```
```csharp
// Semantic Kernel C# example

using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.ChatCompletion;
using System.ComponentModel;
using Microsoft.SemanticKernel.Connectors.AzureOpenAI;

ChatHistory chatHistory = [];
chatHistory.AddUserMessage("I'd like to go to New York on January 1, 2025");

var kernelBuilder = Kernel.CreateBuilder();
kernelBuilder.AddAzureOpenAIChatCompletion(
    deploymentName: "NAME_OF_YOUR_DEPLOYMENT",
    apiKey: "YOUR_API_KEY",
    endpoint: "YOUR_AZURE_ENDPOINT"
);
kernelBuilder.Plugins.AddFromType<BookTravelPlugin>("BookTravel"); 
var kernel = kernelBuilder.Build();

var settings = new AzureOpenAIPromptExecutionSettings()
{
    FunctionChoiceBehavior = FunctionChoiceBehavior.Auto()
};

var chatCompletion = kernel.GetRequiredService<IChatCompletionService>();

var response = await chatCompletion.GetChatMessageContentAsync(chatHistory, settings, kernel);

/*
Behind the scenes, the model recognizes the tool to call, what arguments it already has (location) and (date)
{

"tool_calls": [
    {
        "id": "call_abc123",
        "type": "function",
        "function": {
            "name": "BookTravelPlugin-book_flight",
            "arguments": "{'location': 'New York', 'date': '2025-01-01'}"
        }
    }
]
*/

Console.WriteLine(response.Content);
chatHistory.AddMessage(response!.Role, response!.Content!);

// Example AI Model Response: Your flight to New York on January 1, 2025, has been successfully booked. Safe travels! 九걾잺游딯

// Define a plugin that contains the function to book travel
public class BookTravelPlugin
{
    [KernelFunction("book_flight")]
    [Description("Book travel given location and date")]
    public async Task<string> BookFlight(DateTime date, string location)
    {
        return await Task.FromResult( $"Travel was booked to {location} on {date}");
    }
}
```

Det du kan se fra dette eksempelet er hvordan du kan utnytte en forh친ndsbygd parser til 친 trekke ut n칮kkelinfo fra brukerinput, som avreisested, destinasjon og dato for en flybestillingsforesp칮rsel. Denne modul칝re tiln칝rmingen lar deg fokusere p친 logikken p친 et overordnet niv친.

### Dra nytte av samarbeidende verkt칮y

Rammeverk som CrewAI, Microsoft AutoGen og Semantic Kernel legger til rette for opprettelse av flere agenter som kan jobbe sammen.

**Hvordan team kan bruke disse**: Team kan designe agenter med spesifikke roller og oppgaver, slik at de kan teste og forbedre samarbeidende arbeidsflyter og 칮ke den totale systemeffektiviteten.

**Hvordan det fungerer i praksis**: Du kan opprette et team av agenter der hver agent har en spesialisert funksjon, som datainnhenting, analyse eller beslutningstaking. Disse agentene kan kommunisere og dele informasjon for 친 oppn친 et felles m친l, som 친 svare p친 en brukersp칮rsm친l eller fullf칮re en oppgave.

**Eksempelkode (AutoGen)**:

```python
# opprett agenter, og opprett deretter en round-robin-plan hvor de kan samarbeide, i dette tilfellet i rekkef칮lge

# Agent for datainnhenting
# Agent for dataanalyse
# Agent for beslutningstaking

agent_retrieve = AssistantAgent(
    name="dataretrieval",
    model_client=model_client,
    tools=[retrieve_tool],
    system_message="Use tools to solve tasks."
)

agent_analyze = AssistantAgent(
    name="dataanalysis",
    model_client=model_client,
    tools=[analyze_tool],
    system_message="Use tools to solve tasks."
)

# samtalen avsluttes n친r brukeren sier "GODKJENN"
termination = TextMentionTermination("APPROVE")

user_proxy = UserProxyAgent("user_proxy", input_func=input)

team = RoundRobinGroupChat([agent_retrieve, agent_analyze, user_proxy], termination_condition=termination)

stream = team.run_stream(task="Analyze data", max_turns=10)
# Bruk asyncio.run(...) n친r du kj칮rer i et skript.
await Console(stream)
```

Det du ser i forrige kode er hvordan du kan opprette en oppgave som involverer flere agenter som jobber sammen for 친 analysere data. Hver agent utf칮rer en bestemt funksjon, og oppgaven utf칮res ved 친 koordinere agentene for 친 oppn친 칮nsket resultat. Ved 친 lage dedikerte agenter med spesialiserte roller kan du forbedre oppgaveeffektivitet og ytelse.

### L칝r i sanntid

Avanserte rammeverk tilbyr funksjoner for sanntids kontekstforst친else og tilpasning.

**Hvordan team kan bruke disse**: Team kan implementere tilbakemeldingssl칮yfer hvor agenter l칝rer av interaksjoner og dynamisk justerer sin atferd, noe som f칮rer til kontinuerlig forbedring og finjustering av evnene.

**Hvordan det fungerer i praksis**: Agenter kan analysere brukerfeedback, milj칮data og resultatene av oppgaver for 친 oppdatere sin kunnskapsbase, justere beslutningsalgoritmer og forbedre ytelsen over tid. Denne iterative l칝ringsprosessen gj칮r det mulig for agentene 친 tilpasse seg skiftende forhold og brukerpreferanser, og 칮ke den totale systemeffektiviteten.

## Hva er forskjellene mellom rammeverkene AutoGen, Semantic Kernel og Azure AI Agent Service?

Det finnes mange m친ter 친 sammenligne disse rammeverkene p친, men la oss se p친 noen hovedforskjeller n친r det gjelder design, funksjonalitet og m친lrettede bruksomr친der:

## AutoGen

AutoGen er et open-source rammeverk utviklet av Microsoft Researchs AI Frontiers Lab. Det fokuserer p친 hendelsesstyrte, distribuerte *agentiske* applikasjoner, som muliggj칮r flere LLM-er og SLM-er, verkt칮y og avanserte designm칮nstre for flere agenter.

AutoGen er bygd rundt kjernebegrepet agenter, som er autonome enheter som kan oppfatte milj칮et sitt, ta beslutninger og utf칮re handlinger for 친 oppn친 spesifikke m친l. Agenter kommuniserer via asynkrone meldinger, noe som gj칮r at de kan arbeide uavhengig og parallelt, forbedrer systemets skalerbarhet og responsivitet.

<a href="https://en.wikipedia.org/wiki/Actor_model" target="_blank">Agenter er basert p친 akt칮rmodellen</a>. If칮lge Wikipedia er en akt칮r _den grunnleggende byggesteinen i parallellberegning. Som svar p친 en melding den mottar kan en akt칮r: ta lokale beslutninger, opprette flere akt칮rer, sende flere meldinger, og bestemme hvordan den skal svare p친 neste mottatte melding_.

**Bruksomr친der**: Automatisering av kodegenerering, dataanalysetjenester, og bygging av egne agenter for planlegging og forskningsfunksjoner.

Her er noen viktige kjernebegreper i AutoGen:

- **Agenter**. En agent er en programvarenhet som:
  - **Kommuniserer via meldinger**, disse meldingene kan v칝re synkrone eller asynkrone.
  - **Opprettholder sin egen tilstand**, som kan endres av innkommende meldinger.
  - **Utf칮rer handlinger** som svar p친 mottatte meldinger eller endringer i sin tilstand. Disse handlingene kan endre agentens tilstand og produsere eksterne effekter, som 친 oppdatere meldingslogger, sende nye meldinger, kj칮re kode, eller gj칮re API-kall.
    
  Her har du et kort kodesnutt der du lager din egen agent med chattefunksjoner:

    ```python
    from autogen_agentchat.agents import AssistantAgent
    from autogen_agentchat.messages import TextMessage
    from autogen_ext.models.openai import OpenAIChatCompletionClient


    class MyAgent(RoutedAgent):
        def __init__(self, name: str) -> None:
            super().__init__(name)
            model_client = OpenAIChatCompletionClient(model="gpt-4o")
            self._delegate = AssistantAgent(name, model_client=model_client)
    
        @message_handler
        async def handle_my_message_type(self, message: MyMessageType, ctx: MessageContext) -> None:
            print(f"{self.id.type} received message: {message.content}")
            response = await self._delegate.on_messages(
                [TextMessage(content=message.content, source="user")], ctx.cancellation_token
            )
            print(f"{self.id.type} responded: {response.chat_message.content}")
    ```
    
    I forrige kode har `MyAgent` blitt opprettet og arver fra `RoutedAgent`. Den har en meldingsbehandler som skriver ut innholdet i meldingen og deretter sender et svar ved hjelp av delegaten `AssistantAgent`. Merk spesielt hvordan vi tildeler `self._delegate` en instans av `AssistantAgent` som er en forh친ndsbygd agent som kan h친ndtere chat-kompletteringer.


    La oss informere AutoGen om denne agenttypen og starte programmet deretter:

    ```python
    
    # main.py
    runtime = SingleThreadedAgentRuntime()
    await MyAgent.register(runtime, "my_agent", lambda: MyAgent())

    runtime.start()  # Start behandling av meldinger i bakgrunnen.
    await runtime.send_message(MyMessageType("Hello, World!"), AgentId("my_agent", "default"))
    ```

    I forrige kode er agentene registrert i runtime og deretter sendes en melding til agenten, noe som resulterer i f칮lgende utdata:

    ```text
    # Output from the console:
    my_agent received message: Hello, World!
    my_assistant received message: Hello, World!
    my_assistant responded: Hello! How can I assist you today?
    ```

- **Flere agenter**. AutoGen st칮tter opprettelsen av flere agenter som kan samarbeide for 친 l칮se komplekse oppgaver. Agenter kan kommunisere, dele informasjon og koordinere sine handlinger for 친 l칮se problemer mer effektivt. For 친 lage et fleragent-system kan du definere forskjellige typer agenter med spesialiserte funksjoner og roller, som datainnhenting, analyse, beslutningstaking og brukerinteraksjon. La oss se hvordan en slik opprettelse ser ut for 친 f친 en f칮lelse av det:

    ```python
    editor_description = "Editor for planning and reviewing the content."

    # Eksempel p친 친 erkl칝re en agent
    editor_agent_type = await EditorAgent.register(
    runtime,
    editor_topic_type,  # Bruker topic-typen som agenttype.
    lambda: EditorAgent(
        description=editor_description,
        group_chat_topic_type=group_chat_topic_type,
        model_client=OpenAIChatCompletionClient(
            model="gpt-4o-2024-08-06",
            # api_key="YOUR_API_KEY",
        ),
        ),
    )

    # Resterende deklarasjoner forkortet av plasshensyn

    # Gruppechat
    group_chat_manager_type = await GroupChatManager.register(
    runtime,
    "group_chat_manager",
    lambda: GroupChatManager(
        participant_topic_types=[writer_topic_type, illustrator_topic_type, editor_topic_type, user_topic_type],
        model_client=OpenAIChatCompletionClient(
            model="gpt-4o-2024-08-06",
            # api_key="YOUR_API_KEY",
        ),
        participant_descriptions=[
            writer_description, 
            illustrator_description, 
            editor_description, 
            user_description
        ],
        ),
    )
    ```

    I forrige kode har vi en `GroupChatManager` som er registrert i runtime. Denne manageren er ansvarlig for 친 koordinere samspillet mellom ulike typer agenter, som skribenter, illustrat칮rer, redakt칮rer og brukere.

- **Agent Runtime**. Rammeverket tilbyr et runtime-milj칮 som muliggj칮r kommunikasjon mellom agenter, h친ndterer deres identiteter og livssykluser, og h친ndhever sikkerhets- og personverngrenser. Dette betyr at du kan kj칮re agentene dine i et sikkert og kontrollert milj칮, og s칮rge for at de kan interagere trygt og effektivt. Det finnes to runtime-milj칮er av interesse:
  - **Frittst친ende runtime**. Dette er et godt valg for enkeltprosesser der alle agenter er implementert i samme programmeringsspr친k og kj칮rer i samme prosess. Her er en illustrasjon av hvordan det fungerer:
  
    <a href="https://microsoft.github.io/autogen/stable/_images/architecture-standalone.svg" target="_blank">Frittst친ende runtime</a>   
Applikasjonsstack

    *agenter kommuniserer via meldinger gjennom runtime, og runtime h친ndterer agentenes livssyklus*

  - **Distribuert agent-runtime**, egnet for flerprosessapplikasjoner der agenter kan v칝re implementert i forskjellige programmeringsspr친k og kj칮re p친 forskjellige maskiner. Her er en illustrasjon av hvordan det fungerer:
  
    <a href="https://microsoft.github.io/autogen/stable/_images/architecture-distributed.svg" target="_blank">Distribuert runtime</a>

## Semantic Kernel + Agent Framework

Semantic Kernel er et bedriftsklart AI-orchestrerings-SDK. Det best친r av AI- og minnekontakter, sammen med et agentrammeverk.

La oss f칮rst dekke noen kjernekomponenter:

- **AI-kontakter**: Dette er et grensesnitt mot eksterne AI-tjenester og datakilder for bruk i b친de Python og C#.

  ```python
  # Semantisk kjerne Python
  from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
  from semantic_kernel.kernel import Kernel

  kernel = Kernel()
  kernel.add_service(
    AzureChatCompletion(
        deployment_name="your-deployment-name",
        api_key="your-api-key",
        endpoint="your-endpoint",
    )
  )
  ```  

    ```csharp
    // Semantic Kernel C#
    using Microsoft.SemanticKernel;

    // Create kernel
    var builder = Kernel.CreateBuilder();
    
    // Add a chat completion service:
    builder.Services.AddAzureOpenAIChatCompletion(
        "your-resource-name",
        "your-endpoint",
        "your-resource-key",
        "deployment-model");
    var kernel = builder.Build();
    ```

    Her har du et enkelt eksempel p친 hvordan du kan opprette en kernel og legge til en chat completion-tjeneste. Semantic Kernel oppretter en forbindelse til en ekstern AI-tjeneste, i dette tilfelle Azure OpenAI Chat Completion.

- **Plugins**: Disse kapsler inn funksjoner som en applikasjon kan bruke. Det finnes b친de ferdige plugins og egendefinerte du kan lage selv. Et beslektet konsept er "prompt-funksjoner." I stedet for 친 gi naturlige spr친koppfordringer for funksjonskall, kringkaster du visse funksjoner til modellen. Basert p친 den gjeldende chat-konteksten kan modellen velge 친 kalle en av disse funksjonene for 친 fullf칮re en foresp칮rsel eller et sp칮rsm친l. Her er et eksempel:

  ```python
  from semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion import AzureChatCompletion


  async def main():
      from semantic_kernel.functions import KernelFunctionFromPrompt
      from semantic_kernel.kernel import Kernel

      kernel = Kernel()
      kernel.add_service(AzureChatCompletion())

      user_input = input("User Input:> ")

      kernel_function = KernelFunctionFromPrompt(
          function_name="SummarizeText",
          prompt="""
          Summarize the provided unstructured text in a sentence that is easy to understand.
          Text to summarize: {{$user_input}}
          """,
      )

      response = await kernel_function.invoke(kernel=kernel, user_input=user_input)
      print(f"Model Response: {response}")

      """
      Sample Console Output:

      User Input:> I like dogs
      Model Response: The text expresses a preference for dogs.
      """


  if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
  ```

    ```csharp
    var userInput = Console.ReadLine();

    // Define semantic function inline.
    string skPrompt = @"Summarize the provided unstructured text in a sentence that is easy to understand.
                        Text to summarize: {{$userInput}}";
    
    // create the function from the prompt
    KernelFunction summarizeFunc = kernel.CreateFunctionFromPrompt(
        promptTemplate: skPrompt,
        functionName: "SummarizeText"
    );

    //then import into the current kernel
    kernel.ImportPluginFromFunctions("SemanticFunctions", [summarizeFunc]);

    ```

    Her har du f칮rst en malprompt `skPrompt` som gir plass for brukerens input, `$userInput`. Deretter oppretter du kjernens funksjon `SummarizeText` og importerer den inn i kjernen med plugin-navnet `SemanticFunctions`. Merk navnet p친 funksjonen som hjelper Semantic Kernel med 친 forst친 hva funksjonen gj칮r og n친r den skal kalles.

- **Native funksjon**: Det finnes ogs친 native funksjoner som rammeverket kan kalle direkte for 친 utf칮re oppgaven. Her er et eksempel p친 en slik funksjon som henter innhold fra en fil:

    ```csharp
    public class NativeFunctions {

        [SKFunction, Description("Retrieve content from local file")]
        public async Task<string> RetrieveLocalFile(string fileName, int maxSize = 5000)
        {
            string content = await File.ReadAllTextAsync(fileName);
            if (content.Length <= maxSize) return content;
            return content.Substring(0, maxSize);
        }
    }
    
    //Import native function
    string plugInName = "NativeFunction";
    string functionName = "RetrieveLocalFile";

   //To add the functions to a kernel use the following function
    kernel.ImportPluginFromType<NativeFunctions>();

    ```

- **Minne**: Abstraherer og forenkler kontekststyring for AI-apper. Id칠en med minne er at dette er noe LLM b칮r kjenne til. Du kan lagre denne informasjonen i en vektorbutikk som i praksis er en in-memory database, en vektordatabase eller lignende. Her er et eksempel p친 et veldig forenklet scenario der *fakta* legges til i minnet:

    ```csharp
    var facts = new Dictionary<string,string>();
    facts.Add(
        "Azure Machine Learning; https://learn.microsoft.com/azure/machine-learning/",
        @"Azure Machine Learning is a cloud service for accelerating and
        managing the machine learning project lifecycle. Machine learning professionals,
        data scientists, and engineers can use it in their day-to-day workflows"
    );
    
    facts.Add(
        "Azure SQL Service; https://learn.microsoft.com/azure/azure-sql/",
        @"Azure SQL is a family of managed, secure, and intelligent products
        that use the SQL Server database engine in the Azure cloud."
    );
    
    string memoryCollectionName = "SummarizedAzureDocs";
    
    foreach (var fact in facts) {
        await memoryBuilder.SaveReferenceAsync(
            collection: memoryCollectionName,
            description: fact.Key.Split(";")[1].Trim(),
            text: fact.Value,
            externalId: fact.Key.Split(";")[2].Trim(),
            externalSourceName: "Azure Documentation"
        );
    }
    ```

Disse faktaene blir deretter lagret i minnesamlingen `SummarizedAzureDocs`. Dette er et veldig forenklet eksempel, men du kan se hvordan du kan lagre informasjon i hukommelsen for at LLM skal bruke det.

S친 det er det grunnleggende om Semantic Kernel-rammeverket, hva med Agent Framework?

## Azure AI Agent Service

Azure AI Agent Service er en nyere tillegg, introdusert p친 Microsoft Ignite 2024. Det gj칮r det mulig 친 utvikle og distribuere AI-agenter med mer fleksible modeller, som 친 direkte kalle open source LLM-er som Llama 3, Mistral og Cohere.

Azure AI Agent Service gir sterkere sikkerhetsmekanismer for bedriftsbruk og metoder for datalagring, noe som gj칮r det egnet for bedriftsapplikasjoner.

Det fungerer rett ut av boksen med fleragentorchestrasjonsrammeverk som AutoGen og Semantic Kernel.

Denne tjenesten er for 칮yeblikket i offentlig forh친ndsvisning og st칮tter Python og C# for bygging av agenter.

Ved 친 bruke Semantic Kernel Python kan vi lage en Azure AI Agent med et brukerdefinert plugin:

```python
import asyncio
from typing import Annotated

from azure.identity.aio import DefaultAzureCredential

from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings, AzureAIAgentThread
from semantic_kernel.contents import ChatMessageContent
from semantic_kernel.contents import AuthorRole
from semantic_kernel.functions import kernel_function


# Definer en eksempel-plugin for eksempelet
class MenuPlugin:
    """A sample Menu Plugin used for the concept sample."""

    @kernel_function(description="Provides a list of specials from the menu.")
    def get_specials(self) -> Annotated[str, "Returns the specials from the menu."]:
        return """
        Special Soup: Clam Chowder
        Special Salad: Cobb Salad
        Special Drink: Chai Tea
        """

    @kernel_function(description="Provides the price of the requested menu item.")
    def get_item_price(
        self, menu_item: Annotated[str, "The name of the menu item."]
    ) -> Annotated[str, "Returns the price of the menu item."]:
        return "$9.99"


async def main() -> None:
    ai_agent_settings = AzureAIAgentSettings.create()

    async with (
        DefaultAzureCredential() as creds,
        AzureAIAgent.create_client(
            credential=creds,
            conn_str=ai_agent_settings.project_connection_string.get_secret_value(),
        ) as client,
    ):
        # Opprett agentdefinisjon
        agent_definition = await client.agents.create_agent(
            model=ai_agent_settings.model_deployment_name,
            name="Host",
            instructions="Answer questions about the menu.",
        )

        # Opprett AzureAI-agenten ved 친 bruke den definerte klienten og agentdefinisjonen
        agent = AzureAIAgent(
            client=client,
            definition=agent_definition,
            plugins=[MenuPlugin()],
        )

        # Opprett en tr친d for 친 holde samtalen
        # Hvis ingen tr친d er oppgitt, vil en ny tr친d bli
        # opprettet og returnert med den innledende responsen
        thread: AzureAIAgentThread | None = None

        user_inputs = [
            "Hello",
            "What is the special soup?",
            "How much does that cost?",
            "Thank you",
        ]

        try:
            for user_input in user_inputs:
                print(f"# User: '{user_input}'")
                # Kall agenten for den angitte tr친den
                response = await agent.get_response(
                    messages=user_input,
                    thread_id=thread,
                )
                print(f"# {response.name}: {response.content}")
                thread = response.thread
        finally:
            await thread.delete() if thread else None
            await client.agents.delete_agent(agent.id)


if __name__ == "__main__":
    asyncio.run(main())
```

### Kjernen begreper

Azure AI Agent Service har f칮lgende kjernebegreper:

- **Agent**. Azure AI Agent Service integreres med Microsoft Foundry. Innenfor AI Foundry fungerer en AI Agent som en "smart" mikrotjeneste som kan brukes til 친 svare p친 sp칮rsm친l (RAG), utf칮re handlinger eller fullstendig automatisere arbeidsflyter. Den oppn친r dette ved 친 kombinere kraften til generative AI-modeller med verkt칮y som gj칮r det mulig 친 f친 tilgang til og samhandle med virkelige datakilder. Her er et eksempel p친 en agent:

    ```python
    agent = project_client.agents.create_agent(
        model="gpt-4o-mini",
        name="my-agent",
        instructions="You are helpful agent",
        tools=code_interpreter.definitions,
        tool_resources=code_interpreter.resources,
    )
    ```

    I dette eksemplet opprettes en agent med modellen `gpt-4o-mini`, et navn `my-agent` og instruksjoner `You are helpful agent`. Agenten er utstyrt med verkt칮y og ressurser for 친 utf칮re kodeinterpretasjonsoppgaver.

- **Tr친d og meldinger**. Tr친den er et annet viktig begrep. Den representerer en samtale eller interaksjon mellom en agent og en bruker. Tr친der kan brukes til 친 spore fremdriften i en samtale, lagre kontekstinformasjon og administrere tilstanden til interaksjonen. Her er et eksempel p친 en tr친d:

    ```python
    thread = project_client.agents.create_thread()
    message = project_client.agents.create_message(
        thread_id=thread.id,
        role="user",
        content="Could you please create a bar chart for the operating profit using the following data and provide the file to me? Company A: $1.2 million, Company B: $2.5 million, Company C: $3.0 million, Company D: $1.8 million",
    )
    
    # Ask the agent to perform work on the thread
    run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)
    
    # Fetch and log all messages to see the agent's response
    messages = project_client.agents.list_messages(thread_id=thread.id)
    print(f"Messages: {messages}")
    ```

    I den forrige koden opprettes en tr친d. Deretter sendes en melding til tr친den. Ved 친 kalle `create_and_process_run` blir agenten bedt om 친 utf칮re arbeid p친 tr친den. Til slutt hentes meldingene og logges for 친 se agentens respons. Meldingene indikerer fremdriften i samtalen mellom brukeren og agenten. Det er ogs친 viktig 친 forst친 at meldingene kan v칝re av forskjellige typer som tekst, bilde eller fil, det vil si at agentens arbeid har resultert i for eksempel et bilde eller en tekstrespons. Som utvikler kan du deretter bruke denne informasjonen til 친 viderebehandle responsen eller presentere den til brukeren.

- **Integreres med andre AI-rammeverk**. Azure AI Agent Service kan samhandle med andre rammeverk som AutoGen og Semantic Kernel, noe som betyr at du kan bygge deler av appen din i ett av disse rammeverkene og for eksempel bruke Agent-tjenesten som en orkestrator, eller du kan bygge alt i Agent-tjenesten.

**Bruksomr친der**: Azure AI Agent Service er designet for bedriftsapplikasjoner som krever sikker, skalerbar og fleksibel distribusjon av AI-agenter.

## Hva er forskjellen mellom disse rammeverkene?

Det h칮res ut som det er mye overlapp mellom disse rammeverkene, men det finnes noen viktige forskjeller n친r det gjelder deres design, funksjoner og m친lrettede bruksomr친der:

- **AutoGen**: Er et eksperimenteringsrammeverk som fokuserer p친 forskningsledende multi-agent-systemer. Det er det beste stedet 친 eksperimentere og prototype avanserte multi-agent-systemer.
- **Semantic Kernel**: Er et produksjonsklart agentbibliotek for bygging av agentapplikasjoner for bedrifter. Fokuserer p친 hendelsesdrevne, distribuerte agentapplikasjoner, som muliggj칮r flere LLM-er og SLM-er, verkt칮y og enkelt-/fleragent-designm칮nstre.
- **Azure AI Agent Service**: Er en plattform- og distribusjonstjeneste i Azure Foundry for agenter. Den tilbyr tilkoblingsbygging til tjenester st칮ttet av Azure Foundry som Azure OpenAI, Azure AI Search, Bing Search og kodekj칮ring.

Er du fortsatt usikker p친 hvilken du skal velge?

### Bruksomr친der

La oss se om vi kan hjelpe deg ved 친 g친 gjennom noen vanlige brukstilfeller:

> Q: Jeg eksperimenterer, l칝rer og bygger bevis-p친-konsept agentapplikasjoner, og jeg 칮nsker 친 kunne bygge og eksperimentere raskt
>

> A: AutoGen vil v칝re et godt valg for dette scenariet, siden det fokuserer p친 hendelsesdrevne, distribuerte agentapplikasjoner og st칮tter avanserte fleragent-designm칮nstre.

> Q: Hva gj칮r AutoGen til et bedre valg enn Semantic Kernel og Azure AI Agent Service for dette bruksomr친det?
>
> A: AutoGen er spesifikt designet for hendelsesdrevne, distribuerte agentapplikasjoner, noe som gj칮r det godt egnet til 친 automatisere kodegenerering og dataanalyseoppgaver. Det gir n칮dvendige verkt칮y og funksjonalitet for 친 bygge komplekse multi-agent-systemer effektivt.

> Q: Det h칮res ut som Azure AI Agent Service ogs친 kan passe her, det har verkt칮y for kodegenerering og mer?

>
> A: Ja, Azure AI Agent Service er en plattformtjeneste for agenter og har innebygde muligheter for flere modeller, Azure AI Search, Bing Search og Azure Functions. Det gj칮r det enkelt 친 bygge agentene dine i Foundry-portalen og distribuere dem i stor skala.

> Q: Jeg er fortsatt forvirret, gi meg bare ett valg
>
> A: Et godt valg er 친 bygge applikasjonen din f칮rst i Semantic Kernel, og deretter bruke Azure AI Agent Service til 친 distribuere agenten din. Denne tiln칝rmingen lar deg enkelt vedvare agentene dine samtidig som du utnytter kraften til 친 bygge fler-agent-systemer i Semantic Kernel. I tillegg har Semantic Kernel en kobling i AutoGen, noe som gj칮r det enkelt 친 bruke begge rammeverkene sammen.

La oss oppsummere de viktigste forskjellene i en tabell:

| Framework | Fokus | Kjernen Begreper | Bruksomr친der |
| --- | --- | --- | --- |
| AutoGen | Hendelsesdrevne, distribuerte agentapplikasjoner | Agenter, Personas, Funksjoner, Data | Kodegenerering, dataanalyseoppgaver |
| Semantic Kernel | Forst친else og generering av menneskelignende tekstinnhold | Agenter, Modul칝re komponenter, Samarbeid | Naturlig spr친ksforst친else, innholdsgenerering |
| Azure AI Agent Service | Fleksible modeller, bedriftsikkerhet, kodegenerering, verkt칮y-kall | Modularitet, samarbeid, prosessorchestrering | Sikker, skalerbar og fleksibel distribusjon av AI-agenter |

Hva er det ideelle bruksomr친det for hvert av disse rammeverkene?

## Kan jeg integrere mine eksisterende Azure-칮kosystemverkt칮y direkte, eller trenger jeg frittst친ende l칮sninger?

Svaret er ja, du kan integrere dine eksisterende Azure-칮kosystemverkt칮y direkte med Azure AI Agent Service spesielt, dette fordi den er bygget for 친 fungere s칮ml칮st med andre Azure-tjenester. Du kan for eksempel integrere Bing, Azure AI Search og Azure Functions. Det er ogs친 dyp integrasjon med Microsoft Foundry.

For AutoGen og Semantic Kernel kan du ogs친 integrere med Azure-tjenester, men det kan kreve at du kaller Azure-tjenestene fra koden din. En annen m친te 친 integrere p친 er 친 bruke Azure SDK-ene for 친 samhandle med Azure-tjenester fra agentene dine. I tillegg, som nevnt, kan du bruke Azure AI Agent Service som en orkestrator for agentene dine bygget i AutoGen eller Semantic Kernel, noe som gir enkel tilgang til Azure-칮kosystemet.

## Eksempel Kode

- Python: [Agent Framework](./code_samples/02-python-agent-framework.ipynb)
- .NET: [Agent Framework](./code_samples/02-dotnet-agent-framework.md)

## Har du flere sp칮rsm친l om AI Agent Frameworks?

Bli med i [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) for 친 m칮te andre l칝rende, delta p친 kontortimer og f친 svar p친 sp칮rsm친l om AI-agenter.

## Referanser

- <a href="https://techcommunity.microsoft.com/blog/azure-ai-services-blog/introducing-azure-ai-agent-service/4298357" target="_blank">Azure Agent Service</a>
- <a href="https://devblogs.microsoft.com/semantic-kernel/microsofts-agentic-ai-frameworks-autogen-and-semantic-kernel/" target="_blank">Semantic Kernel and AutoGen</a>
- <a href="https://learn.microsoft.com/semantic-kernel/frameworks/agent/?pivots=programming-language-python" target="_blank">Semantic Kernel Python Agent Framework</a>
- <a href="https://learn.microsoft.com/semantic-kernel/frameworks/agent/?pivots=programming-language-csharp" target="_blank">Semantic Kernel .Net Agent Framework</a>
- <a href="https://learn.microsoft.com/azure/ai-services/agents/overview" target="_blank">Azure AI Agent service</a>
- <a href="https://techcommunity.microsoft.com/blog/educatordeveloperblog/using-azure-ai-agent-service-with-autogen--semantic-kernel-to-build-a-multi-agen/4363121" target="_blank">Using Azure AI Agent Service with AutoGen / Semantic Kernel to build a multi-agent's solution</a>

## Forrige leksjon

[Introduction to AI Agents and Agent Use Cases](../01-intro-to-ai-agents/README.md)

## Neste leksjon

[Understanding Agentic Design Patterns](../03-agentic-design-patterns/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n칮yaktighet, vennligst v칝r oppmerksom p친 at automatiske oversettelser kan inneholde feil eller un칮yaktigheter. Originaldokumentet p친 dets opprinnelige spr친k b칮r betraktes som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller feiltolkninger som oppst친r ved bruk av denne oversettelsen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->