# AI-agenter i produksjon: Observabilitet og evaluering

[![AI Agents in Production](../../../translated_images/no/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

Etter hvert som AI-agenter beveger seg fra eksperimentelle prototyper til virkelige applikasjoner, blir evnen til √• forst√• deres oppf√∏rsel, overv√•ke ytelsen og systematisk evaluere resultatene deres viktig.

## L√¶ringsm√•l

Etter √• ha fullf√∏rt denne leksjonen vil du vite hvordan du kan/forst√•:
- Kjernemekanismer for agentobservabilitet og evaluering
- Teknikker for √• forbedre ytelse, kostnader og effektivitet for agenter
- Hva og hvordan du systematisk evaluerer AI-agentene dine
- Hvordan du kontrollerer kostnader n√•r du distribuerer AI-agenter i produksjon
- Hvordan du instrumenterer agenter bygd med AutoGen

M√•let er √• gi deg kunnskapen til √• forvandle dine "svarte bokser" til gjennomsiktige, h√•ndterbare og p√•litelige systemer.

_**Merk:** Det er viktig √• distribuere AI-agenter som er trygge og p√•litelige. Sjekk ogs√• ut leksjonen [Building Trustworthy AI Agents](./06-building-trustworthy-agents/README.md)._

## Traces og Spans

Observabilitetsverkt√∏y som [Langfuse](https://langfuse.com/) eller [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) representerer vanligvis agentkj√∏ringer som traces og spans.

- **Trace** representerer en komplett agentoppgave fra start til slutt (for eksempel h√•ndtering av en brukerhenvendelse).
- **Spans** er individuelle steg innen trace (for eksempel et spr√•kmodellkall eller datainnhenting).

![Trace tree in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Uten observabilitet kan en AI-agent f√∏les som en "svart boks" ‚Äì dens interne tilstand og resonnement er ugjennomsiktig, noe som gj√∏r det vanskelig √• feils√∏ke problemer eller optimalisere ytelsen. Med observabilitet blir agenter "glassbokser" som tilbyr gjennomsiktighet, noe som er avgj√∏rende for √• bygge tillit og sikre at de fungerer som forventet.

## Hvorfor observabilitet er viktig i produksjonsmilj√∏er

Overgangen til produksjon av AI-agenter introduserer nye utfordringer og krav. Observabilitet er ikke lenger en "hyggelig √• ha"-funksjon, men en kritisk kapasitet:

*   **Feils√∏king og rot√•rsaksanalyse**: N√•r en agent feiler eller gir uventet resultat, gir observabilitetsverkt√∏yene traces som trengs for √• spore opp feilkilden. Dette er spesielt viktig i komplekse agenter som kan inneb√¶re flere LLM-kall, verkt√∏ysinteraksjoner og betinget logikk.
*   **Latens- og kostnadsh√•ndtering**: AI-agenter baserer seg ofte p√• LLM-er og andre eksterne API-er som faktureres per token eller kall. Observabilitet tillater n√∏yaktig sporing av disse kallene, slik at man kan identifisere operasjoner som er un√∏dvendig treg eller kostbar. Dette gj√∏r det mulig √• optimalisere prompts, velge mer effektive modeller eller redesigne arbeidsflyter for √• styre driftskostnader og sikre god brukeropplevelse.
*   **Tillit, sikkerhet og samsvar**: I mange applikasjoner er det viktig √• sikre at agenter oppf√∏rer seg trygt og etisk. Observabilitet gir en revisjonsspor av agenthandlinger og beslutninger. Dette kan brukes til √• oppdage og sette inn tiltak mot problemer som prompt-injeksjon, generering av skadelig innhold, eller feilbehandling av personlig identifiserbar informasjon (PII). For eksempel kan du gjennomg√• traces for √• forst√• hvorfor en agent ga et bestemt svar eller brukte et bestemt verkt√∏y.
*   **Kontinuerlige forbedringssykluser**: Observabilitetsdata er grunnlaget for en iterativ utviklingsprosess. Ved √• overv√•ke hvordan agenter fungerer i den virkelige verden, kan team identifisere forbedringsomr√•der, samle data for finjustering av modeller og validere effekten av endringer. Dette skaper en tilbakemeldingssl√∏yfe hvor produksjonsinnsikter fra online evaluering informerer offline eksperimentering og forbedring, noe som f√∏rer til stadig bedre agentytelse.

## Viktige m√•l for sporing

For √• overv√•ke og forst√• agentoppf√∏rsel b√∏r en rekke metrikker og signaler spores. Mens spesifikke metrikker kan variere basert p√• agentens form√•l, er noen universelt viktige.

Her er noen av de vanligste metrikker som observabilitetsverkt√∏y overv√•ker:

**Latens:** Hvor raskt svarer agenten? Lange ventetider p√•virker brukeropplevelsen negativt. Du b√∏r m√•le latens for oppgaver og individuelle steg ved √• spore agentkj√∏ringer. For eksempel kan en agent som tar 20 sekunder for alle modellkall akselereres ved √• bruke en raskere modell eller ved √• kj√∏re modellkall parallelt.

**Kostnader:** Hva koster hver agentkj√∏ring? AI-agenter baserer seg p√• LLM-kall fakturert per token eller eksterne API-er. Hyppig bruk av verkt√∏y eller flere prompts kan raskt gi √∏kte kostnader. For eksempel, hvis en agent kaller en LLM fem ganger for marginal kvalitetsforbedring, m√• du vurdere om kostnaden er berettiget eller om du kan redusere antall kall eller bruke en billigere modell. Sanntidsoverv√•king hjelper ogs√• med √• oppdage uventede kostnadstopper (f.eks. feil som for√•rsaker overdrevne API-l√∏kker).

**Feil i foresp√∏rsler:** Hvor mange foresp√∏rsler feilet agenten p√•? Dette kan inkludere API-feil eller mislykkede verkt√∏yskall. For √• gj√∏re agenten mer robust i produksjon kan du sette opp fallback-mekanismer eller automatiske retryer. For eksempel, hvis LLM-leverand√∏r A er nede, bytter du til LLM-leverand√∏r B som backup.

**Brukertilbakemeldinger:** Gjennomf√∏ring av direkte brukerevalueringer gir verdifulle innsikter. Dette kan inkludere eksplisitte vurderinger (üëçtommel opp/üëétommel ned, ‚≠ê1-5 stjerner) eller tekstlige kommentarer. Konsistent negativ tilbakemelding b√∏r varsle deg, da det er et tegn p√• at agenten ikke fungerer som forventet.

**Implicit brukertilbakemelding:** Brukeratferd gir indirekte tilbakemeldinger uten eksplisitte vurderinger. Dette kan inkludere umiddelbar omformulering av sp√∏rsm√•l, gjentatte foresp√∏rsler eller klikk p√• en retry-knapp. For eksempel, hvis du ser at brukere gjentatte ganger sp√∏r samme sp√∏rsm√•l, er dette et tegn p√• at agenten ikke fungerer som forventet.

**N√∏yaktighet:** Hvor ofte produserer agenten korrekte eller √∏nskede resultater? Definisjoner av n√∏yaktighet varierer (f.eks. korrekt probleml√∏sning, n√∏yaktighet i informasjonss√∏k, brukertilfredshet). Det f√∏rste steget er √• definere hva suksess betyr for din agent. Du kan spore n√∏yaktighet gjennom automatiske kontroller, evalueringsscore eller merke oppgavefullf√∏ringer. For eksempel ved √• merke traces som "lyktes" eller "feilet".

**Automatiserte evalueringsmetrikker:** Du kan ogs√• sette opp automatiserte evalueringer. For eksempel kan du bruke en LLM til √• score agentens output, f.eks. om den er hjelpsom, n√∏yaktig eller ikke. Det finnes ogs√• flere open source-biblioteker som hjelper deg med √• score ulike aspekter ved agenten, f.eks. [RAGAS](https://docs.ragas.io/) for RAG-agenter eller [LLM Guard](https://llm-guard.com/) for √• oppdage skadelig spr√•k eller prompt-injeksjon.

I praksis gir en kombinasjon av disse metrikker best dekning av en AI-agents helse. I dette kapitlets [eksempelnotatbok](./code_samples/10_autogen_evaluation.ipynb) vil vi vise hvordan disse metrikker ser ut i virkelige eksempler, men f√∏rst l√¶rer vi hvordan en typisk evalueringsarbeidsflyt ser ut.

## Instrumenter agenten din

For √• samle inn tracing-data m√• du instrumentere koden din. M√•let er √• instrumentere agentkoden slik at den sender ut traces og metrikker som kan fanges opp, behandles og visualiseres av en observabilitetsplattform.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) har blitt en industristandard for LLM-observabilitet. Det gir sett med API-er, SDK-er og verkt√∏y for √• generere, samle og eksportere telemetridata.

Det finnes mange instrumenteringsbiblioteker som pakker inn eksisterende agentrammeverk og gj√∏r det enkelt √• eksportere OpenTelemetry-spans til et observabilitetsverkt√∏y. Nedenfor er et eksempel p√• instrumentering av en AutoGen-agent med [OpenLit-instrumenteringsbiblioteket](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```


[Eksempelnotatboken](./code_samples/10_autogen_evaluation.ipynb) i dette kapitlet vil demonstrere hvordan du instrumenterer AutoGen-agenten din.

**Manuell opprettelse av Span:** Selv om instrumenteringsbiblioteker gir et godt utgangspunkt, er det ofte behov for mer detaljert eller tilpasset informasjon. Du kan opprette spans manuelt for √• legge til skreddersydd applikasjonslogikk. Enda viktigere, de kan berikes med egendefinerte attributter (ogs√• kalt tags eller metadata). Disse attributtene kan inkludere forretningsspesifikke data, mellomregninger eller annen kontekst som kan v√¶re nyttig for feils√∏king eller analyse, som for eksempel `user_id`, `session_id` eller `model_version`.

Eksempel p√• manuell opprettelse av traces og spans med [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3): 

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```


## Agent-evaluering

Observabilitet gir oss metrikker, men evaluering er prosessen med √• analysere disse dataene (og utf√∏re tester) for √• avgj√∏re hvor godt en AI-agent presterer og hvordan den kan forbedres. Med andre ord, n√•r du har de traces og metrikker, hvordan bruker du dem til √• vurdere agenten og ta beslutninger?

Regelmessig evaluering er viktig fordi AI-agenter ofte er ikke-deterministiske og kan utvikle seg (gjennom oppdateringer eller endringer i modellens oppf√∏rsel) ‚Äì uten evaluering ville du ikke vite om din "smarte agent" faktisk gj√∏r jobben sin bra eller om den har f√•tt tilbakegang.

Det finnes to kategorier av evaluering for AI-agenter: **online evaluering** og **offline evaluering**. Begge er verdifulle og utfyller hverandre. Vi starter vanligvis med offline evaluering, da dette er det minste n√∏dvendige steget f√∏r distribusjon av en agent.

### Offline evaluering

![Dataset items in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Dette inneb√¶rer evaluering av agenten i et kontrollert milj√∏, vanligvis ved √• bruke testdatasett, ikke direkte brukerhenvendelser i sanntid. Du bruker kuraterte datasett hvor du vet hva den forventede outputen eller korrekte oppf√∏rselen er, og kj√∏rer agenten p√• disse.

For eksempel, hvis du laget en agent for tekstbaserte matteoppgaver, kan du ha et [testdatasett](https://huggingface.co/datasets/gsm8k) med 100 problemer med kjente svar. Offline evaluering utf√∏res ofte under utvikling (og kan inng√• i CI/CD-pipelines) for √• sjekke forbedringer eller hindre regresjoner. Fordelen er at det er **repetitivt og gir klare n√∏yaktighetsmetrikker siden du har sannheten som grunnlag**. Du kan ogs√• simulere brukerhenvendelser og m√•le agentens svar mot ideelle svar eller bruke automatiske metrikker som beskrevet ovenfor.

Den viktigste utfordringen med offline evaluering er √• sikre at testdatasettet er omfattende og fortsatt relevant ‚Äì agenten kan prestere godt p√• et fast testsett, men m√∏te sv√¶rt ulike sp√∏rsm√•l i produksjon. Derfor b√∏r du holde testsett oppdatert med nye tilfeller og eksempler som gjenspeiler virkelige scenarioer. En blanding av sm√• "sm√∏retstester" og st√∏rre evalueringssett er nyttig: sm√• sett for raske kontroller og st√∏rre for bredere ytelsesm√•linger.

### Online evaluering

![Observability metrics overview](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Dette refererer til evaluering av agenten i et levende, ekte milj√∏, alts√• under faktisk bruk i produksjon. Online evaluering inkluderer overv√•king av agentens ytelse p√• ekte brukerinteraksjoner og kontinuerlig analyse av resultater.

For eksempel kan du spore suksessrater, brukertilfredshetspoeng eller andre metrikker p√• sanntidstrafikk. Fordelen med online evaluering er at den **fanger opp ting du kanskje ikke forutser i et laboratoriemilj√∏** ‚Äì du kan observere modellendringer over tid (hvis agentens effektivitet forringes n√•r inputm√∏nstre skifter) og fange opp uventede sp√∏rsm√•l eller situasjoner som ikke var i testdataene dine. Den gir et ekte bilde av hvordan agenten oppf√∏rer seg ute i feltet.

Online evaluering inneb√¶rer ofte innsamling av implisitte og eksplisitte brukertilbakemeldinger, som nevnt, og muligens kj√∏ring av shadow-tester eller A/B-tester (der en ny versjon kj√∏rer parallelt for √• sammenligne med den gamle). Utfordringen er at det kan v√¶re vanskelig √• f√• p√•litelige etiketter eller poeng p√• live-interaksjoner ‚Äì du kan v√¶re avhengig av brukertilbakemeldinger eller downstream-metrikker (som om brukeren klikket p√• resultatet).

### Kombinere de to

Online og offline evalueringer er ikke gjensidig utelukkende; de utfyller hverandre godt. Innsikter fra online overv√•king (f.eks. nye typer brukerhenvendelser der agenten presterer d√•rlig) kan brukes til √• forbedre offline testdatasett. Omvendt kan agenter som presterer godt p√• offline-tester ogs√• trygt distribueres og overv√•kes online.

Mange team f√∏lger en syklus:

_evaluer offline -> deployer -> overv√•k online -> samle nye feiltilfeller -> legg til i offline datasett -> forbedre agent -> gjenta_.

## Vanlige problemer

N√•r du distribuerer AI-agenter i produksjon, kan du m√∏te ulike utfordringer. Her er noen vanlige problemer og mulige l√∏sninger:

| **Problem**    | **Potensiell l√∏sning**   |
| ------------- | ------------------ |
| AI-agent utf√∏rer ikke oppgaver konsekvent | - Forbedre prompten som gis til AI-agenten; v√¶r tydelig p√• m√•l.<br>- Identifiser om oppdeling av oppgavene i deloppgaver som h√•ndteres av flere agenter kan hjelpe. |
| AI-agent sitter fast i uendelige l√∏kker | - Sikre klare avslutningsvilk√•r slik at agenten vet n√•r prosessen skal stoppe.<br>- For komplekse oppgaver som krever resonnement og planlegging, bruk en st√∏rre modell spesialisert for slike oppgaver. |
| AI-agentens verkt√∏yskall fungerer d√•rlig | - Test og valider verkt√∏yets output utenfor agentsystemet.<br>- Forbedre definerte parametere, prompts og navngivning av verkt√∏y. |
| Multi-agent system utf√∏rer ikke konsekvent | - Forbedre prompts til hver agent for √• sikre at de er spesifikke og forskjellige fra hverandre.<br>- Bygg et hierarkisk system med en "ruting"- eller kontrolleragent som bestemmer hvilken agent som er riktig. |

Mange av disse problemene kan identifiseres mer effektivt med observabilitet p√• plass. De traces og metrikker vi diskuterte tidligere hjelper deg n√∏yaktig √• finne hvor i agentens arbeidsflyt problemene oppst√•r, noe som gj√∏r feils√∏king og optimalisering mye mer effektivt.

## Kostnadsh√•ndtering
Her er noen strategier for √• h√•ndtere kostnadene ved √• sette AI-agenter i produksjon:

**Bruke mindre modeller:** Sm√• spr√•kmodeller (SLM) kan fungere godt p√• visse agent-brukstilfeller og vil redusere kostnadene betydelig. Som nevnt tidligere er det beste m√•ten √• forst√• hvor godt en SLM vil prestere p√• ditt brukstilfelle √• bygge et evalueringssystem for √• bestemme og sammenligne ytelse mot st√∏rre modeller. Vurder √• bruke SLM-er for enklere oppgaver som intensjonsklassifisering eller parameterekstraksjon, mens du reserverer st√∏rre modeller til kompleks resonnement.

**Bruke en ruter-modell:** En lignende strategi er √• bruke en variasjon av modeller og st√∏rrelser. Du kan bruke en LLM/SLM eller serverl√∏s funksjon til √• rute foresp√∏rsler basert p√• kompleksitet til de modellene som passer best. Dette vil ogs√• bidra til √• redusere kostnadene samtidig som det sikrer ytelse p√• riktige oppgaver. For eksempel, rute enkle foresp√∏rsler til mindre, raskere modeller, og bare bruke dyre store modeller for komplekse resonnementsoppgaver.

**Caching av svar:** √Ö identifisere vanlige foresp√∏rsler og oppgaver og levere svarene f√∏r de g√•r gjennom ditt agentiske system er en god m√•te √• redusere volumet av like foresp√∏rsler p√•. Du kan til og med implementere en flyt for √• identifisere hvor lik en foresp√∏rsel er til dine bufrede foresp√∏rsler ved hjelp av mer grunnleggende AI-modeller. Denne strategien kan betydelig redusere kostnadene for ofte stilte sp√∏rsm√•l eller vanlige arbeidsflyter.

## La oss se hvordan dette fungerer i praksis

I [eksempelskriptet til denne seksjonen](./code_samples/10_autogen_evaluation.ipynb) vil vi se eksempler p√• hvordan vi kan bruke observasjonsverkt√∏y for √• overv√•ke og evaluere agenten v√•r.

### Har du flere sp√∏rsm√•l om AI-agenter i produksjon?

Bli med i [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) for √• m√∏te andre l√¶rende, delta p√• kontortid og f√• svar p√• dine sp√∏rsm√•l om AI-agenter.

## Forrige leksjon

[Metakognitivt designm√∏nster](../09-metacognition/README.md)

## Neste leksjon

[Agentiske protokoller](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi jobber for √• oppn√• n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det opprinnelige dokumentet p√• originalspr√•ket skal anses som den autoritative kilden. For kritisk informasjon anbefales det √• bruke profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r som f√∏lge av bruk av denne oversettelsen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->