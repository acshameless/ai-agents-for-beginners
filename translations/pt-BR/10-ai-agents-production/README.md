# Agentes de IA em Produ√ß√£o: Observabilidade & Avalia√ß√£o

[![Agentes de IA em Produ√ß√£o](../../../translated_images/pt-BR/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

√Ä medida que agentes de IA passam de prot√≥tipos experimentais para aplica√ß√µes no mundo real, a capacidade de entender seu comportamento, monitorar seu desempenho e avaliar sistematicamente suas sa√≠das se torna importante.

## Objetivos de Aprendizagem

Ap√≥s concluir esta li√ß√£o, voc√™ saber√° como/entender√°:
- Conceitos centrais de observabilidade e avalia√ß√£o de agentes
- T√©cnicas para melhorar o desempenho, os custos e a efetividade dos agentes
- O que e como avaliar seus agentes de IA de forma sistem√°tica
- Como controlar custos ao implantar agentes de IA em produ√ß√£o
- Como instrumentar agentes constru√≠dos com AutoGen

O objetivo √© capacit√°-lo com o conhecimento para transformar seus agentes "caixa-preta" em sistemas transparentes, gerenci√°veis e confi√°veis.

_**Nota:** √â importante implantar Agentes de IA que sejam seguros e confi√°veis. Confira tamb√©m a li√ß√£o [Building Trustworthy AI Agents](./06-building-trustworthy-agents/README.md)._

## Traces e Spans

Ferramentas de observabilidade como [Langfuse](https://langfuse.com/) ou [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) geralmente representam execu√ß√µes de agentes como traces e spans.

- **Trace** representa uma tarefa completa do agente do in√≠cio ao fim (como lidar com uma consulta do usu√°rio).
- **Spans** s√£o etapas individuais dentro do trace (como chamar um modelo de linguagem ou recuperar dados).

![√Årvore de rastreamento no Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Sem observabilidade, um agente de IA pode parecer uma "caixa-preta" ‚Äî seu estado interno e racioc√≠nio s√£o opacos, tornando dif√≠cil diagnosticar problemas ou otimizar o desempenho. Com observabilidade, agentes se tornam "caixas de vidro", oferecendo transpar√™ncia vital para construir confian√ßa e garantir que operem conforme o esperado.

## Por que a Observabilidade Importa em Ambientes de Produ√ß√£o

A transi√ß√£o de agentes de IA para ambientes de produ√ß√£o introduz um novo conjunto de desafios e requisitos. Observabilidade deixa de ser um "desej√°vel" e passa a ser uma capacidade cr√≠tica:

*   **Depura√ß√£o e An√°lise da Causa Raiz**: Quando um agente falha ou produz uma sa√≠da inesperada, ferramentas de observabilidade fornecem os traces necess√°rios para identificar a origem do erro. Isso √© especialmente importante em agentes complexos que podem envolver m√∫ltiplas chamadas LLM, intera√ß√µes com ferramentas e l√≥gica condicional.
*   **Gerenciamento de Lat√™ncia e Custos**: Agentes de IA frequentemente dependem de LLMs e outras APIs externas que s√£o cobradas por token ou por chamada. A observabilidade permite rastrear com precis√£o essas chamadas, ajudando a identificar opera√ß√µes excessivamente lentas ou caras. Isso possibilita que equipes otimizem prompts, escolham modelos mais eficientes ou redesenhem fluxos de trabalho para controlar custos operacionais e garantir uma boa experi√™ncia do usu√°rio.
*   **Confian√ßa, Seguran√ßa e Conformidade**: Em muitas aplica√ß√µes, √© importante garantir que agentes se comportem de forma segura e √©tica. Observabilidade fornece um rastro de auditoria das a√ß√µes e decis√µes do agente. Isso pode ser usado para detectar e mitigar problemas como inje√ß√£o de prompt, gera√ß√£o de conte√∫do prejudicial ou manuseio indevido de informa√ß√µes pessoalmente identific√°veis (PII). Por exemplo, voc√™ pode revisar traces para entender por que um agente forneceu certa resposta ou usou uma ferramenta espec√≠fica.
*   **Ciclos de Melhoria Cont√≠nua**: Dados de observabilidade s√£o a base de um processo de desenvolvimento iterativo. Ao monitorar como agentes se comportam no mundo real, equipes podem identificar √°reas para melhoria, coletar dados para ajuste fino de modelos e validar o impacto de mudan√ßas. Isso cria um loop de feedback onde insights de produ√ß√£o provenientes da avalia√ß√£o online alimentam experimenta√ß√£o e refinamento offline, levando a um desempenho progressivamente melhor do agente.

## M√©tricas Principais para Acompanhar

Para monitorar e entender o comportamento do agente, uma variedade de m√©tricas e sinais deve ser acompanhada. Embora as m√©tricas espec√≠ficas possam variar conforme o prop√≥sito do agente, algumas s√£o universalmente importantes.

Aqui est√£o algumas das m√©tricas mais comuns que ferramentas de observabilidade monitoram:

**Lat√™ncia:** Qu√£o r√°pido o agente responde? Tempos de espera longos impactam negativamente a experi√™ncia do usu√°rio. Voc√™ deve medir a lat√™ncia de tarefas e etapas individuais tra√ßando execu√ß√µes do agente. Por exemplo, um agente que demora 20 segundos para todas as chamadas de modelo poderia ser acelerado usando um modelo mais r√°pido ou executando chamadas de modelo em paralelo.

**Custos:** Qual √© a despesa por execu√ß√£o do agente? Agentes de IA dependem de chamadas LLM cobradas por token ou de APIs externas. Uso frequente de ferramentas ou m√∫ltiplos prompts pode aumentar rapidamente os custos. Por exemplo, se um agente chama um LLM cinco vezes por uma melhoria marginal de qualidade, voc√™ precisa avaliar se o custo √© justificado ou se poderia reduzir o n√∫mero de chamadas ou usar um modelo mais barato. Monitoramento em tempo real tamb√©m pode ajudar a identificar picos inesperados (por exemplo, bugs causando loops excessivos de API).

**Erros de Requisi√ß√£o:** Quantas requisi√ß√µes o agente falhou? Isso pode incluir erros de API ou chamadas de ferramenta que falharam. Para tornar seu agente mais robusto contra esses problemas em produ√ß√£o, voc√™ pode configurar alternativas ou tentativas de nova chamada (retries). Ex.: se o provedor de LLM A estiver fora do ar, voc√™ alterna para o provedor de LLM B como backup.

**Feedback do Usu√°rio:** Implementar avalia√ß√µes diretas dos usu√°rios fornece insights valiosos. Isso pode incluir avalia√ß√µes expl√≠citas (üëçthumbs-up/üëédown, ‚≠ê1-5 estrelas) ou coment√°rios textuais. Feedback negativo consistente deve alert√°-lo, pois √© um sinal de que o agente n√£o est√° funcionando como esperado.

**Feedback Impl√≠cito do Usu√°rio:** Comportamentos dos usu√°rios fornecem feedback indireto mesmo sem avalia√ß√µes expl√≠citas. Isso pode incluir reformula√ß√£o imediata de perguntas, consultas repetidas ou clicar em um bot√£o de tentar novamente. Ex.: se voc√™ perceber que usu√°rios repetidamente fazem a mesma pergunta, isso √© um sinal de que o agente n√£o est√° funcionando como esperado.

**Precis√£o:** Com que frequ√™ncia o agente produz sa√≠das corretas ou desej√°veis? As defini√ß√µes de precis√£o variam (por exemplo, corretude na resolu√ß√£o de problemas, precis√£o em recupera√ß√£o de informa√ß√£o, satisfa√ß√£o do usu√°rio). O primeiro passo √© definir como o sucesso se parece para seu agente. Voc√™ pode acompanhar a precis√£o por meio de verifica√ß√µes automatizadas, scores de avalia√ß√£o ou r√≥tulos de conclus√£o de tarefas. Por exemplo, marcar traces como "succeeded" ou "failed".

**M√©tricas de Avalia√ß√£o Automatizadas:** Voc√™ tamb√©m pode configurar avalia√ß√µes automatizadas. Por exemplo, pode usar um LLM para pontuar a sa√≠da do agente, por exemplo, se foi √∫til, precisa ou n√£o. Existem tamb√©m v√°rias bibliotecas de c√≥digo aberto que ajudam a pontuar diferentes aspectos do agente. Ex.: [RAGAS](https://docs.ragas.io/) para agentes RAG ou [LLM Guard](https://llm-guard.com/) para detectar linguagem prejudicial ou inje√ß√£o de prompt.

Na pr√°tica, uma combina√ß√£o dessas m√©tricas fornece a melhor cobertura da sa√∫de de um agente de IA. No [notebook de exemplo](./code_samples/10_autogen_evaluation.ipynb) deste cap√≠tulo, mostraremos como essas m√©tricas aparecem em exemplos reais, mas primeiro, aprenderemos como √© um fluxo de trabalho t√≠pico de avalia√ß√£o.

## Instrumente seu Agente

Para coletar dados de tracing, voc√™ precisar√° instrumentar seu c√≥digo. O objetivo √© instrumentar o c√≥digo do agente para emitir traces e m√©tricas que possam ser capturados, processados e visualizados por uma plataforma de observabilidade.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) emergiu como um padr√£o da ind√∫stria para observabilidade de LLMs. Ele fornece um conjunto de APIs, SDKs e ferramentas para gerar, coletar e exportar dados de telemetria.

Existem muitas bibliotecas de instrumenta√ß√£o que envolvem frameworks de agente existentes e facilitam exportar spans do OpenTelemetry para uma ferramenta de observabilidade. Abaixo est√° um exemplo de instrumenta√ß√£o de um agente AutoGen com a [biblioteca de instrumenta√ß√£o OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

O [notebook de exemplo](./code_samples/10_autogen_evaluation.ipynb) neste cap√≠tulo demonstrar√° como instrumentar seu agente AutoGen.

**Cria√ß√£o Manual de Spans:** Embora bibliotecas de instrumenta√ß√£o forne√ßam uma boa linha de base, muitas vezes h√° casos em que informa√ß√µes mais detalhadas ou personalizadas s√£o necess√°rias. Voc√™ pode criar spans manualmente para adicionar l√≥gica de aplica√ß√£o personalizada. Mais importante, eles podem enriquecer spans criados automaticamente ou manualmente com atributos personalizados (tamb√©m conhecidos como tags ou metadados). Esses atributos podem incluir dados espec√≠ficos do neg√≥cio, c√°lculos intermedi√°rios ou qualquer contexto que possa ser √∫til para depura√ß√£o ou an√°lise, como `user_id`, `session_id` ou `model_version`.

Exemplo de cria√ß√£o de traces e spans manualmente com o [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3): 

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Avalia√ß√£o do Agente

Observabilidade nos d√° m√©tricas, mas avalia√ß√£o √© o processo de analisar esses dados (e realizar testes) para determinar qu√£o bem um agente de IA est√° desempenhando e como ele pode ser melhorado. Em outras palavras, uma vez que voc√™ tem esses traces e m√©tricas, como us√°-los para julgar o agente e tomar decis√µes?

Avalia√ß√µes regulares s√£o importantes porque agentes de IA costumam ser n√£o-determin√≠sticos e podem evoluir (por meio de atualiza√ß√µes ou altera√ß√£o do comportamento do modelo) ‚Äì sem avalia√ß√£o, voc√™ n√£o saberia se seu "agente inteligente" est√° realmente fazendo bem seu trabalho ou se regrediu.

Existem duas categorias de avalia√ß√µes para agentes de IA: **avalia√ß√£o online** e **avalia√ß√£o offline**. Ambas s√£o valiosas e se complementam. Normalmente come√ßamos com avalia√ß√£o offline, pois este √© o passo m√≠nimo necess√°rio antes de implantar qualquer agente.

### Avalia√ß√£o Offline

![Itens do conjunto de dados no Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Isso envolve avaliar o agente em um ambiente controlado, tipicamente usando conjuntos de teste, n√£o consultas de usu√°rios ao vivo. Voc√™ usa conjuntos de dados curados onde se sabe qual √© a sa√≠da esperada ou o comportamento correto, e ent√£o executa seu agente sobre eles.

Por exemplo, se voc√™ construiu um agente para resolver problemas matem√°ticos em texto, pode ter um [conjunto de teste](https://huggingface.co/datasets/gsm8k) de 100 problemas com respostas conhecidas. A avalia√ß√£o offline costuma ser feita durante o desenvolvimento (e pode fazer parte de pipelines de CI/CD) para verificar melhorias ou proteger contra regress√µes. O benef√≠cio √© que √© **reprodut√≠vel e voc√™ pode obter m√©tricas claras de precis√£o, j√° que tem a verdade de base**. Voc√™ tamb√©m pode simular consultas de usu√°rios e medir as respostas do agente contra respostas ideais ou usar m√©tricas automatizadas, como descrito acima.

O principal desafio da avalia√ß√£o offline √© garantir que seu conjunto de teste seja abrangente e permane√ßa relevante ‚Äì o agente pode ter bom desempenho em um conjunto de teste fixo, mas encontrar consultas muito diferentes em produ√ß√£o. Portanto, voc√™ deve manter os conjuntos de teste atualizados com novos casos de borda e exemplos que reflitam cen√°rios do mundo real. Uma mistura de pequenos casos de "smoke test" e conjuntos maiores de avalia√ß√£o √© √∫til: conjuntos pequenos para verifica√ß√µes r√°pidas e conjuntos maiores para m√©tricas de desempenho mais amplas.

### Avalia√ß√£o Online 

![Vis√£o geral das m√©tricas de observabilidade](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Refere-se a avaliar o agente em um ambiente ao vivo e do mundo real, ou seja, durante o uso real em produ√ß√£o. Avalia√ß√£o online envolve monitorar o desempenho do agente em intera√ß√µes reais de usu√°rios e analisar os resultados de forma cont√≠nua.

Por exemplo, voc√™ pode acompanhar taxas de sucesso, pontua√ß√µes de satisfa√ß√£o do usu√°rio ou outras m√©tricas no tr√°fego ao vivo. A vantagem da avalia√ß√£o online √© que ela **captura coisas que voc√™ pode n√£o antecipar em um ambiente de laborat√≥rio** ‚Äì voc√™ pode observar deriva do modelo ao longo do tempo (se a efetividade do agente se degradar conforme padr√µes de entrada mudam) e capturar consultas ou situa√ß√µes inesperadas que n√£o estavam em seus dados de teste. Isso fornece uma imagem verdadeira de como o agente se comporta em produ√ß√£o.

A avalia√ß√£o online frequentemente envolve coletar feedback impl√≠cito e expl√≠cito dos usu√°rios, como discutido, e possivelmente executar testes shadow ou testes A/B (onde uma nova vers√£o do agente roda em paralelo para compara√ß√£o com a antiga). O desafio √© que pode ser complicado obter r√≥tulos ou pontua√ß√µes confi√°veis para intera√ß√µes ao vivo ‚Äì voc√™ pode depender do feedback do usu√°rio ou de m√©tricas downstream (como se o usu√°rio clicou no resultado).

### Combinando os dois

Avalia√ß√µes online e offline n√£o s√£o mutuamente exclusivas; elas se complementam muito bem. Insights do monitoramento online (por exemplo, novos tipos de consultas de usu√°rios onde o agente tem baixo desempenho) podem ser usados para aumentar e melhorar conjuntos de teste offline. Por outro lado, agentes que se saem bem em testes offline podem ser implantados com mais confian√ßa e monitorados online.

De fato, muitas equipes adotam um loop:

_avaliar offline -> implantar -> monitorar online -> coletar novos casos de falha -> adicionar ao conjunto de teste offline -> refinar o agente -> repetir_.

## Problemas Comuns

Ao implantar agentes de IA em produ√ß√£o, voc√™ pode encontrar v√°rios desafios. Aqui est√£o alguns problemas comuns e suas poss√≠veis solu√ß√µes:

| **Problema**    | **Solu√ß√£o Potencial**   |
| ------------- | ------------------ |
| Agente de IA n√£o executa tarefas de forma consistente | - Aprimore o prompt fornecido ao Agente de IA; seja claro quanto aos objetivos.<br>- Identifique onde dividir as tarefas em subtarefas e trat√°-las por m√∫ltiplos agentes pode ajudar. |
| Agente de IA entrando em loops cont√≠nuos  | - Garanta que voc√™ tenha termos e condi√ß√µes de t√©rmino claros para que o Agente saiba quando parar o processo.<br>- Para tarefas complexas que exigem racioc√≠nio e planejamento, use um modelo maior especializado para tarefas de racioc√≠nio. |
| Chamadas a ferramentas pelo Agente de IA n√£o est√£o tendo bom desempenho   | - Teste e valide a sa√≠da da ferramenta fora do sistema do agente.<br>- Aprimore os par√¢metros definidos, prompts e a nomenclatura das ferramentas.  |
| Sistema Multi-Agente n√£o est√° funcionando de forma consistente | - Aprimore os prompts dados a cada agente para garantir que sejam espec√≠ficos e distintos entre si.<br>- Construa um sistema hier√°rquico usando um agente de "routing" ou controlador para determinar qual agente √© o correto. |

Muitos desses problemas podem ser identificados de forma mais eficaz com observabilidade em vigor. Os traces e m√©tricas discutidos anteriormente ajudam a localizar exatamente onde no fluxo de trabalho do agente os problemas ocorrem, tornando a depura√ß√£o e otimiza√ß√£o muito mais eficientes.

## Gerenciando Custos
Aqui est√£o algumas estrat√©gias para gerenciar os custos de implantar agentes de IA em produ√ß√£o:

**Using Smaller Models:** Small Language Models (SLMs) can perform well on certain agentic use-cases and will reduce costs significantly. As mentioned earlier, building an evaluation system to determine and compare performance vs larger models is the best way to understand how well an SLM will perform on your use case. Consider using SLMs for simpler tasks like intent classification or parameter extraction, while reserving larger models for complex reasoning.

**Using a Router Model:** A similar strategy is to use a diversity of models and sizes. You can use an LLM/SLM or serverless function to route requests based on complexity to the best fit models. This will also help reduce costs while also ensuring performance on the right tasks. For example, route simple queries to smaller, faster models, and only use expensive large models for complex reasoning tasks.

**Caching Responses:** Identifying common requests and tasks and providing the responses before they go through your agentic system is a good way to reduce the volume of similar requests. You can even implement a flow to identify how similar a request is to your cached requests using more basic AI models. This strategy can significantly reduce costs for frequently asked questions or common workflows.

## Vamos ver como isso funciona na pr√°tica

In the [example notebook of this section](./code_samples/10_autogen_evaluation.ipynb), we‚Äôll see examples of how we can use observability tools to monitor and evaluate our agent.


### Tem mais perguntas sobre Agentes de IA em Produ√ß√£o?

Participe do [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) para encontrar outros aprendizes, participar de hor√°rios de atendimento e obter respostas √†s suas perguntas sobre Agentes de IA.

## Li√ß√£o Anterior

[Padr√£o de Design de Metacogni√ß√£o](../09-metacognition/README.md)

## Pr√≥xima Li√ß√£o

[Protocolos Agentivos](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Isen√ß√£o de responsabilidade:
Este documento foi traduzido usando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original, em seu idioma nativo, deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por um tradutor humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->