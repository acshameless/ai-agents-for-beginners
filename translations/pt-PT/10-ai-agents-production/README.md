# Agentes de IA em Produ√ß√£o: Observabilidade & Avalia√ß√£o

[![AI Agents in Production](../../../translated_images/pt-PT/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

√Ä medida que os agentes de IA passam de prot√≥tipos experimentais para aplica√ß√µes no mundo real, a capacidade de compreender o seu comportamento, monitorizar o seu desempenho e avaliar sistematicamente os seus resultados torna-se importante.

## Objetivos de Aprendizagem

Ap√≥s completar esta li√ß√£o, ir√° saber fazer/compreender:
- Conceitos essenciais de observabilidade e avalia√ß√£o de agentes
- T√©cnicas para melhorar o desempenho, custos e efic√°cia dos agentes
- O que e como avaliar sistematicamente os seus agentes de IA
- Como controlar custos ao implementar agentes de IA em produ√ß√£o
- Como instrumentar agentes constru√≠dos com AutoGen

O objetivo √© equip√°-lo com o conhecimento para transformar os seus agentes "caixa preta" em sistemas transparentes, ger√≠veis e fi√°veis.

_**Nota:** √â importante implementar Agentes de IA que sejam seguros e confi√°veis. Consulte tamb√©m a li√ß√£o [Constru√ß√£o de Agentes de IA Confi√°veis](./06-building-trustworthy-agents/README.md)._

## Rastreamentos e Spans

Ferramentas de observabilidade, como [Langfuse](https://langfuse.com/) ou [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry), normalmente representam execu√ß√µes de agentes como rastreamentos e spans.

- **Rastreamento (Trace)** representa uma tarefa completa do agente do in√≠cio ao fim (como tratar uma consulta de utilizador).
- **Spans** s√£o passos individuais dentro do rastreamento (como chamar um modelo de linguagem ou recuperar dados).

![Trace tree in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Sem observabilidade, um agente de IA pode parecer uma "caixa preta" ‚Äî o seu estado interno e racioc√≠nio s√£o opacos, dificultando a dete√ß√£o de problemas ou otimiza√ß√£o do desempenho. Com observabilidade, os agentes tornam-se "caixas de vidro", oferecendo transpar√™ncia que √© vital para construir confian√ßa e garantir que operam conforme previsto.

## Porque a Observabilidade √© Importante em Ambientes de Produ√ß√£o

A transi√ß√£o dos agentes de IA para ambientes de produ√ß√£o introduz um novo conjunto de desafios e requisitos. A observabilidade deixa de ser algo "agrad√°vel de ter" para se tornar uma capacidade cr√≠tica:

*   **Depura√ß√£o e An√°lise da Causa Raiz**: Quando um agente falha ou produz um resultado inesperado, as ferramentas de observabilidade fornecem os rastreamentos necess√°rios para identificar a origem do erro. Isto √© especialmente importante em agentes complexos que podem envolver m√∫ltiplas chamadas a LLM, intera√ß√µes com ferramentas e l√≥gica condicional.
*   **Gest√£o de Lat√™ncia e Custos**: Os agentes de IA frequentemente dependem de LLMs e outras APIs externas faturadas por token ou por chamada. A observabilidade permite o acompanhamento preciso dessas chamadas, ajudando a identificar opera√ß√µes excessivamente lentas ou caras. Isto permite √†s equipas otimizar prompts, selecionar modelos mais eficientes ou redesenhar fluxos de trabalho para controlar custos operacionais e garantir uma boa experi√™ncia ao utilizador.
*   **Confian√ßa, Seguran√ßa e Conformidade**: Em muitas aplica√ß√µes, √© importante garantir que os agentes se comportam de forma segura e √©tica. A observabilidade fornece um registo de auditoria das a√ß√µes e decis√µes do agente. Este pode ser usado para detetar e mitigar problemas como inje√ß√£o de prompt, gera√ß√£o de conte√∫do prejudicial ou o manuseio incorreto de informa√ß√µes pessoalmente identific√°veis (PII). Por exemplo, pode rever rastreamentos para entender por que um agente forneceu certa resposta ou usou uma ferramenta espec√≠fica.
*   **Ciclos de Melhoria Cont√≠nua**: Os dados de observabilidade s√£o a base de um processo de desenvolvimento iterativo. Ao monitorizar o desempenho dos agentes no mundo real, as equipas podem identificar √°reas para melhoria, recolher dados para ajuste fino dos modelos e validar o impacto das altera√ß√µes. Isto cria um ciclo de feedback onde insights da produ√ß√£o a partir da avalia√ß√£o online informam experimenta√ß√£o e refinamento offline, levando a um desempenho progressivamente melhor dos agentes.

## M√©tricas-Chave a Monitorizar

Para monitorizar e entender o comportamento do agente, deve-se acompanhar uma s√©rie de m√©tricas e sinais. Embora as m√©tricas espec√≠ficas possam variar conforme o prop√≥sito do agente, algumas s√£o universalmente importantes.

Aqui est√£o algumas das m√©tricas mais comuns que as ferramentas de observabilidade monitorizam:

**Lat√™ncia:** Com que rapidez responde o agente? Tempos de espera longos impactam negativamente a experi√™ncia do utilizador. Deve medir a lat√™ncia para tarefas e etapas individuais, rastreando as execu√ß√µes do agente. Por exemplo, um agente que leva 20 segundos para todas as chamadas do modelo pode ser acelerado utilizando um modelo mais r√°pido ou executando chamadas em paralelo.

**Custos:** Qual o custo por execu√ß√£o do agente? Os agentes de IA dependem de chamadas a LLM faturadas por token ou APIs externas. O uso frequente de ferramentas ou m√∫ltiplos prompts pode aumentar rapidamente os custos. Por exemplo, se um agente chama um LLM cinco vezes para uma melhoria marginal da qualidade, deve avaliar se o custo √© justificado ou se pode reduzir o n√∫mero de chamadas ou usar um modelo mais barato. Monitoriza√ß√£o em tempo real pode tamb√©m ajudar a identificar picos inesperados (ex.: bugs que causam loops excessivos de API).

**Erros de Pedido:** Quantas requisi√ß√µes falharam? Isto pode incluir erros de API ou chamadas a ferramentas que falharam. Para tornar o seu agente mais robusto contra estes erros em produ√ß√£o, pode configurar mecanismos de fallback ou tentativas de repeti√ß√£o. Ex.: se o fornecedor LLM A estiver indispon√≠vel, pode mudar para o fornecedor LLM B como reserva.

**Feedback do Utilizador:** Implementar avalia√ß√µes diretas dos utilizadores fornece insights valiosos. Isto pode incluir classifica√ß√µes expl√≠citas (üëçgosto/üëén√£o gosto, ‚≠ê 1-5 estrelas) ou coment√°rios textuais. Feedback negativo consistente deve alert√°-lo pois √© um sinal de que o agente n√£o est√° a funcionar como esperado.

**Feedback Impl√≠cito do Utilizador:** Os comportamentos dos utilizadores fornecem feedback indireto mesmo sem classifica√ß√µes expl√≠citas. Isto pode incluir reformula√ß√£o imediata da pergunta, consultas repetidas ou clicar num bot√£o de retry. Ex.: se notar que os utilizadores fazem repetidamente a mesma pergunta, √© um sinal de que o agente n√£o est√° a funcionar como esperado.

**Precis√£o:** Com que frequ√™ncia o agente produz resultados corretos ou desej√°veis? As defini√ß√µes de precis√£o variam (ex.: corre√ß√£o na resolu√ß√£o de problemas, precis√£o na recupera√ß√£o de informa√ß√£o, satisfa√ß√£o do utilizador). O primeiro passo √© definir o que constitui sucesso para o seu agente. Pode acompanhar precis√£o atrav√©s de verifica√ß√µes autom√°ticas, pontua√ß√µes de avalia√ß√£o ou etiquetas de conclus√£o da tarefa. Por exemplo, marcar rastreamentos como "bem-sucedidos" ou "falhados".

**M√©tricas de Avalia√ß√£o Autom√°tica:** Pode tamb√©m configurar avalia√ß√µes autom√°ticas. Por exemplo, pode usar um LLM para pontuar a sa√≠da do agente, p.ex., se √© √∫til, precisa ou n√£o. Existem tamb√©m v√°rias bibliotecas open source que ajudam a pontuar diferentes aspetos do agente. Ex.: [RAGAS](https://docs.ragas.io/) para agentes RAG ou [LLM Guard](https://llm-guard.com/) para detetar linguagem prejudicial ou inje√ß√£o de prompt.

Na pr√°tica, uma combina√ß√£o destas m√©tricas oferece a melhor cobertura da sa√∫de de um agente de IA. No [caderno de exemplo](./code_samples/10_autogen_evaluation.ipynb) deste cap√≠tulo, iremos mostrar como estas m√©tricas se apresentam em exemplos reais, mas primeiro, vamos aprender como √© um fluxo t√≠pico de avalia√ß√£o.

## Instrumente o Seu Agente

Para recolher dados de rastreamento, precisar√° instrumentar o seu c√≥digo. O objetivo √© instrumentar o c√≥digo do agente para emitir rastreamentos e m√©tricas que possam ser capturados, processados e visualizados por uma plataforma de observabilidade.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) tornou-se um standard da ind√∫stria para observabilidade de LLMs. Fornece um conjunto de APIs, SDKs e ferramentas para gerar, recolher e exportar dados de telemetria.

Existem muitas bibliotecas de instrumenta√ß√£o que envolvem frameworks existentes de agentes e facilitam a exporta√ß√£o de spans OpenTelemetry para uma ferramenta de observabilidade. Abaixo est√° um exemplo de como instrumentar um agente AutoGen com a [biblioteca de instrumenta√ß√£o OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

O [caderno de exemplo](./code_samples/10_autogen_evaluation.ipynb) deste cap√≠tulo demonstra como instrumentar o seu agente AutoGen.

**Cria√ß√£o Manual de Spans:** Apesar das bibliotecas de instrumenta√ß√£o fornecerem uma boa base, h√° frequentemente casos onde se precisa de informa√ß√£o mais detalhada ou personalizada. Pode criar spans manualmente para adicionar l√≥gica customizada da aplica√ß√£o. Mais importante, pode enriquecer spans criados autom√°tica ou manualmente com atributos personalizados (tamb√©m conhecidos como tags ou metadados). Estes atributos podem incluir dados espec√≠ficos do neg√≥cio, c√°lculos interm√©dios ou qualquer contexto que seja √∫til para depura√ß√£o ou an√°lise, como `user_id`, `session_id` ou `model_version`.

Exemplo de cria√ß√£o manual de rastreamentos e spans com o [SDK Langfuse Python](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Avalia√ß√£o do Agente

A observabilidade fornece m√©tricas, mas a avalia√ß√£o √© o processo de analisar esses dados (e realizar testes) para determinar como est√° o desempenho do agente de IA e como pode ser melhorado. Por outras palavras, uma vez que tem esses rastreamentos e m√©tricas, como os usa para julgar o agente e tomar decis√µes?

A avalia√ß√£o regular √© importante porque os agentes de IA s√£o frequentemente n√£o determin√≠sticos e podem evoluir (por atualiza√ß√µes ou mudan√ßa no comportamento do modelo) ‚Äì sem avalia√ß√£o, n√£o saberia se o seu "agente inteligente" est√° realmente a fazer bem o seu trabalho ou se decaiu.

Existem duas categorias de avalia√ß√£o para agentes de IA: **avalia√ß√£o online** e **avalia√ß√£o offline**. Ambas s√£o valiosas e complementares. Normalmente come√ßamos pela avalia√ß√£o offline, pois este √© o passo m√≠nimo necess√°rio antes de implementar qualquer agente.

### Avalia√ß√£o Offline

![Dataset items in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Envolve avaliar o agente num ambiente controlado, tipicamente usando conjuntos de dados de teste, n√£o consultas reais de utilizadores. Usa conjuntos de dados curados onde sabe qual √© o resultado esperado ou comportamento correto, e depois executa o seu agente nesses dados.

Por exemplo, se construiu um agente para resolver problemas matem√°ticos em palavra, pode ter um [conjunto de dados de teste](https://huggingface.co/datasets/gsm8k) com 100 problemas e respostas conhecidas. A avalia√ß√£o offline √© geralmente feita durante o desenvolvimento (e pode fazer parte das pipelines de CI/CD) para verificar melhorias ou proteger contra regress√µes. A vantagem √© que √© **repet√≠vel e pode obter m√©tricas claras de precis√£o, uma vez que tem a verdade fundamentada**. Pode tamb√©m simular consultas de utilizador e medir as respostas do agente contra respostas ideais ou usar m√©tricas autom√°ticas como descrito acima.

O grande desafio com a avalia√ß√£o offline √© garantir que o conjunto de dados de teste √© abrangente e se mant√©m relevante ‚Äì o agente pode usar bem um conjunto fixo, mas encontrar consultas muito diferentes em produ√ß√£o. Assim, deve manter os conjuntos de teste atualizados com novos casos de borda e exemplos que reflitam os cen√°rios do mundo real. Uma mistura de pequenos casos ‚Äúsmoke test‚Äù e conjuntos maiores de avalia√ß√£o √© √∫til: pequenos conjuntos para verifica√ß√µes r√°pidas e conjuntos maiores para m√©tricas de desempenho mais amplas.

### Avalia√ß√£o Online

![Observability metrics overview](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Refere-se √† avalia√ß√£o do agente num ambiente real e ao vivo, ou seja, durante o uso efetivo em produ√ß√£o. A avalia√ß√£o online envolve monitorizar o desempenho do agente nas intera√ß√µes reais dos utilizadores e analisar os resultados continuamente.

Por exemplo, pode acompanhar taxas de sucesso, pontua√ß√µes de satisfa√ß√£o do utilizador ou outras m√©tricas no tr√°fego ao vivo. A vantagem da avalia√ß√£o online √© que **captura coisas que pode n√£o antecipar num laborat√≥rio** ‚Äì pode observar desvios do modelo ao longo do tempo (se a efic√°cia do agente decrescer √† medida que os padr√µes de entrada mudam) e detectar consultas ou situa√ß√µes inesperadas que n√£o estavam nos dados de teste. Fornece uma imagem real de como o agente se comporta no "mundo real".

A avalia√ß√£o online envolve frequentemente a recolha de feedback impl√≠cito e expl√≠cito dos utilizadores, como foi discutido, e possivelmente a realiza√ß√£o de testes sombra ou testes A/B (onde uma nova vers√£o do agente corre em paralelo para compara√ß√£o com a antiga). O desafio √© que pode ser dif√≠cil obter etiquetas ou pontua√ß√µes fi√°veis para intera√ß√µes ao vivo ‚Äì pode depender do feedback do utilizador ou de m√©tricas subsequentes (ex.: se o utilizador clicou no resultado).

### Combinar os dois

As avalia√ß√µes online e offline n√£o s√£o mutuamente exclusivas; s√£o altamente complementares. Os insights da monitoriza√ß√£o online (ex.: novos tipos de consultas onde o agente tem desempenho fraco) podem ser usados para melhorar os conjuntos de dados de teste offline. Por outro lado, agentes que performam bem nos testes offline podem depois ser implementados com mais confian√ßa e monitorizados online.

De facto, muitas equipas adotam um ciclo:

_avaliar offline -> implementar -> monitorizar online -> recolher novos casos de falha -> adicionar ao conjunto offline -> refinar agente -> repetir_.

## Problemas Comuns

Ao implementar agentes de IA em produ√ß√£o, poder√° encontrar v√°rios desafios. Aqui est√£o alguns problemas comuns e as suas poss√≠veis solu√ß√µes:

| **Problema**    | **Solu√ß√£o Potencial**   |
| ------------- | ------------------ |
| Agente de IA n√£o executa tarefas de forma consistente | - Refinar o prompt dado ao agente de IA; ser claro nos objetivos.<br>- Identificar onde dividir as tarefas em subtarefas e lidar com elas por m√∫ltiplos agentes pode ajudar. |
| Agente de IA entra em loops cont√≠nuos  | - Garantir que tem termos e condi√ß√µes claros de t√©rmino para que o agente saiba quando parar o processo.<br>- Para tarefas complexas que requerem racioc√≠nio e planeamento, usar um modelo maior especializado nessas tarefas. |
| Chamadas √†s ferramentas do agente n√£o est√£o a funcionar bem   | - Testar e validar a sa√≠da da ferramenta fora do sistema do agente.<br>- Refinar os par√¢metros definidos, prompts e nomes das ferramentas.  |
| Sistema Multi-Agente n√£o funciona de forma consistente | - Refinar os prompts dados a cada agente para garantir que s√£o espec√≠ficos e distintos entre si.<br>- Construir um sistema hier√°rquico usando um agente de "roteamento" ou controlador para determinar qual agente √© o correto. |

Muitos destes problemas podem ser identificados de forma mais eficaz com observabilidade implementada. Os rastreamentos e m√©tricas discutidos anteriormente ajudam a localizar exatamente onde no fluxo de trabalho do agente ocorrem os problemas, tornando a depura√ß√£o e otimiza√ß√£o muito mais eficientes.

## Gest√£o de Custos
Aqui est√£o algumas estrat√©gias para gerir os custos de implementa√ß√£o de agentes de IA em produ√ß√£o:

**Utilizar Modelos Mais Pequenos:** Modelos de Linguagem Pequenos (SLMs) podem ter um bom desempenho em certos casos de uso agentic e reduzir√£o significativamente os custos. Como mencionado anteriormente, construir um sistema de avalia√ß√£o para determinar e comparar o desempenho em rela√ß√£o a modelos maiores √© a melhor forma de entender qu√£o bem um SLM se comportar√° no seu caso de uso. Considere usar SLMs para tarefas mais simples, como classifica√ß√£o de inten√ß√£o ou extra√ß√£o de par√¢metros, enquanto reserva modelos maiores para racioc√≠nios complexos.

**Usar um Modelo de Roteamento:** Uma estrat√©gia semelhante √© usar uma diversidade de modelos e tamanhos. Pode usar um LLM/SLM ou uma fun√ß√£o serverless para encaminhar pedidos com base na complexidade para os modelos mais adequados. Isto tamb√©m ajudar√° a reduzir custos, garantindo o desempenho nas tarefas certas. Por exemplo, encaminhar consultas simples para modelos menores e mais r√°pidos, e usar apenas modelos grandes e dispendiosos para tarefas de racioc√≠nio complexo.

**Cache de Respostas:** Identificar pedidos e tarefas comuns e fornecer as respostas antes de passarem pelo seu sistema agentic √© uma boa forma de reduzir o volume de pedidos semelhantes. Pode at√© implementar um fluxo para identificar o qu√£o semelhante um pedido √© aos seus pedidos em cache usando modelos de IA mais b√°sicos. Esta estrat√©gia pode reduzir significativamente os custos para perguntas frequentes ou fluxos de trabalho comuns.

## Vamos ver como isto funciona na pr√°tica

No [exemplo de notebook desta se√ß√£o](./code_samples/10_autogen_evaluation.ipynb), veremos exemplos de como podemos usar ferramentas de observabilidade para monitorizar e avaliar o nosso agente.


### Tem mais perguntas sobre Agentes de IA em Produ√ß√£o?

Junte-se ao [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) para encontrar outros aprendizes, participar em sess√µes de esclarecimento e obter respostas √†s suas perguntas sobre Agentes de IA.

## Aula Anterior

[Metacognition Design Pattern](../09-metacognition/README.md)

## Pr√≥xima Aula

[Agentic Protocols](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, pedimos que tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa dever√° ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes erradas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->