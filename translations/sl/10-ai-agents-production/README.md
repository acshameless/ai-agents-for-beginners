# AI agenti v produkciji: Opazljivost in ocenjevanje

[![AI agenti v produkciji](../../../translated_images/sl/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

Ker AI agenti prehajajo iz eksperimentalnih prototipov v aplikacije v resniÄnem svetu, postaja pomembna sposobnost razumevanja njihovega vedenja, spremljanja zmogljivosti in sistematiÄnega ocenjevanja njihovih izhodov.

## Cilji uÄenja

Po konÄani lekciji boste znali/razumeli:
- Osnovne koncepte opazljivosti in ocenjevanja agentov
- Tehnike za izboljÅ¡anje zmogljivosti, stroÅ¡kov in uÄinkovitosti agentov
- Kaj in kako sistematiÄno ocenjevati vaÅ¡e AI agente
- Kako nadzorovati stroÅ¡ke pri uvajanju AI agentov v produkcijo
- Kako instrumentirati agente zgrajene z AutoGen

Cilj je, da vas opremimo z znanjem, kako spremeniti vaÅ¡e "Ärne skrinjice" agente v pregledne, obvladljive in zanesljive sisteme.

_**Opomba:** Pomembno je uvajati AI agente, ki so varni in zaupanja vredni. Oglejte si tudi lekcijo [Gradnja zaupanja vrednih AI agentov](./06-building-trustworthy-agents/README.md)._

## Sledi in spani

Orodja za opazljivost, kot sta [Langfuse](https://langfuse.com/) ali [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry), obiÄajno predstavljajo izvedbe agentov kot sledi in spane.

- **Trace** predstavlja celotno nalogo agenta od zaÄetka do konca (npr. obravnava uporabniÅ¡ke poizvedbe).
- **Spani** so posamezni koraki znotraj sledi (npr. klic jezikovnega modela ali pridobivanje podatkov).

![Drevo sledi v Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Brez opazljivosti se AI agent lahko zdi kot "Ärna skrinjica" â€” njegovo notranje stanje in sklepanje sta neprosojna, zaradi Äesar je teÅ¾ko diagnosticirati teÅ¾ave ali optimizirati delovanje. Z opazljivostjo agenti postanejo "steklene skrinjice", ki nudijo prosojnost, bistveno za gradnjo zaupanja in zagotavljanje delovanja po priÄakovanjih.

## Zakaj je opazljivost pomembna v produkcijskih okoljih

Prehod AI agentov v produkcijska okolja prinaÅ¡a nov nabor izzivov in zahtev. Opazljivost ni veÄ "le lepo imeti", temveÄ kljuÄna zmogljivost:

*   **RazhroÅ¡Äevanje in analiza izvornega vzroka**: Ko agent ne uspe ali poda nepriÄakovan izhod, orodja za opazljivost zagotavljajo sledi, potrebne za natanÄno lociranje vira napake. To je Å¡e posebej pomembno pri kompleksnih agentih, ki lahko vkljuÄujejo veÄ klicev LLM, interakcije z orodji in pogojno logiko.
*   **Upravljanje zakasnitev in stroÅ¡kov**: AI agenti pogosto temeljijo na LLM modelih in drugih zunanjih API-jih, za katere se zaraÄunava na token ali klic. Opazljivost omogoÄa natanÄno sledenje teh klicev in pomaga identificirati operacije, ki so pretirano poÄasne ali drage. To ekipam omogoÄa optimizacijo pozivov, izbiro bolj uÄinkovitih modelov ali prenovo potekov dela za obvladovanje operativnih stroÅ¡kov in zagotavljanje dobre uporabniÅ¡ke izkuÅ¡nje.
*   **Zaupanje, varnost in skladnost**: V mnogih aplikacijah je pomembno zagotavljanje varnega in etiÄnega vedenja agentov. Opazljivost nudi revizijsko sled dejanj in odloÄitev agenta. To lahko uporabite za zaznavanje in ublaÅ¾itev teÅ¾av, kot so injekcije pozivov, generiranje Å¡kodljive vsebine ali nepravilno ravnanje s osebno prepoznavnimi podatki (PII). Na primer, lahko pregledate sledi, da razumete, zakaj je agent podal doloÄen odgovor ali uporabil doloÄeno orodje.
*   **Zanke za neprekinjeno izboljÅ¡evanje**: Podatki opazljivosti so temelj iterativnega razvojnega procesa. S spremljanjem, kako agenti delujejo v resniÄnem svetu, ekipe lahko identificirajo podroÄja za izboljÅ¡ave, zberejo podatke za fino nastavitev modelov in potrdijo vpliv sprememb. To ustvarja povratno zanko, kjer produkcijski vpogledi iz spletnega ocenjevanja informirajo offline eksperimentiranje in izpopolnjevanje, kar vodi k postopnemu izboljÅ¡anju zmogljivosti agentov.

## KljuÄni kazalniki za spremljanje

Za spremljanje in razumevanje vedenja agenta je treba spremljati vrsto kazalnikov in signalov. SpecifiÄni kazalniki se lahko razlikujejo glede na namen agenta, a nekateri so univerzalno pomembni.

Tukaj je nekaj najpogostejÅ¡ih kazalnikov, ki jih spremljajo orodja za opazljivost:

**Zakasnitev:** Kako hitro agent odgovori? Dolgi Äasi Äakanja negativno vplivajo na uporabniÅ¡ko izkuÅ¡njo. Merite zakasnitev za naloge in posamezne korake z sledenjem izvedbam agenta. Na primer, agent, ki za vse klice modela porabi 20 sekund, bi lahko pohitrili z uporabo hitrejÅ¡ega modela ali z vzporednim izvajanjem klicev modela.

**StroÅ¡ki:** Koliko stane ena izvedba agenta? AI agenti se zanaÅ¡ajo na klice LLM, ki se zaraÄunavajo na token ali zunanje API-je. Pogosta uporaba orodij ali veÄ pozivov lahko hitro poveÄa stroÅ¡ke. Na primer, Äe agent petkrat kliÄe LLM zaradi minimalnega izboljÅ¡anja kakovosti, morate oceniti, ali je stroÅ¡ek upraviÄen ali pa lahko zmanjÅ¡ate Å¡tevilo klicev ali uporabite cenejÅ¡i model. Spremljanje v realnem Äasu lahko tudi pomaga odkriti nepriÄakovane skoke (npr. napake, ki povzroÄajo pretirane API zanke).

**Napake zahtevkov:** Koliko zahtevkov je agent neuspel izvesti? To lahko vkljuÄuje API napake ali neuspeÅ¡ne klice orodij. Da bi agent naredili odpornejÅ¡ega pred temi teÅ¾avami v produkciji, lahko nastavite rezervne poti ali ponovitve. Npr. Äe ponudnik LLM A ne deluje, preklopite na ponudnika LLM B kot rezervnega.

**Povratne informacije uporabnikov:** Izvajanje neposrednih ocen uporabnikov zagotavlja dragocene vpoglede. To lahko vkljuÄuje eksplicitne ocene (ğŸ‘thumbs-up/ğŸ‘down, â­1-5 zvezdic) ali besedilne komentarje. Stalno negativno povratno informacijo naj vam priÅ¾ge opozorilo, saj je to znak, da agent ne deluje po priÄakovanjih. 

**Implicitne povratne informacije uporabnikov:** Vedenje uporabnikov nudi posredne povratne informacije tudi brez eksplicitnih ocen. To lahko vkljuÄuje takojÅ¡nje preoblikovanje vpraÅ¡anja, ponavljene poizvedbe ali pritisk na gumb za ponovni poizkus. Npr. Äe opazite, da uporabniki veÄkrat zastavljajo isto vpraÅ¡anje, je to znak, da agent ne deluje po priÄakovanjih.

**NatanÄnost:** Kako pogosto agent ustvari pravilne ali zaÅ¾elene izhode? Definicije natanÄnosti se razlikujejo (npr. pravilnost reÅ¡evanja problemov, natanÄnost iskanja informacij, zadovoljstvo uporabnikov). Prvi korak je opredeliti, kako izgleda uspeh za vaÅ¡ega agenta. NatanÄnost lahko spremljate prek avtomatiziranih preverjanj, ocenjevalnih toÄk ali oznak dokonÄanja nalog. Na primer, oznaÄevanje sledi kot "uspeÅ¡no" ali "neuspeÅ¡no". 

**Samodejni evalvacijski kazalniki:** Prav tako lahko nastavite samodejne evaluacije. Na primer, lahko uporabite LLM za oceno izhoda agenta, npr. ali je koristen, natanÄen ali ne. Obstaja tudi veÄ odprtokodnih knjiÅ¾nic, ki pomagajo ocenjevati razliÄne vidike agenta. Npr. [RAGAS](https://docs.ragas.io/) za RAG agente ali [LLM Guard](https://llm-guard.com/) za zaznavanje Å¡kodljivega jezika ali injekcij v pozive. 

V praksi kombinacija teh kazalnikov nudi najboljÅ¡i vpogled v zdravje AI agenta. V tem poglavju v [primerovem zvezku](./code_samples/10_autogen_evaluation.ipynb) bomo prikazali, kako ti kazalniki izgledajo v resniÄnih primerih, a najprej se bomo nauÄili, kako tipiÄen potek ocenjevanja izgleda.

## Instrumentirajte svojega agenta

Za zbiranje podatkov o sledenju boste morali instrumentirati svojo kodo. Cilj je instrumentirati kodo agenta, da oddaja sledi in metrike, ki jih lahko zajame, obdela in vizualizira platforma za opazljivost.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) se je uveljavil kot industrijski standard za opazljivost LLM. Nudi nabor API-jev, SDK-jev in orodij za ustvarjanje, zbiranje in izvoz telemetriÄnih podatkov. 

Obstaja veliko knjiÅ¾nic za instrumentiranje, ki ovijejo obstojeÄe ogrodje agentov in olajÅ¡ajo izvoz OpenTelemetry spanov v orodje za opazljivost. Spodaj je primer instrumentiranja AutoGen agenta z [OpenLit instrumentation library](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

V tem poglavju bo [primer zvezka](./code_samples/10_autogen_evaluation.ipynb) prikazal, kako instrumentirati vaÅ¡ AutoGen agent.

**RoÄno ustvarjanje spanov:** Medtem ko knjiÅ¾nice za instrumentiranje nudijo dobro osnovo, se pogosto pojavljajo primeri, kjer so potrebne bolj podrobne ali prilagojene informacije. Span-e lahko roÄno ustvarite, da dodate prilagojeno aplikacijsko logiko. Å e pomembneje, lahko obogatite samodejno ali roÄno ustvarjene spane s prilagojenimi atributi (znanimi tudi kot oznake ali metapodatki). Ti atributi lahko vkljuÄujejo poslovno-specifiÄne podatke, vmesne izraÄune ali katerikoli kontekst, ki je lahko uporaben za razhroÅ¡Äevanje ali analizo, kot so `user_id`, `session_id` ali `model_version`.

Primer roÄnega ustvarjanja sledi in spanov z [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3): 

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Ocenjevanje agentov

Opazljivost nam daje metrike, vendar je ocenjevanje proces analiziranja teh podatkov (in izvajanja testov), da ugotovimo, kako dobro AI agent deluje in kako ga je mogoÄe izboljÅ¡ati. Z drugimi besedami, ko imate te sledi in metrike, kako jih uporabite za presojanje agenta in sprejemanje odloÄitev? 

Redno ocenjevanje je pomembno, ker so AI agenti pogosto nedeterministiÄni in se lahko spreminjajo (z nadgradnjami ali driftnim vedenjem modela) â€“ brez ocenjevanja ne bi vedeli, ali vaÅ¡ Â»pametni agentÂ« dejansko opravlja svoje delo dobro ali pa je nazadoval.

Obstajata dve kategoriji ocenjevanj za AI agente: **online ocenjevanje** in **offline ocenjevanje**. Obe sta vredni in se dopolnjujeta. ObiÄajno zaÄnemo z offline ocenjevanjem, ker je to minimalni potreben korak pred uvajanjem katerega koli agenta.

### Offline ocenjevanje

![Elementi podatkovnega nabora v Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

To vkljuÄuje ocenjevanje agenta v nadzorovanem okolju, obiÄajno z uporabo testnih podatkovnih nizov, ne z Å¾ivimi uporabniÅ¡kimi poizvedbami. Uporabite skrbno izbrane podatkovne nabore, kjer poznate priÄakovani izhod ali pravilno vedenje, in nato zaÅ¾enete agenta na teh podatkih. 

Na primer, Äe ste zgradili agenta za reÅ¡evanje besedilnih matematiÄnih problemov, boste morda imeli [testni podatkovni niz](https://huggingface.co/datasets/gsm8k) s 100 problemi z znanimi odgovori. Offline ocenjevanje se pogosto izvaja med razvojem (in je lahko del CI/CD cevovodov), da preveri izboljÅ¡ave ali zaÅ¡Äiti pred regresijami. Prednost je, da je **ponovljivo in lahko dobite jasne metrike natanÄnosti, saj imate referenÄno resnico**. Prav tako lahko simulirate uporabniÅ¡ke poizvedbe in merite odzive agenta glede na idealne odgovore ali uporabite avtomatizirane metrike, kot je opisano zgoraj. 

KljuÄni izziv pri offline ocenjevanju je zagotavljanje, da je vaÅ¡ testni podatkovni niz obseÅ¾en in ostane relevanten â€“ agent je morda uspeÅ¡en na fiksnem testnem naboru, vendar se lahko v produkciji sreÄa z zelo drugaÄnimi poizvedbami. Zato naj bodo testni nabori redno posodobljeni z novimi robnimi primeri in primeri, ki odraÅ¾ajo scenarije iz resniÄnega sveta. MeÅ¡anica majhnih "smoke test" primerov in veÄjih evalvacijskih nizov je uporabna: majhni nizi za hitre preglede in veÄji za obseÅ¾nejÅ¡e metrike zmogljivosti.

### Online ocenjevanje 

![Pregled meril opazljivosti](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

To se nanaÅ¡a na ocenjevanje agenta v Å¾ivo, v resniÄnem okolju, tj. med dejansko uporabo v produkciji. Online ocenjevanje vkljuÄuje spremljanje zmogljivosti agenta pri resniÄnih uporabniÅ¡kih interakcijah in neprekinjeno analizo rezultatov. 

Na primer, morda spremljate stopnje uspeha, ocene zadovoljstva uporabnikov ali druge metrike na Å¾iÄnem prometu. Prednost online ocenjevanja je, da **ujame stvari, ki jih morda v laboratoriju ne predvidevate** â€“ lahko opazite drift modela skozi Äas (Äe uÄinkovitost agenta upada, ko se vzorci vhodov spreminjajo) in ujamete nepriÄakovane poizvedbe ali situacije, ki niso bile v vaÅ¡ih testnih podatkih. Ponuja resniÄno sliko, kako agent deluje v divjini. 

Online ocenjevanje pogosto vkljuÄuje zbiranje implicitnih in eksplicitnih povratnih informacij uporabnikov, kot je bilo omenjeno, in morebiti izvajanje shadow testov ali A/B testov (kjer nova razliÄica agenta teÄe vzporedno, da jo primerjate s staro). Izziv je, da je lahko teÅ¾ko pridobiti zanesljive oznake ali ocene za Å¾ive interakcije â€“ pogosto se zanaÅ¡ate na povratne informacije uporabnikov ali metrika na bolj oddaljenih stopnjah (npr. ali je uporabnik kliknil rezultat).

### ZdruÅ¾evanje obeh

Online in offline ocenjevanja nista izkljuÄujoÄa; sta zelo dopolnjujoÄa. Vpoglede iz spletnega spremljanja (npr. nove vrste uporabniÅ¡kih poizvedb, pri katerih agent deluje slabo) lahko uporabite za dopolnitev in izboljÅ¡anje offline testnih nizov. Obratno, agenti, ki se dobro obnesejo v offline testih, se nato lahko z veÄ zaupanja uvedejo in spremljajo online. 

Dejansko mnoge ekipe sprejmejo zanko: 

_evaluate offline -> deploy -> monitor online -> collect new failure cases -> add to offline dataset -> refine agent -> repeat_.

## Pogoste teÅ¾ave

Ko uvajate AI agente v produkcijo, se lahko sreÄate z razliÄnimi izzivi. Tukaj je nekaj pogostih teÅ¾av in njihovih moÅ¾nih reÅ¡itev:

| **TeÅ¾ava**    | **MoÅ¾na reÅ¡itev**   |
| ------------- | ------------------ |
| AI Agent ne izvaja nalog dosledno | - IzboljÅ¡ajte poziv, dan agentu; jasno doloÄite cilje.<br>- Ugotovite, kje je smiselno razdeliti naloge na podnaloge in jih obravnavati z veÄ agenti. |
| AI Agent se znajde v neskonÄnih zankah  | - Poskrbite za jasne pogoje za prekinitev, da agent ve, kdaj naj konÄa proces.<br>- Za kompleksne naloge, ki zahtevajo sklepanje in naÄrtovanje, uporabite veÄji model, specializiran za naloge sklepanja. |
| Klici orodij AI agenta ne delujejo dobro   | - Testirajte in potrdite izhod orodja zunaj sistema agenta.<br>- IzboljÅ¡ajte definirane parametre, pozive in poimenovanje orodij.  |
| Sistem veÄ agentov ne deluje dosledno | - IzboljÅ¡ajte pozive, dane vsakemu agentu, da bodo specifiÄni in razliÄni med seboj.<br>- Zgradite hierarhiÄni sistem z "usmerjevalnim" ali kontrolnim agentom, ki doloÄi, kateri agent je pravi. |

Veliko teh teÅ¾av je mogoÄe uÄinkoviteje odkriti z vzpostavljeno opazljivostjo. Sledi in metrike, o katerih smo govorili, pomagajo natanÄno doloÄiti, kje v poteku dela agenta nastanejo problemi, kar olajÅ¡a razhroÅ¡Äevanje in optimizacijo.

## Upravljanje stroÅ¡kov
Tukaj je nekaj strategij za upravljanje stroÅ¡kov uvajanja AI agentov v produkcijo:

**Using Smaller Models:** Majhni jezikovni modeli (SLMs) lahko dobro delujejo pri nekaterih agentskih primerih uporabe in bodo znatno zniÅ¾ali stroÅ¡ke. Kot je omenjeno prej, je najbolje zgraditi sistem za ocenjevanje, da doloÄite in primerjate zmogljivost proti veÄjim modelom, saj je to najboljÅ¡i naÄin, da razumete, kako dobro bo SLM deloval v vaÅ¡em primeru uporabe. Razmislite o uporabi SLM-jev za preprostejÅ¡a opravila, kot so klasifikacija namena ali izvleÄek parametrov, medtem ko rezervirate veÄje modele za kompleksno razmiÅ¡ljanje.

**Using a Router Model:** Podobna strategija je uporaba razliÄnih modelov in velikosti. Lahko uporabite LLM/SLM ali funkcijo brez streÅ¾nika za usmerjanje zahtev glede na kompleksnost do najbolj primernih modelov. To bo prav tako pomagalo zniÅ¾ati stroÅ¡ke, hkrati pa zagotoviti zmogljivost za pravilna opravila. Na primer, preproste poizvedbe usmerite na manjÅ¡e, hitrejÅ¡e modele in drage velike modele uporabite le za kompleksna razmiÅ¡ljanja.

**Caching Responses:** Prepoznavanje pogostih zahtev in opravil ter zagotavljanje odgovorov, preden gredo skozi vaÅ¡ agentski sistem, je dober naÄin za zmanjÅ¡anje obsega podobnih zahtev. Lahko celo uvedete potek, ki ugotavlja, kako podobna je zahteva vaÅ¡im predpomnjenim zahtevam, z uporabo bolj osnovnih AI modelov. Ta strategija lahko znatno zmanjÅ¡a stroÅ¡ke za pogosto zastavljena vpraÅ¡anja ali obiÄajne delovne tokove.

## Poglejmo, kako to deluje v praksi

V [primer zvezka tega razdelka](./code_samples/10_autogen_evaluation.ipynb) bomo videli primere, kako lahko uporabimo orodja za opazovanje za spremljanje in ocenjevanje naÅ¡ega agenta.


### Imate veÄ vpraÅ¡anj o AI agentih v produkciji?

PridruÅ¾ite se [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord), da se poveÅ¾ete z drugimi udeleÅ¾enci, udeleÅ¾ite ur za vpraÅ¡anja in dobite odgovore na vpraÅ¡anja o AI agentih.

## PrejÅ¡nja lekcija

[Vzorec metakognicije](../09-metacognition/README.md)

## Naslednja lekcija

[Agentni protokoli](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Izjava o omejitvi odgovornosti:
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, upoÅ¡tevajte, da avtomatizirani prevodi lahko vsebujejo napake ali netoÄnosti. Izvirni dokument v izvirnem jeziku velja za avtoritativni vir. Za kritiÄne informacije priporoÄamo strokovni prevod, opravljen s strani usposobljenega prevajalca. Ne odgovarjamo za morebitne nesporazume ali napaÄne razlage, ki izhajajo iz uporabe tega prevoda.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->