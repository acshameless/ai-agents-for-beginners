# AI-agenter i produktion: Observabilitet & utv√§rdering

[![AI Agents in Production](../../../translated_images/sv/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

N√§r AI-agenter g√•r fr√•n experimentella prototyper till verkliga till√§mpningar blir f√∂rm√•gan att f√∂rst√• deras beteende, √∂vervaka deras prestanda och systematiskt utv√§rdera deras utdata viktig.

## L√§randem√•l

Efter att ha slutf√∂rt den h√§r lektionen kommer du att veta hur du/f√∂rst√•:
- K√§rnkoncept f√∂r agentobservabilitet och utv√§rdering
- Tekniker f√∂r att f√∂rb√§ttra agenters prestanda, kostnader och effektivitet
- Vad och hur du systematiskt utv√§rderar dina AI-agenter
- Hur du kontrollerar kostnader vid drifts√§ttning av AI-agenter i produktion
- Hur du instrumenterar agenter byggda med AutoGen

M√•let √§r att ge dig kunskapen f√∂r att omvandla dina "svarta l√•da"-agenter till transparenta, hanterbara och p√•litliga system.

_**Obs:** Det √§r viktigt att drifts√§tta AI-agenter som √§r s√§kra och p√•litliga. Kolla ocks√• in lektionen [Bygga p√•litliga AI-agenter](./06-building-trustworthy-agents/README.md)._

## Sp√•r och spans

Observabilitetsverktyg som [Langfuse](https://langfuse.com/) eller [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) representerar vanligtvis agentk√∂rningar som sp√•r (traces) och spans.

- **Trace** representerar en komplett agentuppgift fr√•n start till slut (som att hantera en anv√§ndarfr√•ga).
- **Spans** √§r individuella steg inom sp√•ret (som att anropa en spr√•kmodell eller h√§mta data).

![Trace tree in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Utan observabilitet kan en AI-agent k√§nnas som en "svart l√•da" - dess interna tillst√•nd och resonemang √§r ogenomskinliga, vilket g√∂r det sv√•rt att diagnostisera problem eller optimera prestanda. Med observabilitet blir agenter "glasl√•dor", vilket ger den transparens som √§r avg√∂rande f√∂r att bygga f√∂rtroende och s√§kerst√§lla att de fungerar som avsett. 

## Varf√∂r observabilitet √§r viktigt i produktionsmilj√∂er

Att √∂verf√∂ra AI-agenter till produktionsmilj√∂er introducerar en ny upps√§ttning utmaningar och krav. Observabilitet √§r inte l√§ngre en "trevlig-att-ha"-funktion utan en kritisk kapabilitet:

*   **Fels√∂kning och rotorsaksanalys**: N√§r en agent misslyckas eller producerar ett ov√§ntat resultat ger observabilitetsverktyg de sp√•r som beh√∂vs f√∂r att lokalisera felk√§llan. Detta √§r s√§rskilt viktigt i komplexa agenter som kan involvera flera LLM-anrop, verktygsinteraktioner och villkorlig logik.
*   **Latens- och kostnadshantering**: AI-agenter f√∂rlitar sig ofta p√• LLM:er och andra externa API:er som debiteras per token eller per anrop. Observabilitet m√∂jligg√∂r exakt sp√•rning av dessa anrop, vilket hj√§lper till att identifiera operationer som √§r √∂verdrivet l√•ngsamma eller dyra. Detta g√∂r att team kan optimera prompts, v√§lja mer effektiva modeller eller omforma arbetsfl√∂den f√∂r att hantera driftkostnader och s√§kerst√§lla en bra anv√§ndarupplevelse.
*   **F√∂rtroende, s√§kerhet och efterlevnad**: I m√•nga till√§mpningar √§r det viktigt att s√§kerst√§lla att agenter upptr√§der s√§kert och etiskt. Observabilitet ger en revisionskedja av agentens handlingar och beslut. Detta kan anv√§ndas f√∂r att uppt√§cka och mildra problem som promptinjektion, generering av skadligt inneh√•ll eller felhantering av personligt identifierbar information (PII). Till exempel kan du granska sp√•r f√∂r att f√∂rst√• varf√∂r en agent gav ett visst svar eller anv√§nde ett specifikt verktyg.
*   **Kontinuerliga f√∂rb√§ttringsloopar**: Observabilitetsdata √§r grunden f√∂r en iterativ utvecklingsprocess. Genom att √∂vervaka hur agenter presterar i verkligheten kan team identifiera f√∂rb√§ttringsomr√•den, samla data f√∂r finjustering av modeller och validera effekten av √§ndringar. Detta skapar en √•terkopplingsslinga d√§r produktionsinsikter fr√•n onlineutv√§rdering informerar offline-experiment och f√∂rfining, vilket leder till successivt b√§ttre agentprestanda.

## Viktiga m√•tt att f√∂lja

F√∂r att √∂vervaka och f√∂rst√• agentbeteende b√∂r en rad m√•tt och signaler sp√•ras. Medan de specifika m√•tten kan variera beroende p√• agentens syfte, √§r vissa universellt viktiga.

H√§r √§r n√•gra av de vanligaste m√•tten som observabilitetsverktyg √∂vervakar:

**Latens:** Hur snabbt svarar agenten? L√•nga v√§ntetider p√•verkar anv√§ndarupplevelsen negativt. Du b√∂r m√§ta latens f√∂r uppgifter och individuella steg genom att sp√•ra agentk√∂rningar. Till exempel kan en agent som tar 20 sekunder f√∂r alla modellanrop accelereras genom att anv√§nda en snabbare modell eller genom att k√∂ra modellanrop parallellt.

**Kostnader:** Vad kostar en agentk√∂rning? AI-agenter f√∂rlitar sig p√• LLM-anrop som debiteras per token eller externa API:er. Frekvent verktygsanv√§ndning eller flera prompts kan snabbt √∂ka kostnaderna. Till exempel, om en agent anropar en LLM fem g√•nger f√∂r marginell kvalitetsf√∂rb√§ttring m√•ste du bed√∂ma om kostnaden √§r motiverad eller om du kan minska antalet anrop eller anv√§nda en billigare modell. Realtids√∂vervakning kan ocks√• hj√§lpa till att identifiera ov√§ntade toppar (t.ex. buggar som orsakar √∂verdrivna API-loopar).

**Felkoder i f√∂rfr√•gningar:** Hur m√•nga f√∂rfr√•gningar misslyckades agenten med? Detta kan inkludera API-fel eller misslyckade verktygsanrop. F√∂r att g√∂ra din agent mer robust mot dessa i produktion kan du sedan st√§lla in fallback-mekanismer eller retries. T.ex. om LLM-leverant√∂r A ligger nere, byter du till LLM-leverant√∂r B som backup.

**Anv√§ndarfeedback:** Implementering av direkt anv√§ndarutv√§rdering ger v√§rdefulla insikter. Detta kan inkludera explicita betyg (üëçthumbs-up/üëédown, ‚≠ê1-5 stj√§rnor) eller textkommentarer. Konsekvent negativ feedback b√∂r varna dig eftersom det √§r ett tecken p√• att agenten inte fungerar som f√∂rv√§ntat. 

**Implicit anv√§ndarfeedback:** Anv√§ndarbeteenden ger indirekt feedback √§ven utan explicita betyg. Detta kan inkludera omformulering av fr√•gor direkt, upprepade f√∂rfr√•gningar eller att klicka p√• en f√∂rs√∂k-igen-knapp. T.ex. om du ser att anv√§ndare upprepade g√•nger st√§ller samma fr√•ga √§r det ett tecken p√• att agenten inte fungerar som f√∂rv√§ntat.

**Noggrannhet:** Hur ofta producerar agenten korrekta eller √∂nskv√§rda utdata? Definitioner av noggrannhet varierar (t.ex. probleml√∂sningsriktighet, informations√•tervinningsnoggrannhet, anv√§ndarn√∂jdhet). Det f√∂rsta steget √§r att definiera vad framg√•ng betyder f√∂r din agent. Du kan sp√•ra noggrannhet via automatiska kontroller, evalueringspo√§ng eller etiketter f√∂r slutf√∂rda uppgifter. Till exempel att markera sp√•r som "succeeded" eller "failed". 

**Automatiserade utv√§rderingsm√•tt:** Du kan ocks√• s√§tta upp automatiska utv√§rderingar. Till exempel kan du anv√§nda en LLM f√∂r att po√§ngs√§tta agentens utdata, t.ex. om det √§r hj√§lpsamt, korrekt eller ej. Det finns ocks√• flera open source-bibliotek som hj√§lper dig att po√§ngs√§tta olika aspekter av agenten. T.ex. [RAGAS](https://docs.ragas.io/) f√∂r RAG-agenter eller [LLM Guard](https://llm-guard.com/) f√∂r att uppt√§cka skadligt spr√•k eller promptinjektion. 

I praktiken ger en kombination av dessa m√•tt b√§sta t√§ckning av en AI-agents h√§lsa. I detta kapitels [exempelanteckningsbok](./code_samples/10_autogen_evaluation.ipynb) visar vi hur dessa m√•tt ser ut i verkliga exempel men f√∂rst l√§r vi oss hur ett typiskt utv√§rderingsarbetsfl√∂de ser ut.

## Instrumentera din agent

F√∂r att samla in sp√•rningsdata beh√∂ver du instrumentera din kod. M√•let √§r att instrumentera agentkoden f√∂r att emittera sp√•r och m√•tt som kan f√•ngas, bearbetas och visualiseras av en observabilitetsplattform.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) har framkommit som en industristandard f√∂r LLM-observabilitet. Det tillhandah√•ller ett set med API:er, SDK:er och verktyg f√∂r att generera, samla in och exportera telemetridata. 

Det finns m√•nga instrumenteringsbibliotek som wrappar befintliga agentramverk och g√∂r det enkelt att exportera OpenTelemetry-spans till ett observabilitetsverktyg. Nedan √§r ett exempel p√• hur man instrumenterar en AutoGen-agent med [OpenLit instrumenteringsbiblioteket](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

The [example notebook](./code_samples/10_autogen_evaluation.ipynb) in this chapter will demonstrate how to instrument your AutoGen agent.

**Manuell span-skapande:** Medan instrumenteringsbibliotek ger en bra bas finns det ofta fall d√§r mer detaljerad eller anpassad information beh√∂vs. Du kan manuellt skapa spans f√∂r att l√§gga till anpassad applikationslogik. Viktigare √§r att de kan berika automatiskt eller manuellt skapade spans med anpassade attribut (√§ven k√§nda som tags eller metadata). Dessa attribut kan inkludera aff√§rsspecifik data, mellanliggande ber√§kningar eller annan kontext som kan vara anv√§ndbar f√∂r fels√∂kning eller analys, s√•som `user_id`, `session_id`, eller `model_version`.

Example on creating traces and spans manually with the [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3): 

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Agentutv√§rdering

Observabilitet ger oss m√•tt, men utv√§rdering √§r processen att analysera dessa data (och utf√∂ra tester) f√∂r att avg√∂ra hur v√§l en AI-agent presterar och hur den kan f√∂rb√§ttras. Med andra ord, n√§r du har de d√§r sp√•ren och m√•tten, hur anv√§nder du dem f√∂r att bed√∂ma agenten och fatta beslut? 

Regelbunden utv√§rdering √§r viktigt eftersom AI-agenter ofta √§r icke-deterministiska och kan f√∂r√§ndras (genom uppdateringar eller drift i modellbeteende) ‚Äì utan utv√§rdering skulle du inte veta om din "smarta agent" faktiskt g√∂r sitt jobb bra eller om den har regressat.

Det finns tv√• kategorier av utv√§rderingar f√∂r AI-agenter: **online-utv√§rdering** och **offline-utv√§rdering**. B√•da √§r v√§rdefulla och kompletterar varandra. Vi b√∂rjar vanligtvis med offline-utv√§rdering, eftersom detta √§r det minsta n√∂dv√§ndiga steget innan man drifts√§tter en agent.

### Offline-utv√§rdering

![Dataset items in Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Detta inneb√§r att utv√§rdera agenten i en kontrollerad milj√∂, vanligtvis med testdataset, inte live anv√§ndarf√∂rfr√•gningar. Du anv√§nder kuraterade dataset d√§r du vet vad den f√∂rv√§ntade utg√•ngen eller korrekt beteende √§r, och k√∂r sedan din agent p√• dessa. 

Till exempel, om du byggt en agent f√∂r matematiska textproblem kan du ha ett [testdataset](https://huggingface.co/datasets/gsm8k) p√• 100 problem med k√§nda svar. Offline-utv√§rdering g√∂rs ofta under utveckling (och kan vara en del av CI/CD-pipelines) f√∂r att kontrollera f√∂rb√§ttringar eller skydda mot regressioner. F√∂rdelen √§r att det √§r **reproducerbart och du kan f√• tydliga noggrannhetsm√•tt eftersom du har sanningen**. Du kan ocks√• simulera anv√§ndarf√∂rfr√•gningar och m√§ta agentens svar mot ideala svar eller anv√§nda automatiska m√•tt som beskrivits ovan. 

Den st√∂rsta utmaningen med offline-utv√§rdering √§r att s√§kerst√§lla att ditt testdataset √§r omfattande och f√∂rblir relevant ‚Äì agenten kan prestera v√§l p√• ett fast testset men m√∂ta mycket annorlunda fr√•gor i produktion. D√§rf√∂r b√∂r du h√•lla testseten uppdaterade med nya edge cases och exempel som speglar verkliga scenarier‚Äã. En mix av sm√• "r√∂ktest"-fall och st√∂rre utv√§rderingsset √§r anv√§ndbar: sm√• set f√∂r snabba kontroller och st√∂rre f√∂r bredare prestandam√•tt‚Äã.

### Online-utv√§rdering

![Observability metrics overview](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Detta h√§nvisar till att utv√§rdera agenten i en live, verklig milj√∂, dvs under faktisk anv√§ndning i produktion. Online-utv√§rdering inneb√§r att √∂vervaka agentens prestanda p√• verkliga anv√§ndarinteraktioner och kontinuerligt analysera resultat. 

Till exempel kan du sp√•ra framg√•ngsfrekvenser, anv√§ndarn√∂jdhetspo√§ng eller andra m√•tt p√• live-trafik. F√∂rdelen med online-utv√§rdering √§r att det **f√•ngar saker du kanske inte f√∂rutser i en laboratoriemilj√∂** ‚Äì du kan observera modelldriftsf√∂r√§ndring √∂ver tid (om agentens effektivitet f√∂rs√§mras n√§r inmatningsm√∂nster skiftar) och f√•nga ov√§ntade fr√•gor eller situationer som inte fanns i ditt testdata‚Äã. Det ger en verklig bild av hur agenten upptr√§der i f√§lt. 

Online-utv√§rdering involverar ofta insamling av implicit och explicit anv√§ndarfeedback, som diskuterats, och eventuellt k√∂rning av skuggtester eller A/B-test (d√§r en ny version av agenten k√∂rs parallellt f√∂r att j√§mf√∂ras med den gamla). Utmaningen √§r att det kan vara sv√•rt att f√• tillf√∂rlitliga etiketter eller po√§ng f√∂r live-interaktioner ‚Äì du kan beh√∂va f√∂rlita dig p√• anv√§ndarfeedback eller downstream-m√•tt (som om anv√§ndaren klickade p√• resultatet eller ej). 

### Att kombinera de tv√•

Online- och offline-utv√§rderingar utesluter inte varandra; de √§r starkt komplement√§ra. Insikter fr√•n online-√∂vervakning (t.ex. nya typer av anv√§ndarfr√•gor d√§r agenten presterar d√•ligt) kan anv√§ndas f√∂r att komplettera och f√∂rb√§ttra offline-testdataset. Omv√§nt kan agenter som presterar v√§l i offline-tester sedan drifts√§ttas mer f√∂rtroendefullt och √∂vervakas online. 

Faktum √§r att m√•nga team antar en loop: 

_utv√§rdera offline -> distribuera -> √∂vervaka online -> samla nya felfall -> l√§gg till i offline-datasetet -> f√∂rfina agenten -> upprepa_.

## Vanliga problem

N√§r du drifts√§tter AI-agenter i produktion kan du st√∂ta p√• olika utmaningar. H√§r √§r n√•gra vanliga problem och deras potentiella l√∂sningar:

| **Problem**    | **M√∂jlig l√∂sning**   |
| ------------- | ------------------ |
| AI Agent not performing tasks consistently | - F√∂rfina prompten som ges till AI-agenten; var tydlig med m√•len.<br>- Identifiera var uppdelning av uppgifterna i deluppgifter och hantering av dessa av flera agenter kan hj√§lpa. |
| AI Agent running into continuous loops  | - Se till att du har tydliga stoppvillkor s√• att agenten vet n√§r processen ska avbrytas.<br>- F√∂r komplexa uppgifter som kr√§ver resonerande och planering, anv√§nd en st√∂rre modell som √§r specialiserad f√∂r resoneringsuppgifter. |
| AI Agent tool calls are not performing well   | - Testa och validera verktygets output utanf√∂r agentsystemet.<br>- F√∂rfina de definierade parametrarna, prompts och namngivningen av verktygen.  |
| Multi-Agent system not performing consistently | - F√∂rfina prompts som ges till varje agent f√∂r att s√§kerst√§lla att de √§r specifika och skilda fr√•n varandra.<br>- Bygg ett hierarkiskt system med en "routing" eller controller-agent f√∂r att avg√∂ra vilken agent som √§r korrekt. |

M√•nga av dessa problem kan identifieras mer effektivt med observabilitet p√• plats. De sp√•r och m√•tt vi diskuterade tidigare hj√§lper till att exakt lokalisera var i agentarbetsfl√∂det problemen uppst√•r, vilket g√∂r fels√∂kning och optimering mycket mer effektivt.

## Hantera kostnader
H√§r √§r n√•gra strategier f√∂r att hantera kostnaderna f√∂r att drifts√§tta AI-agenter i produktion:

**Anv√§nda mindre modeller:** Sm√• spr√•kmodeller (SLMs) kan fungera bra i vissa agentlika anv√§ndningsfall och kommer att minska kostnaderna avsev√§rt. Som n√§mnts tidigare √§r det b√§sta s√§ttet att f√∂rst√• hur bra en SLM kommer att prestera i ditt anv√§ndningsfall att bygga ett utv√§rderingssystem f√∂r att best√§mma och j√§mf√∂ra prestanda mot st√∂rre modeller. √ñverv√§g att anv√§nda SLMs f√∂r enklare uppgifter som avsiktsklassificering eller parameterutvinning, samtidigt som du reserverar st√∂rre modeller f√∂r komplexa resonemang.

**Anv√§nda en routermodell:** En liknande strategi √§r att anv√§nda en variation av modeller och storlekar. Du kan anv√§nda en LLM/SLM eller en serverl√∂s funktion f√∂r att dirigera f√∂rfr√•gningar baserat p√• komplexitet till de modeller som passar b√§st. Detta hj√§lper ocks√• till att minska kostnaderna samtidigt som det s√§kerst√§ller prestanda f√∂r r√§tt uppgifter. Till exempel, dirigera enkla fr√•gor till mindre, snabbare modeller, och anv√§nd endast dyra stora modeller f√∂r uppgifter som kr√§ver komplexa resonemang.

**Cachelagring av svar:** Att identifiera vanliga f√∂rfr√•gningar och uppgifter och tillhandah√•lla svaren innan de g√•r igenom ditt agentlika system √§r ett bra s√§tt att minska volymen av liknande f√∂rfr√•gningar. Du kan till och med implementera ett fl√∂de f√∂r att identifiera hur lik en f√∂rfr√•gan √§r de cachelagrade f√∂rfr√•gningarna med hj√§lp av mer grundl√§ggande AI-modeller. Denna strategi kan avsev√§rt minska kostnaderna f√∂r ofta st√§llda fr√•gor eller vanliga arbetsfl√∂den.

## L√•t oss se hur detta fungerar i praktiken

I [exempelanteckningsboken i detta avsnitt](./code_samples/10_autogen_evaluation.ipynb) kommer vi att se exempel p√• hur vi kan anv√§nda verktyg f√∂r observabilitet f√∂r att √∂vervaka och utv√§rdera v√•r agent.


### Har du fler fr√•gor om AI-agenter i produktion?

G√• med i [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) f√∂r att tr√§ffa andra deltagare, delta i kontorstider och f√• dina fr√•gor om AI-agenter besvarade.

## F√∂reg√•ende lektion

[Designm√∂nster f√∂r metakognition](../09-metacognition/README.md)

## N√§sta lektion

[Agentiska protokoll](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
Ansvarsfriskrivning:
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten Co-op Translator (https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet b√∂r du vara medveten om att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• sitt originalspr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas en professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->