# AI 代理的記憶 
[![代理記憶](../../../translated_images/zh-HK/lesson-13-thumbnail.959e3bc52d210c64.webp)](https://youtu.be/QrYbHesIxpw?si=qNYW6PL3fb3lTPMk)

在討論創建 AI 代理的獨特優勢時，主要談論兩件事：調用工具完成任務的能力以及隨時間改進的能力。記憶是創建能自我改進並為用戶創造更佳體驗的代理的基礎。

本課程將探討 AI 代理的記憶是什麼，以及我們如何管理和利用它來造福應用程序。

## 介紹

本課程將涵蓋：

• **理解 AI 代理記憶**：什麼是記憶，為何它對代理至關重要。

• **實作及存儲記憶**：為 AI 代理添加記憶功能的實用方法，重點是短期記憶與長期記憶。

• **讓 AI 代理自我改進**：記憶如何使代理從過去互動中學習並隨時間提升。

## 可用實現

本課程包含兩個詳盡的筆記本教學：

• **[13-agent-memory.ipynb](./13-agent-memory.ipynb)**：使用 Mem0 和 Azure AI 搜索結合 Semantic Kernel 框架實現記憶

• **[13-agent-memory-cognee.ipynb](./13-agent-memory-cognee.ipynb)**：使用 Cognee 實現結構化記憶，自動構建由嵌入支持的知識圖譜，並可視化圖譜及智能檢索

## 學習目標

完成本課程後，你將能：

• **區分多種類型的 AI 代理記憶**，包括工作記憶、短期記憶、長期記憶，以及像人格記憶和情節記憶等專門形式。

• **使用 Semantic Kernel 框架實作及管理 AI 代理的短期和長期記憶**，善用 Mem0、Cognee、Whiteboard 記憶等工具，並整合 Azure AI 搜索。

• **理解自我改進 AI 代理的原理**，以及堅實的記憶管理系統如何促進持續學習與適應。

## 理解 AI 代理記憶

記憶對 AI 代理而言，本質上是指能讓它們保留與回憶資訊的機制。這些資訊可以是關於對話的具體細節、用戶偏好、過往行動，甚至已學習的模式。

沒有記憶，AI 應用通常是無狀態的，意味著每次交互都從頭開始。這會導致反覆且令人沮喪的使用體驗，代理「忘記」之前的上下文或偏好。

### 為何記憶重要？

代理的智能與它召回並利用過去資訊的能力緊密相關。記憶讓代理能：

• **反思**：從過往行動和結果中學習。

• **互動**：在進行中的對話中維持上下文。

• **主動與被動反應**：根據歷史數據預測需求或恰當回應。

• **自主操作**：透過調用儲存的知識更獨立運作。

實施記憶的目標是使代理更**可靠且有能力**。

### 記憶類型

#### 工作記憶

可將其視為代理在單一進行中的任務或思考過程中使用的一張草稿紙。它存放計算下一步所需的即時資訊。

對 AI 代理而言，工作記憶常捕捉對話中最相關的資訊，即便完整聊天記錄冗長或被截斷。重點是提取關鍵元素，如需求、提案、決策與行動。

**工作記憶範例**

在旅遊訂票代理中，工作記憶可能捕捉用戶當前請求，如「我想訂去巴黎的旅程」。這個具體需求保存在代理的即時上下文中，引導目前的交互。

#### 短期記憶

此類記憶保留資訊於單次對話或會話期間。它是目前聊天的上下文，使代理能參考之前的對話回合。

**短期記憶範例**

若用戶問「到巴黎的機票要多少錢？」然後接著問「那住宿呢？」，短期記憶確保代理明白「那裡」指的是同一對話中的「巴黎」。

#### 長期記憶

這是跨多次對話或會話持續存在的資訊。它使代理能記住用戶偏好、歷史互動或長期的通識知識，這對個性化服務非常重要。

**長期記憶範例**

長期記憶可能儲存「Ben 喜歡滑雪和戶外活動，喜歡在有山景的咖啡廳，因為過往受過傷而希望避免高難度滑雪坡道」的資料。這些從過往互動學到的資訊會影響未來旅遊規劃會話的推薦，令其高度個人化。

#### 人格記憶

此專門記憶幫助代理發展一致的「個性」或「角色」。它讓代理記住自己或其預定角色的細節，使互動更流暢且專注。

**人格記憶範例**

如果旅遊代理被設計為「滑雪專家規劃師」，人格記憶可能強化這個角色，影響其回應以對應專家的語氣與知識。

#### 工作流程／情節記憶

這種記憶存儲代理在執行複雜任務期間採取的步驟、成功與失敗，就像記得特定「情節」或過去經驗以便學習。

**情節記憶範例**

如果代理試圖訂特定航班但因無座位失敗，情節記憶可記錄此失敗，讓代理下次嘗試提供替代航班或更有信息的提醒。

#### 實體記憶

涉及從對話中提取並記住具體實體（例如人、地點或物件）與事件，讓代理建立關鍵元素的結構化理解。

**實體記憶範例**

對話談及過去旅行時，代理可能提取「巴黎」、「埃菲爾鐵塔」和「Le Chat Noir 餐廳晚餐」作為實體。將來對話可回憶起「Le Chat Noir」，並主動提供協助訂位。

#### 結構化 RAG（檢索增強生成）

RAG 是一種更廣泛技術，"結構化 RAG" 被突顯為強大的記憶技術。它從多種來源（對話、電子郵件、圖片）提取濃縮且結構化資訊，以提升回應的精準度、召回率及速度。有別於傳統只依靠語義相似度的 RAG，結構化 RAG 利用資訊固有結構。

**結構化 RAG 範例**

不只是匹配關鍵字，結構化 RAG 可解析電子郵件中航班細節（目的地、日期、時間、航空公司）並結構化存儲，允許精確查詢如「我週二訂了哪班飛巴黎的航班？」

## 實作及存儲記憶

為 AI 代理實作記憶涉及系統化的**記憶管理**流程，包括生成、存儲、檢索、整合、更新，甚至「忘記」（或刪除）資訊。檢索是特別關鍵的部分。

### 專用記憶工具

#### Mem0

存儲及管理代理記憶的一種方法是使用專門工具如 Mem0。Mem0 作為持久記憶層，讓代理回憶相關互動、存用戶偏好和事實背景，並從成功失敗中學習。理念是讓無狀態代理變成有狀態代理。

其運作透過**兩階段記憶管道：提取與更新**。首階段，加入代理對話的訊息會送往 Mem0 服務，該服務運用大型語言模型(LLM)總結對話歷史並提取新記憶。隨後，LLM 驅動的更新階段決定是否要新增、修改或刪除記憶，並存入混合數據庫（可包括向量、圖形及鍵值數據庫）。系統也支援多種記憶類型，並能納入管理實體關係的圖記憶。

#### Cognee

另一強大方法是使用**Cognee**，這是一個開源語義記憶系統，能將結構化和非結構化數據轉成由嵌入支持的可查詢知識圖譜。Cognee 採用**雙存儲架構**，結合向量相似搜索和圖關聯，讓代理不只理解訊息何者相似，還能理解概念之間的關聯。

它擅長**混合檢索**，融合向量相似、圖結構與 LLM 推理 —— 從原始區塊查找到具圖結構感知的問答。系統維持**活躍記憶**，隨時間演化並擴展，同時作為一個連接圖保持可查詢，兼容短期會話上下文和長期持久記憶。

Cognee 筆記本教學（[13-agent-memory-cognee.ipynb](./13-agent-memory-cognee.ipynb)）展示如何構建此統一記憶層，提供多來源資料導入、知識圖譜視覺化和根據代理需求使用不同搜索策略進行查詢的實例。

### 使用 RAG 存儲記憶

除 Mem0 等專用記憶工具外，也可利用強大的搜索服務，如**Azure AI 搜索作為記憶存取後端**，特別適用於結構化 RAG。

這可讓代理回應根據自身數據「落地」，確保回答更相關與精確。Azure AI 搜索可用於存儲用戶專屬的旅程記憶、產品目錄或任何其他特定領域知識。

Azure AI 搜索支持功能如**結構化 RAG**，擅長從大型資料集如對話歷史、郵件甚至圖片中提取和檢索豐富結構化資訊。相比傳統文字切塊和嵌入方法，它提供「超越人類的精度和召回率」。

## 讓 AI 代理自我改進

自我改進代理的一個常見模式是新增**「知識代理」**。此代理獨立觀察用戶與主要代理間的對話。其角色是：

1. **識別有價值資訊**：判斷對話中是否有值得保存為通用知識或特定用戶偏好的部分。

2. **提取與摘要**：萃取對話中重要的學習或偏好。

3. **存入知識庫**：將此資訊持久化，通常存於向量資料庫以便日後檢索。

4. **增強後續查詢**：當用戶發起新查詢時，知識代理檢索相關儲存資訊並附加於用戶提示，為主代理提供關鍵上下文（類似 RAG）。

### 記憶優化

• **延遲管理**：為避免影響用戶交互速度，可先使用更便宜、快速的模型篩查是否值得存取資訊，只有在需要時才調用更複雜的提取/檢索流程。

• **知識庫維護**：當知識庫規模擴大，較少使用的資訊可以移至「冷存儲」，以控制成本。

## 對代理記憶還有疑問？

加入 [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) 與其他學習者交流，參加問答時段，解決你的 AI 代理相關問題。

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**免責聲明**：
本文件由 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。儘管我們力求準確，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應視為權威來源。對於重要資訊，建議使用專業人工翻譯。我們不對因使用本翻譯而引起的任何誤解或誤釋負責。
<!-- CO-OP TRANSLATOR DISCLAIMER END -->