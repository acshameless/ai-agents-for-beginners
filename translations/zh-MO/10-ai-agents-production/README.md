# 生產環境中的 AI 代理：可觀察性與評估

[![生產環境中的 AI 代理](../../../translated_images/zh-MO/lesson-10-thumbnail.2b79a30773db093e.webp)](https://youtu.be/l4TP6IyJxmQ?si=reGOyeqjxFevyDq9)

當 AI 代理從實驗性原型轉向真實世界應用時，了解其行為、監控其效能，以及系統性地評估其輸出就變得很重要。

## 學習目標

完成本課程後，你將知道/理解：
- 代理可觀察性與評估的核心概念
- 提升代理效能、成本與效果的技術
- 如何系統性地評估你的 AI 代理以及評估的內容
- 在將 AI 代理部署到生產環境時如何控制成本
- 如何為使用 AutoGen 建構的代理加入量測（instrumentation）

目標是讓你具備將「黑盒」代理轉變為透明、可管理且可靠系統的知識。

_**注意：** 部署安全且值得信賴的 AI 代理非常重要。也請參考 [建立值得信賴的 AI 代理](./06-building-trustworthy-agents/README.md) 這一課。_

## Traces and Spans

可觀察性工具（例如 [Langfuse](https://langfuse.com/) 或 [Microsoft Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry)）通常會把代理執行表示為 traces 和 spans。

- **Trace** 代表從開始到結束的一個完整代理任務（例如處理一次使用者查詢）。
- **Spans** 是 trace 中的個別步驟（例如呼叫語言模型或檢索資料）。

![Langfuse 中的追蹤樹](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

沒有可觀察性時，AI 代理可能會讓人覺得像個「黑盒」——其內部狀態與推理過程不透明，讓診斷問題或優化效能變得困難。有了可觀察性，代理則變成「玻璃盒」，提供建立信任並確保其依預期運作所需的透明度。

## 為何在生產環境中可觀察性很重要

將 AI 代理轉移到生產環境會帶來一系列新的挑戰與需求。可觀察性不再是「可有可無」，而是關鍵能力：

*   **除錯與根本原因分析**：當代理失敗或產生意外輸出時，可觀察性工具提供定位錯誤來源所需的 traces。這在可能涉及多次 LLM 呼叫、工具互動與條件邏輯的複雜代理中特別重要。
*   **延遲與成本管理**：AI 代理通常依賴按 token 或按呼叫計費的 LLM 與其他外部 API。可觀察性允許精確追踪這些呼叫，幫助識別過慢或過度昂貴的操作。這能使團隊優化提示、選擇更高效的模型，或重新設計工作流程以管理營運成本並確保良好的使用者體驗。
*   **信任、安全與合規**：在許多應用中，確保代理行為安全且合乎倫理非常重要。可觀察性提供代理行為與決策的審計軌跡。這可用來檢測並緩解如提示注入、產生有害內容或錯誤處理個人可識別資訊（PII）等問題。例如，你可以檢視 traces 以了解代理為何會提供特定回應或使用某個工具。
*   **持續改進回饋循環**：可觀察性資料是迭代開發流程的基礎。透過監控代理在真實世界的表現，團隊可以識別改進空間、收集微調模型所需的資料，並驗證變更的影響。這創造了一個回饋循環，從線上評估得到的生產洞見會反饋到離線實驗與精進，讓代理效能逐步提升。

## 需要追蹤的關鍵指標

為了監控並理解代理行為，應該追蹤一系列指標與訊號。雖然具體指標會依代理的目的而異，但有些是普遍重要的。

以下是可觀察性工具常監控的一些指標：

**延遲：** 代理回應的速度如何？過長的等待時間會負面影響使用者體驗。你應該透過追蹤代理執行來量測任務與個別步驟的延遲。例如，一個代理對所有模型呼叫合計耗時 20 秒，就可以透過使用更快的模型或將模型呼叫並行化來加速。

**成本：** 每次代理執行的費用是多少？AI 代理仰賴按 token 計費的 LLM 呼叫或外部 API。頻繁使用工具或多次提示會快速增加成本。例如，如果代理為了微幅的品質提升而呼叫 LLM 五次，就必須評估該成本是否合理，或是否可以減少呼叫次數或改用更便宜的模型。即時監控亦能協助識別意外的費用尖峰（例如錯誤導致的過度 API 迴圈）。

**請求錯誤：** 代理失敗的請求有多少？這包括 API 錯誤或工具呼叫失敗。為了讓代理在生產環境中更具韌性，你可以建立備援或重試機制。例如，如果 LLM 提供者 A 遇到問題，可切換到 LLM 提供者 B 作為備援。

**使用者回饋：** 實作直接的使用者評估能提供有價值的洞見。這可以包括明確的評分（👍thumbs-up/👎down、⭐1-5 顆星）或文字評論。持續的負面回饋應該引起你的警覺，表示代理未如預期運作。

**隱含的使用者回饋：** 即使沒有明確評分，使用者行為也會提供間接回饋。這可以包括立即重新表述問題、重複查詢或點擊重試按鈕。例如，如果你發現使用者反覆問同一個問題，這表示代理沒有如預期運作。

**準確度：** 代理產出正確或理想輸出的頻率如何？準確度的定義會有所不同（例如解題正確性、資訊檢索準確性、使用者滿意度）。第一步是定義代理的成功標準。你可以透過自動化檢查、評分或任務完成標籤來追蹤準確度。例如，將 traces 標記為「成功」或「失敗」。

**自動化評估指標：** 你也可以建立自動化評估。例如，使用 LLM 來為代理的輸出打分（是否有幫助、是否準確等）。也有數個開源函式庫可以幫助你針對代理的不同面向進行評分，例如用於 RAG 代理的 [RAGAS](https://docs.ragas.io/) 或用於偵測有害語言或提示注入的 [LLM Guard](https://llm-guard.com/)。

在實務上，這些指標的組合能提供對 AI 代理健康狀況的最佳覆蓋。在本章的 [範例 notebook](./code_samples/10_autogen_evaluation.ipynb) 中，我們會展示這些指標在真實範例中的樣貌，但首先我們會學習典型的評估工作流程長什麼樣。

## 為你的代理加入監控

要收集追蹤資料，你需要在程式碼中加入監控。目標是讓代理程式碼能發出可被可觀察性平台捕捉、處理與視覺化的 traces 和指標。

**OpenTelemetry (OTel)：** [OpenTelemetry](https://opentelemetry.io/) 已成為 LLM 可觀察性的業界標準。它提供一組用於產生、收集與匯出遙測資料的 API、SDK 與工具。

有許多封裝現有代理框架的量測庫，使得將 OpenTelemetry spans 匯出到可觀察性工具變得容易。下面是一個使用 [OpenLit instrumentation library](https://github.com/openlit/openlit) 為 AutoGen 代理加入監控的範例：

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

本章的 [範例 notebook](./code_samples/10_autogen_evaluation.ipynb) 會示範如何為你的 AutoGen 代理加入監控。

**手動建立 Span：** 雖然量測庫提供了良好的基線，但在某些情況下你可能需要更詳盡或自定的資訊。你可以手動建立 spans 來加入自定的應用邏輯。更重要的是，你可以用自定屬性（也稱為標籤或 metadata）來豐富自動或手動建立的 spans。這些屬性可以包含業務相關資料、中間計算，或任何對除錯或分析有用的上下文，例如 `user_id`、`session_id` 或 `model_version`。

以 [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3) 手動建立 traces 與 spans 的範例如下：

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## 代理評估

可觀察性能提供指標，而評估則是分析那些資料（並執行測試）以判斷 AI 代理表現與改進方向的過程。換句話說，一旦你有了 traces 與指標，你要如何使用它們來評判代理並做出決策？

定期評估很重要，因為 AI 代理通常是非決定性的，且可能會隨著更新或模型行為漂移而演變——沒有評估，你無法知道你的「智慧代理」是否真的做得好或是否出現回歸。

AI 代理的評估有兩大類：**在線評估**與**離線評估**。兩者都很有價值，且互補。我們通常從離線評估開始，因為這是部署任何代理前的最低必要步驟。

### 離線評估

![Langfuse 中的資料集項目](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

這涉及在受控環境中評估代理，通常使用測試資料集，而非實際的使用者查詢。你使用已策劃的資料集，在那裡你知道預期輸出或正確行為，然後在這些資料上執行代理。

例如，如果你建了一個數學應用題代理，你可能有一個包含 100 題且有已知答案的 [測試資料集](https://huggingface.co/datasets/gsm8k)。離線評估通常在開發期間進行（並可以成為 CI/CD 管道的一部分），以檢查改進或防止回歸。好處是它是**可重複的，且因為有真實答案，你可以獲得清楚的準確度指標**。你也可以模擬使用者查詢，並將代理的回應與理想答案比對，或使用上述自動化指標。

離線評估的主要挑戰是確保你的測試資料集具有代表性並持續相關——代理可能在固定測試集上表現良好，但在生產環境面對非常不同的查詢時表現不佳。因此，你應保持測試集更新，加入能反映真實情境的新邊緣案例與範例。混合小型「快速檢查」案例與較大型評估集是有用的：小型集合用於快速檢查，較大型用於更廣泛的效能衡量。

### 在線評估

![可觀察性指標總覽](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

這是指在真實、線上環境中評估代理，即在實際生產使用期間。線上評估涉及監控代理在真實使用者互動中的表現並持續分析結果。

例如，你可能會追蹤成功率、使用者滿意度分數或其他針對實際流量的指標。線上評估的優勢在於它能**捕捉你在實驗室環境中可能預料不到的情況**——你可以觀察模型隨時間的漂移（若輸入模式改變導致代理效能退化）並捕捉測試資料中沒有出現的意外查詢或情境。它提供代理在實際環境中表現的真實樣貌。

線上評估通常包括收集隱性與明性使用者回饋（如前所述），並可能執行 shadow tests 或 A/B 測試（新版本代理與舊版本並行執行以作比較）。挑戰在於為線上互動取得可靠的標籤或分數可能很困難——你可能需要依賴使用者回饋或下游指標（例如使用者是否點擊結果）。

### 結合兩者

線上與離線評估並非互斥；它們高度互補。來自線上監控的洞見（例如代理在某類新型使用者查詢上表現不佳）可以用來擴充與改善離線測試資料集。反之，在離線測試中表現良好的代理也可以更有信心地部署並在線上監控。

事實上，許多團隊採用如下循環：

_evaluate offline -> deploy -> monitor online -> collect new failure cases -> add to offline dataset -> refine agent -> repeat_。

## 常見問題

當你將 AI 代理部署到生產環境時，可能會遇到各種挑戰。以下是一些常見問題及其可能的解決方案：

| **問題**    | **潛在解決方案**   |
| ------------- | ------------------ |
| AI 代理執行任務不穩定 | - 調整給 AI 代理的提示；明確目標。<br>- 識別何時將任務拆分為子任務並由多個代理處理會有幫助。 |
| AI 代理陷入持續迴圈  | - 確保有明確的終止條件與規則，讓代理知道何時停止該流程。<br>- 對於需要推理與規劃的複雜任務，使用專門處理推理任務的較大模型。 |
| AI 代理的工具呼叫性能不佳   | - 在代理系統之外測試並驗證工具的輸出。<br>- 優化工具的定義參數、提示與命名。  |
| 多代理系統表現不穩定 | - 精煉給每個代理的提示，確保它們具體且彼此區分。<br>- 建立一個層級式系統，使用「路由」或控制代理來決定哪個代理最適合。 |

許多這些問題在具備可觀察性的情況下能更有效地被識別。我們先前討論的 traces 與指標可以精確指出代理工作流程中哪個環節出問題，讓除錯與優化更有效率。

## 管理成本
以下是一些管理將 AI 代理部署到生產環境成本的策略：

**使用較小的模型：** 小型語言模型 (SLMs) 在某些具代理性的用例中表現良好，並能顯著降低成本。如前所述，建立一個評估系統來判定並比較與較大模型的效能，是了解 SLM 在你的用例中表現如何的最佳方式。可考慮在較簡單的任務（例如意圖分類或參數擷取）中使用 SLMs，同時將較大的模型保留給複雜推理任務。

**使用路由器模型：** 類似的策略是使用多樣化的模型與不同規模。你可以使用 LLM/SLM 或無伺服器函式來根據請求的複雜度將其導向最適合的模型。這樣既能降低成本，也能確保在適當的任務上達到所需效能。例如，將簡單查詢導向較小且較快的模型，僅在複雜推理任務時才使用昂貴的大型模型。

**快取回應：** 識別常見的請求與任務，並在它們進入你的代理系統之前就提供回應，是減少相似請求量的好方法。你甚至可以實作一個流程，使用較基礎的 AI 模型來判定某個請求與快取請求的相似程度。這種策略對於常見問題或常用工作流程可以大幅降低成本。

## 讓我們看看這在實務上如何運作

在 [本節的範例筆記本](./code_samples/10_autogen_evaluation.ipynb)，我們將看到如何使用可觀測性工具來監控並評估我們的代理的範例。


### 對於 AI 代理在生產環境有更多問題嗎？

加入 [Microsoft Foundry Discord](https://aka.ms/ai-agents/discord) 與其他學習者見面、參加問答時段，並解答你關於 AI 代理的問題。

## 上一課

[元認知設計模式](../09-metacognition/README.md)

## 下一課

[代理協定](../11-agentic-protocols/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
免責聲明：
本文件已使用人工智能翻譯服務 Co‑op Translator (https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們力求準確，但請注意，自動翻譯可能包含錯誤或不準確之處。原文（以原始語言撰寫）的文件應視為具權威性的版本。若涉及重要資訊，建議委託專業人工翻譯。我們不對因使用本翻譯而引起的任何誤解或錯誤詮釋承擔責任。
<!-- CO-OP TRANSLATOR DISCLAIMER END -->